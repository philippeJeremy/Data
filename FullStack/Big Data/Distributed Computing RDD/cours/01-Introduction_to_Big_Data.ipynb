{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Big Data üóÑÔ∏è\n",
    "\n",
    "## What you will learn in this course üßêüßê\n",
    "This course will introduce the notion of big data, what it stands for and how it changed the way people handle data nowadays. We'll follow this outline:\n",
    "* Introduction to Big Data\n",
    "    * Gartner's 3Vs\n",
    "    * History\n",
    "    * Requirements for distributed files systems\n",
    "    * Distributed processing\n",
    "        * Horizontal vs vertical scaling\n",
    "        * When do we need distributed processing\n",
    "        * Why is distributed processing hard?\n",
    "        * MapReduce\n",
    "    * Apache Hadoop\n",
    "\n",
    "## Introduction to Big Data üóÑÔ∏è\n",
    "\n",
    "Big Data has been a buzzword for a couple of years now, making it a rather blury concept which every one thinks they understand when they actually of speak the same word thinking of different things, and when you try to define it you realize there must be more to it.\n",
    "\n",
    "One definition that is very popular:\n",
    "\n",
    "### Gartner's 3Vs 3Ô∏è‚É£\n",
    "\n",
    "*‚ÄúBig data‚Äù is high-volume, -velocity and -variety information assets that demand cost-effective, innovative forms of information processing for enhanced insight and decision making.*\n",
    "\n",
    "- **V**olume\n",
    "\n",
    "This one is pretty self explanatory, it refers to exponentially increasing quantity of data produced by companies, institutions and people.\n",
    "\n",
    "- **V**ariety\n",
    "\n",
    "Organisations are digging out amazing insights from text, locations or log files, not only on aggregated well behaved sales datasets. Elevator logs help to predict vacated real estate, shoplifters tweet about stolen goods right next to the store, emails contain communication patterns of successful projects.\n",
    "\n",
    "- **V**elocity\n",
    "\n",
    "It is frequently equated to real-time analytics. Yet, velocity is also about the rate of changes, about linking data sets that are coming with different speeds and about bursts of activities, rather than habitual steady tempo. \n",
    "\n",
    "### Some history üìú\n",
    "\n",
    "- 2003 - Google Distributed File System\n",
    "The first file system that enabled robust and reliable data storage and access on a cluster of several computers instead of one.\n",
    "\n",
    "- 2004 - Google‚Äôs MapReduce\n",
    "\n",
    "- 2006 - Hadoop\n",
    "The first stable and viable software suite that made it possible to use the MapReduce framework to solve problems on very large sets of data.\n",
    "\n",
    "### Requirements of Distributed File Systems üìë\n",
    "\n",
    "- **schemaless** with no predefined structure, i.e. no rigid schema with tables and columns (column names types and sizes)\n",
    "- **durable** once data is written it should never be lost\n",
    "- **capable of handling component failure** without human intervention (e.g. CPU, disk, memory, network, power supply, MB)\n",
    "- **automatically rebalanced** to even out disk space consumption throughout cluster\n",
    "\n",
    "### Distributed processing üîÄ\n",
    "\n",
    "#### Vertical scaling vs horizontal scaling ‚¨ÜüÜö‚û°\n",
    "\n",
    "* **Vertical scaling:** adding more power (CPU, RAM) to an existing machine.\n",
    "\n",
    "<img src=\"https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/vertical_scaling.png\" />\n",
    "\n",
    "It's expensive and limited by Moore's Law (The law according to which computing power doubles every two years).\n",
    "\n",
    "* **Horizontal scaling:** adding more machines into your pool of resources and connecting them into a cluster.\n",
    "\n",
    "<img src=\"https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/horizontal_scaling.png\" />\n",
    "\n",
    "Allows usage of commodity hardware, e.g. you don't need supercomputers.\n",
    "\n",
    "#### When do we need distributed processing ‚ùì\n",
    "\n",
    "- Data won't fit in the memory of a single machine\n",
    "- Computing can be chunked into small pieces and parallelized (either analytics, ETL or modeling)\n",
    "- We want to run multiple computations in parallel, for example, testing different hyperparameters of a machine learning model (you will learn more about this in the supervised machine learning module)\n",
    "\n",
    "#### Distributed computing is hard ü§ï\n",
    "\n",
    "> In a distributed system, anything that can go wrong, will go wrong.\n",
    "\n",
    "Failure is not an option, **failure is expected**.\n",
    "\n",
    "When you're running a cluster of thousands of machine, the probability that at least one will fail is actually very high. If one job dies or is slow, the whole process will fail. You need safeguards against this. (RDDs for example)\n",
    "\n",
    "#### MapReduce üó∫Ô∏è\n",
    "\n",
    "<img src=\"https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/FULL_STACK_12_WEEK/M05/map_reduce_word_count_process-ed4d1e0b-1180-4609-88e1-e2b1054829e7.png\" />\n",
    "\n",
    "Source: [https://www.oreilly.com/library/view/distributed-computing-in/9781787126992/5fef6ce5-20d7-4d7c-93eb-7e669d48c2b4.xhtml](https://www.oreilly.com/library/view/distributed-computing-in/9781787126992/5fef6ce5-20d7-4d7c-93eb-7e669d48c2b4.xhtml)\n",
    "\n",
    "MapReduce is a programming model and an associated implementation for processing and generating big data sets with a parallel, distributed algorithm on a cluster. (Wikipedia)\n",
    "\n",
    "* **Map**: each worker node applies the map function to the local data\n",
    "\n",
    "* **Shuffle**: worker nodes redistribute data based on the output keys (produced by the previous map step), such that all data belonging to one key is located on the same worker node\n",
    "\n",
    "* **Reduce**: worker node process each group of data, per key, in parallel\n",
    "\n",
    "The key contributions of the MapReduce framework are not the actual map and reduce functions  but the scalability and fault-tolerance achieved for a variety of applications by optimizing the execution engine. The use of this model is beneficial only when the optimized distributed shuffle operation (which reduces network communication cost) and fault tolerance features of the MapReduce framework come into play.\n",
    "\n",
    "---\n",
    "\n",
    "### Apache Hadoop üêò\n",
    "\n",
    "![](https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/664px-Hadoop_logo-381ff611-6909-4d30-bbd7-68b6a3257526.png)\n",
    "\n",
    "A popular open-source implementation of the MapReduce paradigm (plus a distributed file system (HDFS) and some other parts like a resource manager.\n",
    "\n",
    "## Ressources üìöüìö\n",
    "\n",
    "* See [Google's paper on GDFS](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/035fc972c796d33122033a0614bc94cff1527999.pdf) and the excellent [History of Hadoop](https://medium.com/@markobonaci/the-history-of-hadoop-68984a11704).\n",
    "* [the-essentials-of-database-scalability-vertical-horizontal](https://blog.turbonomic.com/blog/on-technology/the-essentials-of-database-scalability-vertical-horizontal)\n",
    "* Berkeley CS61a [Chapter 4: Distributed and Parallel Computing](http://wla.berkeley.edu/~cs61a/fa11/lectures/communication.html#distributed-computing)\n",
    "* [Byzantine Generals problem](https://medium.com/all-things-ledger/the-byzantine-generals-problem-168553f31480)\n",
    "* [8 fallacies of distributed computing](https://www.youtube.com/watch?v=Q4p-2WIS0nQ)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fbc4d3870518eee81184ced0d2279c769a0eca59aab465c4e7ec13e5e6c47a3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
