{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03-Code_encoder_decoder.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOi58V29sj6l4YzRqo6LhQp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"e4N9XyPIoWHV"},"source":["# Code Encoder Decoder\n","\n","The goal of this demo is to teach you how to code an encoder decoder model!\n","Since this is just a demo we will use generated data, you'll be able to tackle the real problem during the exercise, the goal here is to focus on building the model and the training loop."]},{"cell_type":"markdown","metadata":{"id":"-CqUIHNG_w-j"},"source":["## Import libraries"]},{"cell_type":"code","metadata":{"id":"PyeOCpH_yRRe","executionInfo":{"status":"ok","timestamp":1633610975554,"user_tz":-120,"elapsed":189,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"}}},"source":["# Import Tensorflow & Pathlib librairies\n","import tensorflow as tf \n","import pathlib \n","import pandas as pd \n","import os\n","import io\n","import warnings\n","warnings.filterwarnings('ignore')\n","import json\n","from random import randint\n","from numpy import array\n","from numpy import argmax\n","from numpy import array_equal\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.layers import LSTM\n","from tensorflow.keras.layers import Dense"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8yZhjrVO_6aw"},"source":["## Generate data\n","\n","We will generate random input and target data for the purpose of the demonstration."]},{"cell_type":"code","metadata":{"id":"wDwgQyLDHzbN","executionInfo":{"status":"ok","timestamp":1633610975757,"user_tz":-120,"elapsed":6,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"}}},"source":["input_dim = 100\n","input_seq_len = 10\n","target_seq_len = 5"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"0HQ-jiYSAD0D","executionInfo":{"status":"ok","timestamp":1633610975758,"user_tz":-120,"elapsed":7,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"}}},"source":["# generate a sequence of random integers\n","def generate_sequence(length, n_unique):\n","\treturn [randint(1, n_unique-1) for _ in range(length)]"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w-N8q1gaBCsy","executionInfo":{"status":"ok","timestamp":1633610975758,"user_tz":-120,"elapsed":7,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"}},"outputId":"e8a7b206-ca4a-4e13-a1e5-00266822cb15"},"source":["generate_sequence(input_seq_len,input_dim)"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[37, 86, 61, 43, 95, 23, 20, 38, 4, 40]"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"01pWZiHjAJFV","executionInfo":{"status":"ok","timestamp":1633610976013,"user_tz":-120,"elapsed":259,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"}}},"source":["# prepare data for the LSTM\n","def get_dataset(n_in, n_out, cardinality, n_samples, printing=False):\n","  X1, X2, y = list(), list(), list()\n","  for _ in range(n_samples):\n","    # generate source sequence\n","    source = generate_sequence(n_in, cardinality)\n","    if printing:\n","      print(\"source:\", source)\n","    # define padded target sequence\n","    target = source[:n_out]\n","    target.reverse()\n","    if printing:\n","      print(\"target:\", target)\n","    # create padded input target sequence\n","    target_in = [0] + target[:-1]\n","    if printing:\n","      print(\"padded target:\", target_in)\n","    # store\n","    X1.append(source)\n","    X2.append(target_in)\n","    y.append(target)\n","  return array(X1), array(X2), array(y)"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rWkizklpBJpz","executionInfo":{"status":"ok","timestamp":1633610976014,"user_tz":-120,"elapsed":7,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"}},"outputId":"79c29d8e-d6a0-456f-dab7-2ca62e5cf728"},"source":["input, padded_target, target =  get_dataset(input_seq_len,target_seq_len,input_dim,1,True)"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["source: [8, 47, 44, 46, 28, 38, 29, 35, 72, 71]\n","target: [28, 46, 44, 47, 8]\n","padded target: [0, 28, 46, 44, 47]\n"]}]},{"cell_type":"markdown","metadata":{"id":"T-6_AV5lD-6Y"},"source":["The data we are generating consists in a random sequence of numbers (they could very well represent encoded letters, words, sentences or anything you could think of).\n","\n","The target is built using the first elements of the input in reversed order.\n","\n","We also create a padded target sequence for teacher forcing (remember it is when the previous element from the target will be used as information for the decoder to predict the next element in the target)\n","\n","Now that we understand this, let's create the training data and validation data."]},{"cell_type":"code","metadata":{"id":"VeOFZcCeFFGj","executionInfo":{"status":"ok","timestamp":1633610976212,"user_tz":-120,"elapsed":201,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"}}},"source":["X_train, padded_y_train, y_train = get_dataset(input_seq_len,target_seq_len,input_dim,10000)\n","X_val, padded_y_val, y_val = get_dataset(input_seq_len,target_seq_len,input_dim,5000)"],"execution_count":40,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BPzJHFiSFaeo"},"source":["## Create encoder model\n","\n","In this step we will define the encoder model.\n","\n","The goal of the encoder is to create a representation of the input data, to extract information from the input data which will then be interpreted by the decoder model.\n","\n","The encoder receives sequence inputs and will output sequences with a given depth of representation (we  usually called that dimension channels before)"]},{"cell_type":"code","metadata":{"id":"0D_EKSjfLxd4","executionInfo":{"status":"ok","timestamp":1633610976212,"user_tz":-120,"elapsed":4,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"}}},"source":["# let's start by defining the number of units needed for the embedding and\n","# the lstm layers\n","\n","n_embed = 32\n","n_lstm = 16"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"kquiEvuTHfYw","executionInfo":{"status":"ok","timestamp":1633610976641,"user_tz":-120,"elapsed":431,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"}}},"source":["encoder_input = tf.keras.Input(shape=(input_seq_len))\n","encoder_embed = tf.keras.layers.Embedding(input_dim=input_dim, output_dim=n_embed)\n","encoder_lstm = tf.keras.layers.LSTM(n_lstm, return_state=True)\n","\n","encoder_embed_ouput = encoder_embed(encoder_input)\n","encoder_output = encoder_lstm(encoder_embed_ouput)\n","\n","encoder = tf.keras.Model(inputs = encoder_input, outputs = encoder_output)"],"execution_count":42,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LxjlemPeKTt8"},"source":["That's it, it does not need to be anymore complicated than this, note though that we did not preserve the sequential nature of the data, but we output the cell state, which will serve as input state for the decoder!\n","\n","Let's try it out on an input to see what comes out!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XkgQs5mXJmHO","executionInfo":{"status":"ok","timestamp":1633610976642,"user_tz":-120,"elapsed":10,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"}},"outputId":"3e1f722e-b566-4c1d-d8de-18b67abadb40"},"source":["encoder(tf.expand_dims(X_train[0],0))"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n"," array([[-0.0008015 , -0.01416984,  0.01448857, -0.00112979,  0.00277521,\n","         -0.01476327,  0.00390315,  0.00686706, -0.01231197,  0.00438643,\n","          0.00354464,  0.00281679,  0.01053815,  0.0159905 ,  0.01118115,\n","         -0.00448248]], dtype=float32)>,\n"," <tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n"," array([[-0.0008015 , -0.01416984,  0.01448857, -0.00112979,  0.00277521,\n","         -0.01476327,  0.00390315,  0.00686706, -0.01231197,  0.00438643,\n","          0.00354464,  0.00281679,  0.01053815,  0.0159905 ,  0.01118115,\n","         -0.00448248]], dtype=float32)>,\n"," <tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n"," array([[-0.00157401, -0.02897191,  0.02902606, -0.00225902,  0.00572838,\n","         -0.02893112,  0.00783362,  0.01341706, -0.02487618,  0.0086576 ,\n","          0.00697065,  0.00555785,  0.02056631,  0.03217805,  0.02257848,\n","         -0.00900368]], dtype=float32)>]"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"Q6Bd5XPCPrTJ"},"source":["## Create decoder\n","\n","The goal of the decoder is to use the encoder output and the previous target element to predict the next target element!\n","Which means its output is a sequence with as many elements as the target (this is where the padded target comes in, it will serve as input) and must have a number of channels equals to the number of possible values for target elements.\n","\n","Here we can't use the standard Sequential framework to build the model because the initial state of the decoder as to be set as the encoder states.\n","\n","In addition to this, two versions of the same model (with the same weights) have to be prepared, one of them for training, and one of them for inference (prediction on new unknown data). We'll detail the reason for this in what follows."]},{"cell_type":"markdown","metadata":{"id":"BhFnD8qQIUNQ"},"source":["### Decoder for training\n","\n","Training the decoder requires that we use the teacher forcing mechanism, that will provide the model with the correct answer from the previous element in the output sequence to predict the next element in the output sequence."]},{"cell_type":"code","metadata":{"id":"fgWYnH-UQU1Y","executionInfo":{"status":"ok","timestamp":1633610977071,"user_tz":-120,"elapsed":435,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"}}},"source":["decoder_input = tf.keras.Input(shape=(target_seq_len))\n","decoder_embed = tf.keras.layers.Embedding(input_dim=input_dim,output_dim=n_embed)\n","decoder_lstm = tf.keras.layers.LSTM(n_lstm, return_sequences=True, return_state=True)\n","decoder_pred = tf.keras.layers.Dense(input_dim, activation=\"softmax\")\n","\n","decoder_embed_output = decoder_embed(decoder_input) # teacher forcing happens here\n","# the decoder input is actually the padded target we created earlier, remember\n","# if target is: [91, 47, 89, 21, 62]\n","# the decoder input will be: [0, 91, 47, 89, 21]\n","decoder_lstm_output, _, _ = decoder_lstm(decoder_embed_output, initial_state=encoder_output[1:])\n","# in the step described above the decoder receives the encoder state as its\n","# initial state.\n","decoder_output = decoder_pred(decoder_lstm_output)\n","# then the dense layer will convert the vector representation for each element\n","# in the sequence into a probability distribution across all possible tokens\n","# in the vocabulary!\n","\n","decoder = tf.keras.Model(inputs = [encoder_input,decoder_input], outputs = decoder_output)\n","# all we need to do is put the model together using the input output framework!"],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gELMttoHbqOx"},"source":["Let's try out the decoder model on some input sequences!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"en8cZTDpbwrc","executionInfo":{"status":"ok","timestamp":1633610977486,"user_tz":-120,"elapsed":419,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"}},"outputId":"0544cceb-56c3-4e6a-8702-406b3a3db3ae"},"source":["decoder([tf.expand_dims(X_train[0],0),tf.expand_dims(padded_y_train[0],0)])"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 5, 100), dtype=float32, numpy=\n","array([[[0.00993765, 0.01003179, 0.01005074, 0.00998255, 0.01002816,\n","         0.00986233, 0.00999714, 0.00993832, 0.01003569, 0.00992759,\n","         0.01005428, 0.01008545, 0.01012676, 0.00999361, 0.01012079,\n","         0.00996771, 0.01009511, 0.01004484, 0.01006847, 0.00988823,\n","         0.00993143, 0.0100653 , 0.00998847, 0.00998062, 0.00996088,\n","         0.0099541 , 0.00996993, 0.01003942, 0.01001204, 0.01008488,\n","         0.01000296, 0.00995553, 0.01000181, 0.00999019, 0.01004315,\n","         0.01002374, 0.01003929, 0.00997067, 0.01001312, 0.0099583 ,\n","         0.00996789, 0.01012802, 0.01003536, 0.01004526, 0.01000515,\n","         0.01009611, 0.01004796, 0.01001268, 0.01008893, 0.00995894,\n","         0.01001169, 0.01008057, 0.01000783, 0.01000184, 0.01001132,\n","         0.00988387, 0.0100054 , 0.00994856, 0.00998683, 0.00993286,\n","         0.01003086, 0.00998121, 0.01007184, 0.01000163, 0.00999537,\n","         0.00999809, 0.01002349, 0.00998077, 0.01004493, 0.00991529,\n","         0.01007084, 0.00997306, 0.00994448, 0.00996754, 0.00994327,\n","         0.00991628, 0.00993768, 0.01001839, 0.00996832, 0.0100007 ,\n","         0.00988018, 0.01003533, 0.00989192, 0.01007303, 0.01001997,\n","         0.01009967, 0.00995695, 0.0099815 , 0.00996632, 0.00999063,\n","         0.01011761, 0.00994845, 0.00999843, 0.00995874, 0.00992618,\n","         0.00990968, 0.00996776, 0.01000881, 0.0099754 , 0.01002923],\n","        [0.00996933, 0.01005823, 0.01002499, 0.01002161, 0.01003119,\n","         0.00990516, 0.0100011 , 0.00998048, 0.01004006, 0.01001082,\n","         0.00998434, 0.0101189 , 0.01000723, 0.00995679, 0.01009696,\n","         0.0099706 , 0.01009186, 0.01002107, 0.01002927, 0.00998   ,\n","         0.00998371, 0.0101142 , 0.00998254, 0.00995893, 0.00993507,\n","         0.00998114, 0.00999134, 0.00998558, 0.00999551, 0.01000775,\n","         0.00999273, 0.00996587, 0.00999148, 0.01000252, 0.01001444,\n","         0.00995303, 0.01006484, 0.00991968, 0.00999658, 0.00995758,\n","         0.01000122, 0.01007141, 0.01004202, 0.01005887, 0.01001531,\n","         0.01001013, 0.01001478, 0.01001309, 0.01001918, 0.00989604,\n","         0.00999086, 0.01007506, 0.01000068, 0.01000682, 0.00998961,\n","         0.00995552, 0.01006156, 0.00992713, 0.01006619, 0.00995216,\n","         0.0100037 , 0.0099579 , 0.01002459, 0.01011121, 0.00997853,\n","         0.0099764 , 0.01003865, 0.01000474, 0.00999354, 0.00994634,\n","         0.01003684, 0.0100387 , 0.00998414, 0.00994827, 0.00992359,\n","         0.00995211, 0.01000277, 0.00994131, 0.00999662, 0.01002956,\n","         0.00990686, 0.01002761, 0.00987349, 0.01006366, 0.01008717,\n","         0.0100675 , 0.01002305, 0.01002146, 0.00999135, 0.01003823,\n","         0.01011424, 0.00993464, 0.00997764, 0.00997685, 0.0099484 ,\n","         0.00990113, 0.00991246, 0.0099928 , 0.01002761, 0.00996212],\n","        [0.01001495, 0.01005659, 0.00999287, 0.01004506, 0.01000449,\n","         0.00994238, 0.00995296, 0.00999785, 0.01002686, 0.01004762,\n","         0.00996219, 0.01005318, 0.00991646, 0.00996189, 0.01009393,\n","         0.01002124, 0.01008158, 0.00999067, 0.01000621, 0.01001172,\n","         0.01000289, 0.01011872, 0.00997117, 0.01000815, 0.00991993,\n","         0.01006716, 0.00995232, 0.00996856, 0.00992809, 0.00992899,\n","         0.00997368, 0.01005617, 0.00997453, 0.01003233, 0.00995511,\n","         0.00992916, 0.0100625 , 0.0098719 , 0.0100013 , 0.00996472,\n","         0.01006267, 0.00996513, 0.01001683, 0.01007517, 0.01001964,\n","         0.00992991, 0.00995544, 0.01005671, 0.0099981 , 0.00993701,\n","         0.01000518, 0.01004308, 0.00996512, 0.00996681, 0.01001169,\n","         0.01000346, 0.01005086, 0.00999569, 0.01008353, 0.01002142,\n","         0.00997138, 0.00994286, 0.01000629, 0.01010896, 0.00992839,\n","         0.0099733 , 0.01004388, 0.01000009, 0.00992077, 0.01001211,\n","         0.01002643, 0.01002679, 0.01003242, 0.00988903, 0.01000318,\n","         0.00997206, 0.01003905, 0.00994197, 0.01000465, 0.0100343 ,\n","         0.01002598, 0.00997528, 0.0099123 , 0.0099913 , 0.01009734,\n","         0.01004036, 0.01007265, 0.01001584, 0.01006921, 0.00998569,\n","         0.01006549, 0.01003604, 0.00996604, 0.01003349, 0.00998178,\n","         0.00993371, 0.00989039, 0.00999921, 0.01007033, 0.0099282 ],\n","        [0.0100168 , 0.01006159, 0.00999204, 0.01004242, 0.00999585,\n","         0.00993086, 0.00997768, 0.01003906, 0.00999195, 0.01004783,\n","         0.00994164, 0.01005604, 0.00990234, 0.00999776, 0.01009051,\n","         0.01003028, 0.0100599 , 0.0099946 , 0.01001482, 0.01001098,\n","         0.01000793, 0.01011107, 0.00997947, 0.01002333, 0.00990326,\n","         0.01007974, 0.00998536, 0.00996719, 0.00993185, 0.00992819,\n","         0.0099692 , 0.01005949, 0.00996464, 0.01001822, 0.00996371,\n","         0.0099175 , 0.01005617, 0.00985783, 0.01000803, 0.009965  ,\n","         0.01008692, 0.00996314, 0.01002816, 0.01007723, 0.01000991,\n","         0.00991689, 0.0099506 , 0.01000627, 0.00999412, 0.00994123,\n","         0.01000235, 0.010062  , 0.00995873, 0.00999197, 0.0100215 ,\n","         0.01001052, 0.01006581, 0.00998168, 0.01008493, 0.01003544,\n","         0.00995055, 0.00996833, 0.00998842, 0.01010598, 0.00994512,\n","         0.00996537, 0.01003881, 0.01000433, 0.00991901, 0.00999502,\n","         0.00999832, 0.01003835, 0.01005292, 0.00989838, 0.00997954,\n","         0.00999241, 0.01001814, 0.00993145, 0.01000586, 0.01004495,\n","         0.0100272 , 0.0099842 , 0.00992241, 0.00999666, 0.01010406,\n","         0.01003424, 0.01007331, 0.00998447, 0.01006163, 0.01001534,\n","         0.01002558, 0.01001136, 0.00996027, 0.01002873, 0.00998614,\n","         0.00994306, 0.00991802, 0.00999306, 0.01007131, 0.00993621],\n","        [0.00999667, 0.01007533, 0.01001235, 0.01001475, 0.01000966,\n","         0.00993524, 0.01000126, 0.01002243, 0.00998209, 0.01003439,\n","         0.00993377, 0.01004536, 0.00992766, 0.00999938, 0.01007613,\n","         0.00999793, 0.01002236, 0.01000907, 0.01003942, 0.01000091,\n","         0.00998044, 0.01010887, 0.01001723, 0.01001701, 0.00994122,\n","         0.01003896, 0.00999957, 0.00997346, 0.00995922, 0.00995406,\n","         0.00998778, 0.01000895, 0.00998556, 0.00998854, 0.00997753,\n","         0.00992756, 0.01001514, 0.00987235, 0.0100073 , 0.0099441 ,\n","         0.01007319, 0.01002041, 0.01002607, 0.01004561, 0.00999585,\n","         0.00997337, 0.00995853, 0.01001377, 0.00999805, 0.00992861,\n","         0.01001506, 0.01004668, 0.00998456, 0.01002071, 0.01001929,\n","         0.01001216, 0.01007325, 0.00998315, 0.01006643, 0.01000668,\n","         0.00995802, 0.01000397, 0.0100005 , 0.0100984 , 0.00993742,\n","         0.00994602, 0.01002229, 0.00998237, 0.00994966, 0.00997056,\n","         0.00998505, 0.01003885, 0.01003058, 0.0099303 , 0.00997102,\n","         0.01003146, 0.01000849, 0.00995759, 0.01002246, 0.01003323,\n","         0.01000464, 0.00999634, 0.00993494, 0.01002788, 0.01008289,\n","         0.01003044, 0.01004772, 0.00997565, 0.01004458, 0.01003153,\n","         0.01003094, 0.00995577, 0.00997959, 0.01001367, 0.00999075,\n","         0.00995283, 0.00993007, 0.00998711, 0.01005779, 0.00994417]]],\n","      dtype=float32)>"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"Zyg7N6F3KSgX"},"source":["### Decoder for inference (prediction)\n","\n","Contrary to the training case, for inference we do not have access to the target nor the padded target. The decoder input will be made out of a sequence starting with $0$ which is the special start token in our case, then followed by the predictions of the decoder as they come."]},{"cell_type":"code","metadata":{"id":"AgnWHaCFKzm-","executionInfo":{"status":"ok","timestamp":1633610977486,"user_tz":-120,"elapsed":16,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"}}},"source":["decoder_state_input_h = Input(shape=(n_lstm,))\n","decoder_state_input_c = Input(shape=(n_lstm,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","# at the first step of the inference, these input will be respectively the\n","# hidden state and C state of the encoder model\n","# for following steps, they will become the hidden and C state from the decoder\n","# itself since the input sequence is unknown we will have to predict step by step\n","# using a loop\n","\n","decoder_input_inf = tf.keras.Input(shape=(1))\n","decoder_embed_output = decoder_embed(decoder_input_inf)\n","# the decoder input here is of shape 1 because we will feed the elements in the \n","# sequence one by one\n","\n","decoder_outputs, state_h, state_c = decoder_lstm(decoder_embed_output, initial_state=decoder_states_inputs)\n","# the lstm layer works in the same way, the output from the embedding is used\n","# and the decoder state is used as described above\n","\n","decoder_states = [state_h, state_c]\n","# we store the lstm states in a specific object as we'll have to use them as \n","# initial state for the next inference step\n","\n","decoder_outputs = decoder_pred(decoder_outputs)\n","# the lstm output is then converted to a probability distribution over the\n","# target vocabulary\n","\n","decoder_inf = Model(inputs = [decoder_input_inf, decoder_states_inputs], \n","                     outputs = [decoder_outputs, decoder_states])\n","# Finally we wrap up the model building by setting up the inputs and outputs"],"execution_count":46,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r3XHFd6YdgXQ"},"source":["Here we'll give you an example of how this version of the model will be able to give predictions, we'lls need to write a loop for this!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5JS5yQyxd107","executionInfo":{"status":"ok","timestamp":1633610977487,"user_tz":-120,"elapsed":15,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"}},"outputId":"83db9d6b-866f-4949-9568-0b256cb95618"},"source":["enc_input = tf.expand_dims(X_train[0],0)\n","#classic encoder input\n","\n","dec_input = tf.zeros(shape=(1,1))\n","# the first decoder input is the special token 0\n","\n","enc_out, state_h_inf, state_c_inf = encoder(enc_input)\n","# we compute once and for all the encoder output and the encoder\n","# h state and c state\n","\n","dec_state = [state_h_inf, state_c_inf]\n","# The encoder h state and c state will serve as initial states for the\n","# decoder\n","\n","pred = []  # we'll store the predictions in here\n","\n","# we loop over the expected length of the target, but actually the loop can run\n","# for as many steps as we wish, which is the advantage of the encoder decoder\n","# architecture\n","for i in range(target_seq_len):\n","  dec_out, dec_state = decoder_inf([dec_input, dec_state])\n","  # the decoder state is updated and we get the first prediction probability \n","  # vector\n","  decoded_out = tf.argmax(dec_out, axis=-1)\n","  # we decode the softmax vector into and index\n","  pred.append(decoded_out) # update the prediction list\n","  dec_input = decoded_out # the previous pred will be used as the new input\n","\n","pred"],"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[41]])>,\n"," <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[41]])>,\n"," <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[41]])>,\n"," <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[41]])>,\n"," <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[41]])>]"]},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","metadata":{"id":"zBbC19IPxGju"},"source":["## Training the encoder decoder model\n","\n","We are almost there, the difficult part of this was building the model, now the training step will be super easy!\n","All we have to do is first `compile` the model to assign a loss function then use the `fit` method!"]},{"cell_type":"code","metadata":{"id":"8X6jktGKyIok","executionInfo":{"status":"ok","timestamp":1633610977488,"user_tz":-120,"elapsed":6,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"}}},"source":["decoder.compile(\n","    optimizer=\"Adam\",\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",")"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XBKz1jT-xTA3","executionInfo":{"status":"ok","timestamp":1633611154025,"user_tz":-120,"elapsed":176142,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"}},"outputId":"1a87a041-0050-4050-9e13-df005fab81d3"},"source":["decoder.fit(x=[X_train,padded_y_train],y=y_train,epochs=50, validation_data=([X_val,padded_y_val],y_val))"],"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","313/313 [==============================] - 7s 13ms/step - loss: 4.5114 - sparse_categorical_accuracy: 0.0239 - val_loss: 4.3861 - val_sparse_categorical_accuracy: 0.0369\n","Epoch 2/50\n","313/313 [==============================] - 3s 11ms/step - loss: 4.2568 - sparse_categorical_accuracy: 0.0527 - val_loss: 4.1501 - val_sparse_categorical_accuracy: 0.0650\n","Epoch 3/50\n","313/313 [==============================] - 3s 11ms/step - loss: 4.0558 - sparse_categorical_accuracy: 0.0784 - val_loss: 4.0003 - val_sparse_categorical_accuracy: 0.0847\n","Epoch 4/50\n","313/313 [==============================] - 3s 11ms/step - loss: 3.9040 - sparse_categorical_accuracy: 0.0989 - val_loss: 3.8554 - val_sparse_categorical_accuracy: 0.1053\n","Epoch 5/50\n","313/313 [==============================] - 3s 11ms/step - loss: 3.7498 - sparse_categorical_accuracy: 0.1232 - val_loss: 3.7129 - val_sparse_categorical_accuracy: 0.1236\n","Epoch 6/50\n","313/313 [==============================] - 3s 11ms/step - loss: 3.6051 - sparse_categorical_accuracy: 0.1459 - val_loss: 3.5746 - val_sparse_categorical_accuracy: 0.1460\n","Epoch 7/50\n","313/313 [==============================] - 3s 11ms/step - loss: 3.4643 - sparse_categorical_accuracy: 0.1675 - val_loss: 3.4324 - val_sparse_categorical_accuracy: 0.1707\n","Epoch 8/50\n","313/313 [==============================] - 3s 11ms/step - loss: 3.3196 - sparse_categorical_accuracy: 0.1950 - val_loss: 3.2843 - val_sparse_categorical_accuracy: 0.1962\n","Epoch 9/50\n","313/313 [==============================] - 3s 11ms/step - loss: 3.1705 - sparse_categorical_accuracy: 0.2241 - val_loss: 3.1426 - val_sparse_categorical_accuracy: 0.2252\n","Epoch 10/50\n","313/313 [==============================] - 3s 11ms/step - loss: 3.0159 - sparse_categorical_accuracy: 0.2585 - val_loss: 2.9885 - val_sparse_categorical_accuracy: 0.2599\n","Epoch 11/50\n","313/313 [==============================] - 3s 11ms/step - loss: 2.8644 - sparse_categorical_accuracy: 0.2906 - val_loss: 2.8394 - val_sparse_categorical_accuracy: 0.2893\n","Epoch 12/50\n","313/313 [==============================] - 3s 11ms/step - loss: 2.7182 - sparse_categorical_accuracy: 0.3223 - val_loss: 2.6988 - val_sparse_categorical_accuracy: 0.3220\n","Epoch 13/50\n","313/313 [==============================] - 3s 11ms/step - loss: 2.5845 - sparse_categorical_accuracy: 0.3537 - val_loss: 2.5593 - val_sparse_categorical_accuracy: 0.3533\n","Epoch 14/50\n","313/313 [==============================] - 3s 11ms/step - loss: 2.4625 - sparse_categorical_accuracy: 0.3783 - val_loss: 2.4436 - val_sparse_categorical_accuracy: 0.3787\n","Epoch 15/50\n","313/313 [==============================] - 3s 11ms/step - loss: 2.3460 - sparse_categorical_accuracy: 0.4040 - val_loss: 2.3426 - val_sparse_categorical_accuracy: 0.4002\n","Epoch 16/50\n","313/313 [==============================] - 3s 11ms/step - loss: 2.2443 - sparse_categorical_accuracy: 0.4256 - val_loss: 2.2308 - val_sparse_categorical_accuracy: 0.4265\n","Epoch 17/50\n","313/313 [==============================] - 4s 11ms/step - loss: 2.1406 - sparse_categorical_accuracy: 0.4484 - val_loss: 2.1279 - val_sparse_categorical_accuracy: 0.4505\n","Epoch 18/50\n","313/313 [==============================] - 3s 11ms/step - loss: 2.0435 - sparse_categorical_accuracy: 0.4720 - val_loss: 2.0489 - val_sparse_categorical_accuracy: 0.4612\n","Epoch 19/50\n","313/313 [==============================] - 3s 11ms/step - loss: 1.9587 - sparse_categorical_accuracy: 0.4902 - val_loss: 1.9578 - val_sparse_categorical_accuracy: 0.4837\n","Epoch 20/50\n","313/313 [==============================] - 3s 11ms/step - loss: 1.8740 - sparse_categorical_accuracy: 0.5093 - val_loss: 1.8964 - val_sparse_categorical_accuracy: 0.4919\n","Epoch 21/50\n","313/313 [==============================] - 3s 11ms/step - loss: 1.7974 - sparse_categorical_accuracy: 0.5297 - val_loss: 1.8071 - val_sparse_categorical_accuracy: 0.5216\n","Epoch 22/50\n","313/313 [==============================] - 3s 11ms/step - loss: 1.7259 - sparse_categorical_accuracy: 0.5453 - val_loss: 1.7668 - val_sparse_categorical_accuracy: 0.5236\n","Epoch 23/50\n","313/313 [==============================] - 3s 11ms/step - loss: 1.6589 - sparse_categorical_accuracy: 0.5618 - val_loss: 1.6718 - val_sparse_categorical_accuracy: 0.5497\n","Epoch 24/50\n","313/313 [==============================] - 4s 11ms/step - loss: 1.5903 - sparse_categorical_accuracy: 0.5784 - val_loss: 1.6122 - val_sparse_categorical_accuracy: 0.5693\n","Epoch 25/50\n","313/313 [==============================] - 3s 11ms/step - loss: 1.5330 - sparse_categorical_accuracy: 0.5922 - val_loss: 1.5587 - val_sparse_categorical_accuracy: 0.5765\n","Epoch 26/50\n","313/313 [==============================] - 3s 11ms/step - loss: 1.4819 - sparse_categorical_accuracy: 0.6026 - val_loss: 1.4880 - val_sparse_categorical_accuracy: 0.5966\n","Epoch 27/50\n","313/313 [==============================] - 4s 11ms/step - loss: 1.4189 - sparse_categorical_accuracy: 0.6220 - val_loss: 1.4347 - val_sparse_categorical_accuracy: 0.6158\n","Epoch 28/50\n","313/313 [==============================] - 3s 11ms/step - loss: 1.3767 - sparse_categorical_accuracy: 0.6327 - val_loss: 1.4290 - val_sparse_categorical_accuracy: 0.6070\n","Epoch 29/50\n","313/313 [==============================] - 3s 11ms/step - loss: 1.3247 - sparse_categorical_accuracy: 0.6453 - val_loss: 1.3949 - val_sparse_categorical_accuracy: 0.6186\n","Epoch 30/50\n","313/313 [==============================] - 3s 11ms/step - loss: 1.2862 - sparse_categorical_accuracy: 0.6578 - val_loss: 1.3060 - val_sparse_categorical_accuracy: 0.6480\n","Epoch 31/50\n","313/313 [==============================] - 3s 11ms/step - loss: 1.2440 - sparse_categorical_accuracy: 0.6673 - val_loss: 1.3134 - val_sparse_categorical_accuracy: 0.6379\n","Epoch 32/50\n","313/313 [==============================] - 3s 11ms/step - loss: 1.2044 - sparse_categorical_accuracy: 0.6788 - val_loss: 1.2472 - val_sparse_categorical_accuracy: 0.6616\n","Epoch 33/50\n","313/313 [==============================] - 3s 11ms/step - loss: 1.1611 - sparse_categorical_accuracy: 0.6907 - val_loss: 1.2287 - val_sparse_categorical_accuracy: 0.6619\n","Epoch 34/50\n","313/313 [==============================] - 3s 11ms/step - loss: 1.1335 - sparse_categorical_accuracy: 0.6963 - val_loss: 1.1671 - val_sparse_categorical_accuracy: 0.6850\n","Epoch 35/50\n","313/313 [==============================] - 3s 11ms/step - loss: 1.0943 - sparse_categorical_accuracy: 0.7105 - val_loss: 1.1764 - val_sparse_categorical_accuracy: 0.6776\n","Epoch 36/50\n","313/313 [==============================] - 3s 11ms/step - loss: 1.0617 - sparse_categorical_accuracy: 0.7179 - val_loss: 1.1178 - val_sparse_categorical_accuracy: 0.6929\n","Epoch 37/50\n","313/313 [==============================] - 4s 11ms/step - loss: 1.0372 - sparse_categorical_accuracy: 0.7234 - val_loss: 1.0728 - val_sparse_categorical_accuracy: 0.7092\n","Epoch 38/50\n","313/313 [==============================] - 3s 11ms/step - loss: 1.0077 - sparse_categorical_accuracy: 0.7306 - val_loss: 1.1114 - val_sparse_categorical_accuracy: 0.6914\n","Epoch 39/50\n","313/313 [==============================] - 3s 11ms/step - loss: 0.9790 - sparse_categorical_accuracy: 0.7394 - val_loss: 1.0377 - val_sparse_categorical_accuracy: 0.7150\n","Epoch 40/50\n","313/313 [==============================] - 4s 11ms/step - loss: 0.9536 - sparse_categorical_accuracy: 0.7469 - val_loss: 1.0254 - val_sparse_categorical_accuracy: 0.7166\n","Epoch 41/50\n","313/313 [==============================] - 4s 11ms/step - loss: 0.9391 - sparse_categorical_accuracy: 0.7505 - val_loss: 1.1147 - val_sparse_categorical_accuracy: 0.6810\n","Epoch 42/50\n","313/313 [==============================] - 3s 11ms/step - loss: 0.9073 - sparse_categorical_accuracy: 0.7570 - val_loss: 1.0105 - val_sparse_categorical_accuracy: 0.7165\n","Epoch 43/50\n","313/313 [==============================] - 3s 11ms/step - loss: 0.8795 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.9486 - val_sparse_categorical_accuracy: 0.7388\n","Epoch 44/50\n","313/313 [==============================] - 3s 11ms/step - loss: 0.8586 - sparse_categorical_accuracy: 0.7721 - val_loss: 1.0137 - val_sparse_categorical_accuracy: 0.7136\n","Epoch 45/50\n","313/313 [==============================] - 3s 11ms/step - loss: 0.8468 - sparse_categorical_accuracy: 0.7746 - val_loss: 0.8633 - val_sparse_categorical_accuracy: 0.7640\n","Epoch 46/50\n","313/313 [==============================] - 3s 11ms/step - loss: 0.8244 - sparse_categorical_accuracy: 0.7809 - val_loss: 0.8930 - val_sparse_categorical_accuracy: 0.7546\n","Epoch 47/50\n","313/313 [==============================] - 3s 11ms/step - loss: 0.8082 - sparse_categorical_accuracy: 0.7827 - val_loss: 0.9044 - val_sparse_categorical_accuracy: 0.7468\n","Epoch 48/50\n","313/313 [==============================] - 3s 11ms/step - loss: 0.7900 - sparse_categorical_accuracy: 0.7908 - val_loss: 0.8248 - val_sparse_categorical_accuracy: 0.7708\n","Epoch 49/50\n","313/313 [==============================] - 3s 11ms/step - loss: 0.7638 - sparse_categorical_accuracy: 0.7973 - val_loss: 0.8520 - val_sparse_categorical_accuracy: 0.7647\n","Epoch 50/50\n","313/313 [==============================] - 4s 11ms/step - loss: 0.7475 - sparse_categorical_accuracy: 0.8006 - val_loss: 0.8069 - val_sparse_categorical_accuracy: 0.7818\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f763cb92ed0>"]},"metadata":{},"execution_count":49}]},{"cell_type":"markdown","metadata":{"id":"JaF316p_02jy"},"source":["Nice! The training is over, and it looks as though we could have continued to train the model even longer since it has not yet started to overfit!"]},{"cell_type":"markdown","metadata":{"id":"l4C6vHoo1NqW"},"source":["## Make predictions with the inference model\n","\n","I don't know if you have noticed, but we used the exact same layers for the training and the inference model, therefore they have the same weights, only we are able to use the inference model on new data since we cannot use teacher forcing anymore!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kgymx0a41s-g","executionInfo":{"status":"ok","timestamp":1633611934800,"user_tz":-120,"elapsed":212,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"}},"outputId":"67ebb9e7-8023-4be4-dba2-fbf15b083c37"},"source":["enc_input = X_val\n","#classic encoder input\n","\n","dec_input = tf.zeros(shape=(len(X_val),1))\n","# the first decoder input is the special token 0\n","\n","enc_out, state_h_inf, state_c_inf = encoder(enc_input)\n","# we compute once and for all the encoder output and the encoder\n","# h state and c state\n","\n","dec_state = [state_h_inf, state_c_inf]\n","# The encoder h state and c state will serve as initial states for the\n","# decoder\n","\n","pred = []  # we'll store the predictions in here\n","\n","# we loop over the expected length of the target, but actually the loop can run\n","# for as many steps as we wish, which is the advantage of the encoder decoder\n","# architecture\n","for i in range(target_seq_len):\n","  dec_out, dec_state = decoder_inf([dec_input, dec_state])\n","  # the decoder state is updated and we get the first prediction probability \n","  # vector\n","  decoded_out = tf.argmax(dec_out, axis=-1)\n","  # we decode the softmax vector into and index\n","  pred.append(decoded_out) # update the prediction list\n","  dec_input = decoded_out # the previous pred will be used as the new input\n","\n","pred = tf.concat(pred, axis=-1).numpy()\n","for i in range(10):\n","  print(\"pred:\", pred[i,:])\n","  print(\"true:\", y_val[i,:])\n","  print(\"\\n\")"],"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["pred: [20 84 70 68 68]\n","true: [20 84 70 68 68]\n","\n","\n","pred: [98 61 55 20 47]\n","true: [98 61 65 66 78]\n","\n","\n","pred: [50 33 63 85 46]\n","true: [50 33 63 28 17]\n","\n","\n","pred: [99 81 58 79 51]\n","true: [12 19 68 70 60]\n","\n","\n","pred: [54 83 22 99 76]\n","true: [54 83 22 24  2]\n","\n","\n","pred: [84  8 34 72 48]\n","true: [84  2 16 83 60]\n","\n","\n","pred: [28 15 54 62 13]\n","true: [82 42 85 68 65]\n","\n","\n","pred: [94 55 34  5 61]\n","true: [94 55 50 28 76]\n","\n","\n","pred: [ 2  3 77 14 22]\n","true: [ 2  3 77 79 54]\n","\n","\n","pred: [37 41 78 93 12]\n","true: [37 45 14 66 30]\n","\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"SN9kGOmC3E57"},"source":["The results do not look so bad, however it looks as though once the model make a mistake on one of the predictions, then the rest of the sequence will also not be well predicted!\n","\n","This behaviour can be explained in the following way: the information taken from the encoder is only taken into account directly in the first decoding step, which means that everything that happens after this step depends on what information the decoder feeds itself from that point onwards.\n","\n","The encoder decoder framework however has made possible major advances, especially in terms of predicting sequences of arbitrary length. However we'll learn tomorrow about a solution that can deal with the \"worsening of predictions over the sequence\" problem!\n","\n","I hope you found this demonstration useful! Now it is time for you to apply what you have learned to a real world automatic translation problem!"]}]}