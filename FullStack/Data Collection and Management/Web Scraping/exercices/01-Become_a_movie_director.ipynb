{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hRObT5dxtgu0"
   },
   "source": [
    "# Become a movie director\n",
    "\n",
    "Let's use Scrapy to get some information about the 250 top rated movies on <a href=\"http://www.imdb.com/\" target=\"_blank\">IMDB</a>.\n",
    "\n",
    "1. Install `Scrapy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "23Mz67dMtgu4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scrapy\n",
      "  Using cached Scrapy-2.5.1-py2.py3-none-any.whl (254 kB)\n",
      "Collecting zope.interface>=4.1.3\n",
      "  Using cached zope.interface-5.4.0-cp38-cp38-manylinux2010_x86_64.whl (259 kB)\n",
      "Collecting h2<4.0,>=3.0\n",
      "  Using cached h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "Collecting parsel>=1.5.0\n",
      "  Using cached parsel-1.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Processing /home/jovyan/.cache/pip/wheels/91/64/36/bd0d11306cb22a78c7f53d603c7eb74ebb6c211703bc40b686/Protego-0.1.16-py3-none-any.whl\n",
      "Collecting Twisted[http2]>=17.9.0\n",
      "  Using cached Twisted-21.7.0-py3-none-any.whl (3.1 MB)\n",
      "Collecting queuelib>=1.4.2\n",
      "  Using cached queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting lxml>=3.5.0; platform_python_implementation == \"CPython\"\n",
      "  Using cached lxml-4.7.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.9 MB)\n",
      "Collecting cssselect>=0.9.1\n",
      "  Using cached cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: pyOpenSSL>=16.2.0 in /opt/conda/lib/python3.8/site-packages (from scrapy) (19.1.0)\n",
      "Collecting w3lib>=1.17.0\n",
      "  Using cached w3lib-1.22.0-py2.py3-none-any.whl (20 kB)\n",
      "Processing /home/jovyan/.cache/pip/wheels/d1/d7/61/11b5b370ee487d38b5408ecb7e0257db9107fa622412cbe2ff/PyDispatcher-2.0.5-py3-none-any.whl\n",
      "Collecting service-identity>=16.0.0\n",
      "  Using cached service_identity-21.1.0-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: cryptography>=2.0 in /opt/conda/lib/python3.8/site-packages (from scrapy) (3.1.1)\n",
      "Collecting itemloaders>=1.0.1\n",
      "  Using cached itemloaders-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting itemadapter>=0.1.0\n",
      "  Using cached itemadapter-0.4.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from zope.interface>=4.1.3->scrapy) (49.6.0.post20201009)\n",
      "Collecting hyperframe<6,>=5.2.0\n",
      "  Using cached hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting hpack<4,>=3.0\n",
      "  Using cached hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: six>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from parsel>=1.5.0->scrapy) (1.15.0)\n",
      "Collecting Automat>=0.8.0\n",
      "  Using cached Automat-20.2.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /opt/conda/lib/python3.8/site-packages (from Twisted[http2]>=17.9.0->scrapy) (3.7.4.2)\n",
      "Collecting hyperlink>=17.1.1\n",
      "  Using cached hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
      "Collecting incremental>=21.3.0\n",
      "  Using cached incremental-21.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting constantly>=15.1\n",
      "  Using cached constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.8/site-packages (from Twisted[http2]>=17.9.0->scrapy) (20.2.0)\n",
      "Collecting priority<2.0,>=1.1.0; extra == \"http2\"\n",
      "  Using cached priority-1.3.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pyasn1\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting pyasn1-modules\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /opt/conda/lib/python3.8/site-packages (from cryptography>=2.0->scrapy) (1.14.3)\n",
      "Collecting jmespath>=0.9.5\n",
      "  Using cached jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: idna>=2.5 in /opt/conda/lib/python3.8/site-packages (from hyperlink>=17.1.1->Twisted[http2]>=17.9.0->scrapy) (2.10)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.0->scrapy) (2.20)\n",
      "Installing collected packages: zope.interface, hyperframe, hpack, h2, cssselect, w3lib, lxml, parsel, protego, Automat, hyperlink, incremental, constantly, priority, Twisted, queuelib, PyDispatcher, pyasn1, pyasn1-modules, service-identity, jmespath, itemadapter, itemloaders, scrapy\n",
      "Successfully installed Automat-20.2.0 PyDispatcher-2.0.5 Twisted-21.7.0 constantly-15.1.0 cssselect-1.1.0 h2-3.2.0 hpack-3.0.0 hyperframe-5.2.0 hyperlink-21.0.0 incremental-21.3.0 itemadapter-0.4.0 itemloaders-1.0.4 jmespath-0.10.0 lxml-4.7.1 parsel-1.6.0 priority-1.3.0 protego-0.1.16 pyasn1-0.4.8 pyasn1-modules-0.2.8 queuelib-1.6.2 scrapy-2.5.1 service-identity-21.1.0 w3lib-1.22.0 zope.interface-5.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a folder where you will store the scripts and results of this exercise. Create a file named `imdb1.py` in that folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Start by writing code in the script to:\n",
    "* import os, logging, scrapy, and CrawlerProcess from scrapy.crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create a first spider called `imdb_spider` with:\n",
    "* name `imdb`\n",
    "* start_urls `https://www.imdb.com/chart/top`\n",
    "\n",
    "This spider should scrape the ranking, the title, the url, the crew, the rating and the number of voters for the first movie of the charts.\n",
    "\n",
    "Set up the `CrawlerProcess`.\n",
    "Save the results to a `imdb1.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 16:03:43 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: scrapybot)\n",
      "2022-01-20 16:03:43 [scrapy.utils.log] INFO: Versions: lxml 4.7.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.8.6 | packaged by conda-forge | (default, Oct  7 2020, 19:08:05) - [GCC 7.5.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Linux-5.4.129+-x86_64-with-glibc2.10\n",
      "2022-01-20 16:03:43 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2022-01-20 16:03:43 [scrapy.extensions.telnet] INFO: Telnet Password: 5256ffeb4f1e63c6\n",
      "2022-01-20 16:03:43 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2022-01-20 16:03:43 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2022-01-20 16:03:43 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2022-01-20 16:03:43 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2022-01-20 16:03:43 [scrapy.core.engine] INFO: Spider opened\n",
      "2022-01-20 16:03:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2022-01-20 16:03:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2022-01-20 16:03:44 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2022-01-20 16:03:44 [scrapy.extensions.feedexport] INFO: Stored json feed (1 items) in: 01-Become_a_movie_director/imdb1.json\n",
      "2022-01-20 16:03:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 202,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 545782,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 0.929165,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2022, 1, 20, 16, 3, 44, 506651),\n",
      " 'item_scraped_count': 1,\n",
      " 'log_count/INFO': 11,\n",
      " 'memusage/max': 50864128,\n",
      " 'memusage/startup': 50864128,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2022, 1, 20, 16, 3, 43, 577486)}\n",
      "2022-01-20 16:03:44 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create a new script called `imdb2.py` where you'll scrape the same information for all the movies in the chart!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 16:03:46 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: scrapybot)\n",
      "2022-01-20 16:03:47 [scrapy.utils.log] INFO: Versions: lxml 4.7.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.8.6 | packaged by conda-forge | (default, Oct  7 2020, 19:08:05) - [GCC 7.5.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Linux-5.4.129+-x86_64-with-glibc2.10\n",
      "2022-01-20 16:03:47 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2022-01-20 16:03:47 [scrapy.extensions.telnet] INFO: Telnet Password: 41c33caa114ee041\n",
      "2022-01-20 16:03:47 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2022-01-20 16:03:47 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2022-01-20 16:03:47 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2022-01-20 16:03:47 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2022-01-20 16:03:47 [scrapy.core.engine] INFO: Spider opened\n",
      "2022-01-20 16:03:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2022-01-20 16:03:47 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2022-01-20 16:03:48 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2022-01-20 16:03:48 [scrapy.extensions.feedexport] INFO: Stored json feed (250 items) in: 01-Become_a_movie_director/imdb2.json\n",
      "2022-01-20 16:03:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 202,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 545783,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 1.764881,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2022, 1, 20, 16, 3, 48, 860358),\n",
      " 'item_scraped_count': 250,\n",
      " 'log_count/INFO': 11,\n",
      " 'memusage/max': 51281920,\n",
      " 'memusage/startup': 51281920,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2022, 1, 20, 16, 3, 47, 95477)}\n",
      "2022-01-20 16:03:48 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Based on the results obtained, create a list called `url_list` containing all the urls for the movies in the charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ranking': '\\n      1.\\n      ',\n",
       "  'title': 'The Shawshank Redemption',\n",
       "  'url': '/title/tt0111161/',\n",
       "  'crew': 'Frank Darabont (dir.), Tim Robbins, Morgan Freeman',\n",
       "  'rating': '9.221177810079306',\n",
       "  'nb_voters': '2529631'},\n",
       " {'ranking': '\\n      2.\\n      ',\n",
       "  'title': 'The Godfather',\n",
       "  'url': '/title/tt0068646/',\n",
       "  'crew': 'Francis Ford Coppola (dir.), Marlon Brando, Al Pacino',\n",
       "  'rating': '9.14689710309463',\n",
       "  'nb_voters': '1741538'},\n",
       " {'ranking': '\\n      3.\\n      ',\n",
       "  'title': 'The Godfather: Part II',\n",
       "  'url': '/title/tt0071562/',\n",
       "  'crew': 'Francis Ford Coppola (dir.), Al Pacino, Robert De Niro',\n",
       "  'rating': '8.980975008069025',\n",
       "  'nb_voters': '1208299'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>crew</th>\n",
       "      <th>rating</th>\n",
       "      <th>nb_voters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n      1.\\n</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>/title/tt0111161/</td>\n",
       "      <td>Frank Darabont (dir.), Tim Robbins, Morgan Fre...</td>\n",
       "      <td>9.221177810079306</td>\n",
       "      <td>2529631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n      2.\\n</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>/title/tt0068646/</td>\n",
       "      <td>Francis Ford Coppola (dir.), Marlon Brando, Al...</td>\n",
       "      <td>9.14689710309463</td>\n",
       "      <td>1741538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n      3.\\n</td>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>/title/tt0071562/</td>\n",
       "      <td>Francis Ford Coppola (dir.), Al Pacino, Robert...</td>\n",
       "      <td>8.980975008069025</td>\n",
       "      <td>1208299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n      4.\\n</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>/title/tt0468569/</td>\n",
       "      <td>Christopher Nolan (dir.), Christian Bale, Heat...</td>\n",
       "      <td>8.976474723318388</td>\n",
       "      <td>2480096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n      5.\\n</td>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>/title/tt0050083/</td>\n",
       "      <td>Sidney Lumet (dir.), Henry Fonda, Lee J. Cobb</td>\n",
       "      <td>8.942216792878675</td>\n",
       "      <td>747346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ranking                     title                url  \\\n",
       "0  \\n      1.\\n        The Shawshank Redemption  /title/tt0111161/   \n",
       "1  \\n      2.\\n                   The Godfather  /title/tt0068646/   \n",
       "2  \\n      3.\\n          The Godfather: Part II  /title/tt0071562/   \n",
       "3  \\n      4.\\n                 The Dark Knight  /title/tt0468569/   \n",
       "4  \\n      5.\\n                    12 Angry Men  /title/tt0050083/   \n",
       "\n",
       "                                                crew             rating  \\\n",
       "0  Frank Darabont (dir.), Tim Robbins, Morgan Fre...  9.221177810079306   \n",
       "1  Francis Ford Coppola (dir.), Marlon Brando, Al...   9.14689710309463   \n",
       "2  Francis Ford Coppola (dir.), Al Pacino, Robert...  8.980975008069025   \n",
       "3  Christopher Nolan (dir.), Christian Bale, Heat...  8.976474723318388   \n",
       "4      Sidney Lumet (dir.), Henry Fonda, Lee J. Cobb  8.942216792878675   \n",
       "\n",
       "  nb_voters  \n",
       "0   2529631  \n",
       "1   1741538  \n",
       "2   1208299  \n",
       "3   2480096  \n",
       "4    747346  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url list: ['https://www.imdb.com/title/tt0111161/', 'https://www.imdb.com/title/tt0068646/', 'https://www.imdb.com/title/tt0071562/']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Store the list of urls to a file called `url_list.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Scrape all the pages from the movies in the charts and extract the complete cast, the Storyline, and the tags, also save the title and url for future joins purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 17:50:42 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: scrapybot)\n",
      "2022-01-20 17:50:42 [scrapy.utils.log] INFO: Versions: lxml 4.7.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.8.6 | packaged by conda-forge | (default, Oct  7 2020, 19:08:05) - [GCC 7.5.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Linux-5.4.129+-x86_64-with-glibc2.10\n",
      "2022-01-20 17:50:42 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2022-01-20 17:50:42 [scrapy.extensions.telnet] INFO: Telnet Password: da17500a43b1594c\n",
      "2022-01-20 17:50:42 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2022-01-20 17:50:42 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2022-01-20 17:50:42 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2022-01-20 17:50:42 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2022-01-20 17:50:42 [scrapy.core.engine] INFO: Spider opened\n",
      "2022-01-20 17:50:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2022-01-20 17:50:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2022-01-20 17:51:15 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2022-01-20 17:51:15 [scrapy.extensions.feedexport] INFO: Stored json feed (250 items) in: 01-Become_a_movie_director/imdb3.json\n",
      "2022-01-20 17:51:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 52254,\n",
      " 'downloader/request_count': 250,\n",
      " 'downloader/request_method_count/GET': 250,\n",
      " 'downloader/response_bytes': 34305622,\n",
      " 'downloader/response_count': 250,\n",
      " 'downloader/response_status_count/200': 250,\n",
      " 'elapsed_time_seconds': 33.297829,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2022, 1, 20, 17, 51, 15, 879160),\n",
      " 'httpcompression/response_bytes': 206801118,\n",
      " 'httpcompression/response_count': 250,\n",
      " 'item_scraped_count': 250,\n",
      " 'log_count/INFO': 11,\n",
      " 'memusage/max': 64561152,\n",
      " 'memusage/startup': 64561152,\n",
      " 'response_received_count': 250,\n",
      " 'scheduler/dequeued': 250,\n",
      " 'scheduler/dequeued/memory': 250,\n",
      " 'scheduler/enqueued': 250,\n",
      " 'scheduler/enqueued/memory': 250,\n",
      " 'start_time': datetime.datetime(2022, 1, 20, 17, 50, 42, 581331)}\n",
      "2022-01-20 17:51:15 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pay attention to inconsistencies between pages"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "02-Become_movie_director_solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
