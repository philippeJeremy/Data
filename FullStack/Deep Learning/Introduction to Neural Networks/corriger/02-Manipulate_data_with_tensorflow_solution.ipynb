{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02-Manipulate_data_with_tensorflow_solution","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNDuPARF9o1GwgvFVWiwjHa"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ZNW5K_m7t8Tu"},"source":["# Manipulate data with tensorflow\r\n","\r\n","In this exercise you will practice manipulating tensors and forming tensor datasets with tensorflow.\r\n","We are taking advantage of this moment to let you only manipulate data as we will be focusing much more on building models in the following days!"]},{"cell_type":"code","metadata":{"id":"Awl5S3siIE2I","executionInfo":{"status":"ok","timestamp":1612896570307,"user_tz":-60,"elapsed":2734,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"}}},"source":["import tensorflow as tf"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"be1UHQRtufib"},"source":["## Practice tensor operations\r\n","\r\n","* Create a constant tensor named `tensor1` containing the values `[0,1,2,3,4,5,6,7]` and a variable tensor named `tensor2` containing the values `[0,1,2,0,1,2]`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bC8EkoJRt1YT","executionInfo":{"status":"ok","timestamp":1612897222043,"user_tz":-60,"elapsed":511,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"}},"outputId":"85adb7e2-08d2-4c81-9201-51fef55f8c2e"},"source":["tensor1 = tf.constant([0,1,2,3,4,5,6,7])\r\n","tensor2 = tf.Variable([0,1,2,0,1,2])\r\n","print('tensor1:', tensor1)\r\n","print('tensor2:', tensor2)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["tensor1: tf.Tensor([0 1 2 3 4 5 6 7], shape=(8,), dtype=int32)\n","tensor2: <tf.Variable 'Variable:0' shape=(6,) dtype=int32, numpy=array([0, 1, 2, 0, 1, 2], dtype=int32)>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8kZZuF9FIRPp"},"source":["* Reshape `tensor1` so it has 2 columns and 4 rows, and `tensor2` so it has 2 rows and 3 columns.\r\n","Has this operation changed the nature of `tensor2`? How could you change it back to its former nature?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"weoWXp-tIQB9","executionInfo":{"status":"ok","timestamp":1612897222894,"user_tz":-60,"elapsed":479,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"}},"outputId":"bedcb95d-d945-477f-cacb-20f072cb4cdf"},"source":["tensor1 = tf.reshape(tensor1, [4,2])\r\n","tensor2 = tf.reshape(tensor2, [2,3])\r\n","print('tensor1:', tensor1)\r\n","print('tensor2:', tensor2)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["tensor1: tf.Tensor(\n","[[0 1]\n"," [2 3]\n"," [4 5]\n"," [6 7]], shape=(4, 2), dtype=int32)\n","tensor2: tf.Tensor(\n","[[0 1 2]\n"," [0 1 2]], shape=(2, 3), dtype=int32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LM5T5YDFKPKy","executionInfo":{"status":"ok","timestamp":1612897223357,"user_tz":-60,"elapsed":549,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"}},"outputId":"11f6e868-c254-4dd9-c34c-9493e3b4a978"},"source":["tensor2 = tf.Variable(tensor2)\r\n","print('tensor2:', tensor2)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["tensor2: <tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n","array([[0, 1, 2],\n","       [0, 1, 2]], dtype=int32)>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"A9t1o_2FI8gM"},"source":["* Use a tensorflow function to create `tensor3` with the same shape as `tensor2` but filled with 1"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gfdyLooDJMmI","executionInfo":{"status":"ok","timestamp":1612897224389,"user_tz":-60,"elapsed":486,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"}},"outputId":"087430fe-5ab6-4092-ae56-0cfd368bee34"},"source":["tensor3 = tf.ones_like(tensor2)\r\n","print('tensor3', tensor3)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["tensor3 tf.Tensor(\n","[[1 1 1]\n"," [1 1 1]], shape=(2, 3), dtype=int32)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"D-cHLAq6JYB8"},"source":["* Modify the value of `tensor2` by substracting the values in `tensor3`, use a method so that it is an in place operation. Why would not you be able to do that with `tensor1`?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_fHJJyasJqXw","executionInfo":{"status":"ok","timestamp":1612897225660,"user_tz":-60,"elapsed":450,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"}},"outputId":"3b7011cb-ed10-46ef-cf2b-7cbef72aca95"},"source":["tensor2.assign_sub(tensor3)\r\n","# we cannot do that with tensor1 because it is a constant tensor which is immutable"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=int32, numpy=\n","array([[-1,  0,  1],\n","       [-1,  0,  1]], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"f0CzXqjyKqpF"},"source":["* Can you multiply `tensor1` and `tensor2` pointwise? How about with a matrix multiplication? Display the result of the possible operations."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":225},"id":"wBDmBeOIKlw1","executionInfo":{"status":"error","timestamp":1612897307795,"user_tz":-60,"elapsed":482,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"}},"outputId":"823a1d9b-9a1a-4837-e118-706980d3dee4"},"source":["tensor1*tensor2"],"execution_count":16,"outputs":[{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-2b70bcf24124>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensor1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtensor2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    516\u001b[0m   \"\"\"\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6066\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6067\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6068\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6069\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6070\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [4,2] vs. [2,3] [Op:Mul]"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nR_srVWnK927","executionInfo":{"status":"ok","timestamp":1612897336366,"user_tz":-60,"elapsed":583,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"}},"outputId":"9c355366-22ab-4734-e2d2-f8450da65a89"},"source":["tf.matmul(tensor1,tensor2)"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(4, 3), dtype=int32, numpy=\n","array([[ -1,   0,   1],\n","       [ -5,   0,   5],\n","       [ -9,   0,   9],\n","       [-13,   0,  13]], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"l_Flhy7uLS7w"},"source":["## Tabular data\r\n","\r\n","This part of the exercise will let you deal with tabular data in order to make batch datasets ready to be fed to deep learning models.\r\n","\r\n","* Using the `sklearn.datasets` module, load the mnist dataset thanks to the `load_digits` function."]},{"cell_type":"code","metadata":{"id":"e3VytM5ALuCo","executionInfo":{"status":"ok","timestamp":1612897584772,"user_tz":-60,"elapsed":486,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"}}},"source":["from sklearn.datasets import load_digits\r\n","digits = load_digits()"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EO54ZELkMDnI"},"source":["* This function gives you a Data Bunch object, which works basically like a dictionnary. Create an object data containing the value of the `data` key and an object target containing the value of the `target` key."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oE8RzXi6MBOk","executionInfo":{"status":"ok","timestamp":1612897864273,"user_tz":-60,"elapsed":489,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"}},"outputId":"797631be-0376-4c2e-8cc1-0c0f3277a782"},"source":["data = digits.data\r\n","target = digits.target\r\n","print('data:', data)\r\n","print('target:', target)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["data: [[ 0.  0.  5. ...  0.  0.  0.]\n"," [ 0.  0.  0. ... 10.  0.  0.]\n"," [ 0.  0.  0. ... 16.  9.  0.]\n"," ...\n"," [ 0.  0.  1. ...  6.  0.  0.]\n"," [ 0.  0.  2. ... 12.  0.  0.]\n"," [ 0.  0. 10. ... 12.  1.  0.]]\n","target: [0 1 2 ... 8 9 8]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RoyvPr2sNGxt"},"source":["* What is the shape of `data` and `target`? Can you understand what these objects represent using the `DESCR` key of the Data Bunch?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kOGvg9jcNV5N","executionInfo":{"status":"ok","timestamp":1612898158861,"user_tz":-60,"elapsed":397,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"}},"outputId":"ead6defd-6ec9-4e25-c384-8bc581549fb3"},"source":["print('data shape:', data.shape)\r\n","print('target shape', target.shape)\r\n","print(digits.DESCR)\r\n","\r\n","# data represents the images of handwritten digits in flattened mode, the 8x8 \r\n","# images are represented by 64 columns on each row of the object data"],"execution_count":24,"outputs":[{"output_type":"stream","text":["data shape: (1797, 64)\n","target shape (1797,)\n",".. _digits_dataset:\n","\n","Optical recognition of handwritten digits dataset\n","--------------------------------------------------\n","\n","**Data Set Characteristics:**\n","\n","    :Number of Instances: 5620\n","    :Number of Attributes: 64\n","    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n","    :Missing Attribute Values: None\n","    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n","    :Date: July; 1998\n","\n","This is a copy of the test set of the UCI ML hand-written digits datasets\n","https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n","\n","The data set contains images of hand-written digits: 10 classes where\n","each class refers to a digit.\n","\n","Preprocessing programs made available by NIST were used to extract\n","normalized bitmaps of handwritten digits from a preprinted form. From a\n","total of 43 people, 30 contributed to the training set and different 13\n","to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n","4x4 and the number of on pixels are counted in each block. This generates\n","an input matrix of 8x8 where each element is an integer in the range\n","0..16. This reduces dimensionality and gives invariance to small\n","distortions.\n","\n","For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n","T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n","L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n","1994.\n","\n",".. topic:: References\n","\n","  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n","    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n","    Graduate Studies in Science and Engineering, Bogazici University.\n","  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n","  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n","    Linear dimensionalityreduction using relevance weighted LDA. School of\n","    Electrical and Electronic Engineering Nanyang Technological University.\n","    2005.\n","  - Claudio Gentile. A New Approximate Maximal Margin Classification\n","    Algorithm. NIPS. 2000.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LgrbbCLSORpb"},"source":["* Can you visualize the first image in data ?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"Fo0OnrB2OMcz","executionInfo":{"status":"ok","timestamp":1612900491459,"user_tz":-60,"elapsed":1340,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"}},"outputId":"9167eafa-3071-4c07-db8b-5ab7b0e1f52c"},"source":["from plotly import express as px\r\n","first_image = data[0,:].reshape([8,8])\r\n","px.imshow(first_image,  color_continuous_scale='gray')"],"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"6fe62c0f-7ded-4a43-a491-116a92d75da5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"6fe62c0f-7ded-4a43-a491-116a92d75da5\")) {\n","                    Plotly.newPlot(\n","                        '6fe62c0f-7ded-4a43-a491-116a92d75da5',\n","                        [{\"coloraxis\": \"coloraxis\", \"type\": \"heatmap\", \"z\": [[0.0, 0.0, 5.0, 13.0, 9.0, 1.0, 0.0, 0.0], [0.0, 0.0, 13.0, 15.0, 10.0, 15.0, 5.0, 0.0], [0.0, 3.0, 15.0, 2.0, 0.0, 11.0, 8.0, 0.0], [0.0, 4.0, 12.0, 0.0, 0.0, 8.0, 8.0, 0.0], [0.0, 5.0, 8.0, 0.0, 0.0, 9.0, 8.0, 0.0], [0.0, 4.0, 11.0, 0.0, 1.0, 12.0, 7.0, 0.0], [0.0, 2.0, 14.0, 5.0, 10.0, 12.0, 0.0, 0.0], [0.0, 0.0, 6.0, 13.0, 10.0, 0.0, 0.0, 0.0]]}],\n","                        {\"coloraxis\": {\"colorscale\": [[0.0, \"rgb(0, 0, 0)\"], [0.09090909090909091, \"rgb(16, 16, 16)\"], [0.18181818181818182, \"rgb(38, 38, 38)\"], [0.2727272727272727, \"rgb(59, 59, 59)\"], [0.36363636363636365, \"rgb(81, 80, 80)\"], [0.45454545454545453, \"rgb(102, 101, 101)\"], [0.5454545454545454, \"rgb(124, 123, 122)\"], [0.6363636363636364, \"rgb(146, 146, 145)\"], [0.7272727272727273, \"rgb(171, 171, 170)\"], [0.8181818181818182, \"rgb(197, 197, 195)\"], [0.9090909090909091, \"rgb(224, 224, 223)\"], [1.0, \"rgb(254, 254, 253)\"]]}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"constrain\": \"domain\", \"scaleanchor\": \"y\"}, \"yaxis\": {\"autorange\": \"reversed\", \"constrain\": \"domain\"}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('6fe62c0f-7ded-4a43-a491-116a92d75da5');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"x3TwGhRPacK0"},"source":["* The pixel values from those images is encoded in integers between 0 and 255, it is always better to feed your deep learning models with reasonnably scaled data to avoid the network not being able to learn. To do this we'll divide the value in each pixel by 255. Do this."]},{"cell_type":"code","metadata":{"id":"zazDEYPiaak8","executionInfo":{"status":"ok","timestamp":1612901484291,"user_tz":-60,"elapsed":464,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"}}},"source":["data = data/255"],"execution_count":35,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tPVqElsAXHTt"},"source":["### Technique 1: Split the data with sklearn\r\n","\r\n","Most of the time when you will be dealing with data you want to feed to a deap learning model, you will have a pandas DataFrame or numpy array at some points that contains some representation of your data and the associated values of the target variable. In those cases, it's easier to just split the data in a train and validation set using sklearn. (Remember that for very large datasets or for training and evaluating deep learning models we most of the time use the three way hold out method, where on set serves as the training set, one as the validation set to control for overfitting, and the last one is the test set against which we will evaluate the model).\r\n","\r\n","* Split the data and target into three different parts, one containing the train set (60%), another with the validation set (20%), and a third with the test set (20%), using sklearn."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VBPDWY2OXFsd","executionInfo":{"status":"ok","timestamp":1612901485770,"user_tz":-60,"elapsed":445,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"}},"outputId":"65ec13e9-5aa6-42f2-ea4b-b2adc926cac6"},"source":["from sklearn.model_selection import train_test_split\r\n","X_train, X_valtest, y_train, y_valtest = train_test_split(data,target, test_size=0.4)\r\n","X_val, X_test, y_val, y_test = train_test_split(X_valtest, y_valtest, test_size=0.5)\r\n","print(\"X_train\", X_train.shape, \"y_train\", y_train.shape)\r\n","print(\"X_val\", X_val.shape, \"y_val\", y_val.shape)\r\n","print(\"X_test\", X_test.shape, \"y_test\", y_test.shape)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["X_train (1078, 64) y_train (1078,)\n","X_val (359, 64) y_val (359,)\n","X_test (360, 64) y_test (360,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FzugIQTQZOUn"},"source":["* Form three tensor slice datasets using the training validation and test data."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZHWr5HfCZKLb","executionInfo":{"status":"ok","timestamp":1612901487768,"user_tz":-60,"elapsed":480,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"}},"outputId":"d4d79928-4642-4e2d-a07f-2725ef49844d"},"source":["train = tf.data.Dataset.from_tensor_slices((X_train,y_train))\r\n","val = tf.data.Dataset.from_tensor_slices((X_val,y_val))\r\n","test = tf.data.Dataset.from_tensor_slices((X_test,y_test))\r\n","print(\"train:\",train)\r\n","print(\"val:\", val)\r\n","print(\"test:\", test)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["train: <TensorSliceDataset shapes: ((64,), ()), types: (tf.float64, tf.int64)>\n","val: <TensorSliceDataset shapes: ((64,), ()), types: (tf.float64, tf.int64)>\n","test: <TensorSliceDataset shapes: ((64,), ()), types: (tf.float64, tf.int64)>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7ft2lVP5ZraP"},"source":["* Shuffle these tensor slice datasets and arrange them in batches of 8 observations, then display one batch from each of these batch datasets."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r6upGSBPZ6TY","executionInfo":{"status":"ok","timestamp":1612901489996,"user_tz":-60,"elapsed":419,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"}},"outputId":"62c74644-5f9d-4a9a-a4fe-b8d60817a9d4"},"source":["train_batch = train.shuffle(len(X_train)).batch(8)\r\n","val_batch = train.shuffle(len(X_val)).batch(8)\r\n","test_batch = train.shuffle(len(X_test)).batch(8)\r\n","\r\n","print(\"train batch:\", next(iter(train_batch)))\r\n","print(\"val batch:\", next(iter(val_batch)))\r\n","print(\"test batch:\", next(iter(test_batch)))"],"execution_count":38,"outputs":[{"output_type":"stream","text":["train batch: (<tf.Tensor: shape=(8, 64), dtype=float64, numpy=\n","array([[0.        , 0.        , 0.01960784, 0.05882353, 0.05098039,\n","        0.01176471, 0.        , 0.        , 0.        , 0.        ,\n","        0.04705882, 0.05882353, 0.04705882, 0.05490196, 0.        ,\n","        0.        , 0.        , 0.        , 0.04705882, 0.04705882,\n","        0.05490196, 0.05490196, 0.        , 0.        , 0.        ,\n","        0.        , 0.01176471, 0.0627451 , 0.05490196, 0.01176471,\n","        0.        , 0.        , 0.        , 0.        , 0.03529412,\n","        0.05490196, 0.05882353, 0.01176471, 0.        , 0.        ,\n","        0.        , 0.00392157, 0.05882353, 0.01960784, 0.03137255,\n","        0.04705882, 0.00392157, 0.        , 0.        , 0.        ,\n","        0.0627451 , 0.01568627, 0.01568627, 0.0627451 , 0.01568627,\n","        0.        , 0.        , 0.        , 0.01960784, 0.0627451 ,\n","        0.0627451 , 0.04705882, 0.00784314, 0.        ],\n","       [0.        , 0.00392157, 0.04705882, 0.0627451 , 0.03921569,\n","        0.        , 0.        , 0.        , 0.        , 0.02745098,\n","        0.04313725, 0.02745098, 0.05490196, 0.00392157, 0.        ,\n","        0.        , 0.        , 0.00784314, 0.00784314, 0.01176471,\n","        0.05490196, 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.01176471, 0.05490196, 0.02352941, 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.04705882,\n","        0.0627451 , 0.0627451 , 0.02352941, 0.        , 0.        ,\n","        0.        , 0.        , 0.00784314, 0.        , 0.01960784,\n","        0.05882353, 0.02352941, 0.        , 0.        , 0.00392157,\n","        0.04313725, 0.01568627, 0.01568627, 0.05098039, 0.03137255,\n","        0.        , 0.        , 0.00784314, 0.05490196, 0.0627451 ,\n","        0.0627451 , 0.05098039, 0.00392157, 0.        ],\n","       [0.        , 0.        , 0.00784314, 0.05098039, 0.0627451 ,\n","        0.0627451 , 0.02745098, 0.        , 0.        , 0.        ,\n","        0.04705882, 0.05882353, 0.04705882, 0.0627451 , 0.03921569,\n","        0.        , 0.        , 0.        , 0.0627451 , 0.03529412,\n","        0.        , 0.05490196, 0.02352941, 0.        , 0.        ,\n","        0.        , 0.01176471, 0.        , 0.01568627, 0.0627451 ,\n","        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n","        0.03921569, 0.05490196, 0.0627451 , 0.02352941, 0.        ,\n","        0.        , 0.        , 0.01176471, 0.0627451 , 0.0627451 ,\n","        0.04313725, 0.00784314, 0.        , 0.        , 0.        ,\n","        0.        , 0.03529412, 0.05490196, 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.00784314, 0.05882353,\n","        0.02352941, 0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.00784314, 0.0627451 , 0.03921569,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.01568627, 0.0627451 , 0.0627451 , 0.01960784, 0.        ,\n","        0.        , 0.        , 0.        , 0.03137255, 0.0627451 ,\n","        0.0627451 , 0.01176471, 0.        , 0.        , 0.        ,\n","        0.        , 0.03529412, 0.0627451 , 0.0627451 , 0.01176471,\n","        0.        , 0.        , 0.        , 0.        , 0.03137255,\n","        0.0627451 , 0.0627451 , 0.01176471, 0.        , 0.        ,\n","        0.        , 0.        , 0.03137255, 0.0627451 , 0.0627451 ,\n","        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n","        0.01960784, 0.0627451 , 0.05490196, 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.00392157, 0.04705882,\n","        0.0627451 , 0.01176471, 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.03137255, 0.05490196,\n","        0.05882353, 0.02745098, 0.        , 0.        , 0.        ,\n","        0.01568627, 0.0627451 , 0.04705882, 0.05882353, 0.05490196,\n","        0.        , 0.        , 0.        , 0.00392157, 0.00392157,\n","        0.        , 0.04313725, 0.04705882, 0.        , 0.        ,\n","        0.        , 0.00784314, 0.01568627, 0.02352941, 0.05490196,\n","        0.05882353, 0.        , 0.        , 0.01568627, 0.0627451 ,\n","        0.0627451 , 0.0627451 , 0.0627451 , 0.01960784, 0.        ,\n","        0.        , 0.03137255, 0.04705882, 0.02745098, 0.05490196,\n","        0.04705882, 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.01568627, 0.0627451 , 0.01176471, 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.04313725,\n","        0.02745098, 0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.04705882, 0.05490196,\n","        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n","        0.01960784, 0.0627451 , 0.04705882, 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.03921569, 0.05882353,\n","        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.05490196, 0.05882353, 0.03529412, 0.00784314,\n","        0.        , 0.        , 0.        , 0.00392157, 0.0627451 ,\n","        0.05882353, 0.0627451 , 0.05882353, 0.00784314, 0.        ,\n","        0.        , 0.        , 0.05882353, 0.02745098, 0.00392157,\n","        0.04705882, 0.03921569, 0.        , 0.        , 0.        ,\n","        0.03921569, 0.05490196, 0.01568627, 0.05882353, 0.04705882,\n","        0.        , 0.        , 0.        , 0.        , 0.04313725,\n","        0.0627451 , 0.05882353, 0.01960784, 0.        ],\n","       [0.        , 0.        , 0.01176471, 0.05882353, 0.00784314,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.04705882, 0.04705882, 0.00392157, 0.02745098, 0.        ,\n","        0.        , 0.        , 0.00784314, 0.0627451 , 0.01568627,\n","        0.03529412, 0.05098039, 0.        , 0.        , 0.        ,\n","        0.03137255, 0.04313725, 0.02352941, 0.0627451 , 0.00392157,\n","        0.00784314, 0.        , 0.        , 0.04705882, 0.03921569,\n","        0.04705882, 0.05490196, 0.04705882, 0.04313725, 0.        ,\n","        0.        , 0.04313725, 0.0627451 , 0.0627451 , 0.05490196,\n","        0.02745098, 0.00392157, 0.        , 0.        , 0.00392157,\n","        0.02745098, 0.0627451 , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.01960784, 0.0627451 ,\n","        0.00392157, 0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.00784314, 0.04313725, 0.05490196,\n","        0.04705882, 0.01176471, 0.        , 0.        , 0.        ,\n","        0.05490196, 0.05490196, 0.03529412, 0.05882353, 0.03137255,\n","        0.        , 0.        , 0.01960784, 0.04705882, 0.        ,\n","        0.01960784, 0.05882353, 0.00784314, 0.        , 0.        ,\n","        0.01176471, 0.0627451 , 0.04313725, 0.05882353, 0.01176471,\n","        0.        , 0.        , 0.        , 0.        , 0.00392157,\n","        0.05490196, 0.0627451 , 0.01568627, 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.05882353, 0.01960784,\n","        0.05882353, 0.        , 0.        , 0.        , 0.        ,\n","        0.00392157, 0.0627451 , 0.03921569, 0.04313725, 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.05882353,\n","        0.05098039, 0.00784314, 0.        , 0.        ]])>, <tf.Tensor: shape=(8,), dtype=int64, numpy=array([8, 3, 7, 1, 7, 6, 4, 8])>)\n","val batch: (<tf.Tensor: shape=(8, 64), dtype=float64, numpy=\n","array([[0.        , 0.        , 0.03137255, 0.0627451 , 0.04313725,\n","        0.        , 0.        , 0.        , 0.        , 0.00784314,\n","        0.05882353, 0.03137255, 0.0627451 , 0.02745098, 0.        ,\n","        0.        , 0.        , 0.01176471, 0.05098039, 0.00392157,\n","        0.05490196, 0.05098039, 0.        , 0.        , 0.        ,\n","        0.        , 0.03921569, 0.0627451 , 0.0627451 , 0.0627451 ,\n","        0.01176471, 0.        , 0.        , 0.        , 0.        ,\n","        0.00784314, 0.01960784, 0.05882353, 0.01568627, 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.04705882, 0.02352941, 0.        , 0.        , 0.        ,\n","        0.01960784, 0.02352941, 0.01960784, 0.05882353, 0.01568627,\n","        0.        , 0.        , 0.        , 0.02352941, 0.05882353,\n","        0.0627451 , 0.04705882, 0.00392157, 0.        ],\n","       [0.        , 0.        , 0.        , 0.05098039, 0.03137255,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.00784314, 0.05882353, 0.00392157, 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.04313725, 0.03921569,\n","        0.        , 0.03137255, 0.00784314, 0.        , 0.        ,\n","        0.01568627, 0.0627451 , 0.01960784, 0.04313725, 0.0627451 ,\n","        0.03137255, 0.        , 0.        , 0.02745098, 0.0627451 ,\n","        0.0627451 , 0.0627451 , 0.0627451 , 0.01176471, 0.        ,\n","        0.        , 0.00784314, 0.05098039, 0.03529412, 0.0627451 ,\n","        0.04705882, 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.02745098, 0.0627451 , 0.02352941, 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.05098039,\n","        0.05882353, 0.00392157, 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.01176471, 0.0627451 ,\n","        0.03137255, 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.04313725, 0.0627451 , 0.03529412, 0.        ,\n","        0.        , 0.        , 0.01176471, 0.04705882, 0.0627451 ,\n","        0.0627451 , 0.03137255, 0.        , 0.        , 0.        ,\n","        0.05098039, 0.0627451 , 0.03529412, 0.0627451 , 0.03137255,\n","        0.        , 0.        , 0.        , 0.00392157, 0.00784314,\n","        0.        , 0.0627451 , 0.03137255, 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.00784314, 0.0627451 ,\n","        0.01568627, 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.00784314, 0.0627451 , 0.02352941, 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.00392157,\n","        0.0627451 , 0.03529412, 0.        , 0.        ],\n","       [0.        , 0.        , 0.01960784, 0.05098039, 0.05882353,\n","        0.02352941, 0.        , 0.        , 0.        , 0.00784314,\n","        0.0627451 , 0.03529412, 0.0627451 , 0.05098039, 0.        ,\n","        0.        , 0.        , 0.01568627, 0.05490196, 0.        ,\n","        0.03921569, 0.0627451 , 0.00784314, 0.        , 0.        ,\n","        0.01568627, 0.05882353, 0.04313725, 0.05882353, 0.0627451 ,\n","        0.00392157, 0.        , 0.        , 0.        , 0.02745098,\n","        0.03921569, 0.01176471, 0.05098039, 0.03137255, 0.        ,\n","        0.        , 0.        , 0.01176471, 0.        , 0.        ,\n","        0.04705882, 0.01960784, 0.        , 0.        , 0.        ,\n","        0.05098039, 0.04313725, 0.01568627, 0.0627451 , 0.01568627,\n","        0.        , 0.        , 0.        , 0.02745098, 0.05490196,\n","        0.0627451 , 0.04313725, 0.00392157, 0.        ],\n","       [0.        , 0.00784314, 0.05882353, 0.0627451 , 0.02745098,\n","        0.        , 0.        , 0.        , 0.        , 0.03921569,\n","        0.05882353, 0.03921569, 0.0627451 , 0.00784314, 0.        ,\n","        0.        , 0.        , 0.03529412, 0.04313725, 0.01960784,\n","        0.0627451 , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.04705882, 0.04313725, 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.01960784,\n","        0.0627451 , 0.00784314, 0.        , 0.        , 0.        ,\n","        0.        , 0.01176471, 0.05882353, 0.03137255, 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.03137255,\n","        0.05882353, 0.01960784, 0.01960784, 0.03137255, 0.01176471,\n","        0.        , 0.        , 0.01176471, 0.05882353, 0.0627451 ,\n","        0.0627451 , 0.0627451 , 0.03921569, 0.        ],\n","       [0.        , 0.        , 0.02352941, 0.05098039, 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.05882353, 0.04705882, 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.0627451 , 0.02352941,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.01176471, 0.0627451 , 0.05490196, 0.04313725, 0.01960784,\n","        0.        , 0.        , 0.        , 0.01960784, 0.0627451 ,\n","        0.04705882, 0.04313725, 0.0627451 , 0.02352941, 0.        ,\n","        0.        , 0.02352941, 0.0627451 , 0.03529412, 0.00784314,\n","        0.0627451 , 0.03529412, 0.        , 0.        , 0.        ,\n","        0.05098039, 0.05490196, 0.03137255, 0.0627451 , 0.03137255,\n","        0.        , 0.        , 0.        , 0.01568627, 0.05882353,\n","        0.0627451 , 0.05098039, 0.00784314, 0.        ],\n","       [0.        , 0.        , 0.        , 0.05098039, 0.00392157,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.03921569, 0.04705882, 0.00392157, 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.05490196, 0.01176471,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.01568627, 0.05490196, 0.        , 0.01568627, 0.01960784,\n","        0.        , 0.        , 0.        , 0.02745098, 0.0627451 ,\n","        0.01568627, 0.02745098, 0.05490196, 0.02745098, 0.        ,\n","        0.        , 0.01176471, 0.05490196, 0.        , 0.        ,\n","        0.01568627, 0.04705882, 0.        , 0.        , 0.        ,\n","        0.03921569, 0.03921569, 0.01568627, 0.03921569, 0.04705882,\n","        0.        , 0.        , 0.        , 0.00392157, 0.03529412,\n","        0.0627451 , 0.05490196, 0.00784314, 0.        ],\n","       [0.        , 0.        , 0.00392157, 0.05098039, 0.04705882,\n","        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n","        0.03529412, 0.0627451 , 0.0627451 , 0.04705882, 0.        ,\n","        0.        , 0.        , 0.        , 0.05490196, 0.02352941,\n","        0.        , 0.05098039, 0.01176471, 0.        , 0.        ,\n","        0.02352941, 0.03921569, 0.        , 0.        , 0.03921569,\n","        0.02352941, 0.        , 0.        , 0.02745098, 0.05098039,\n","        0.        , 0.        , 0.03529412, 0.03137255, 0.        ,\n","        0.        , 0.01176471, 0.0627451 , 0.00392157, 0.01176471,\n","        0.05490196, 0.02745098, 0.        , 0.        , 0.        ,\n","        0.04313725, 0.0627451 , 0.0627451 , 0.0627451 , 0.00392157,\n","        0.        , 0.        , 0.        , 0.        , 0.04313725,\n","        0.0627451 , 0.02352941, 0.        , 0.        ]])>, <tf.Tensor: shape=(8,), dtype=int64, numpy=array([9, 4, 1, 9, 2, 6, 6, 0])>)\n","test batch: (<tf.Tensor: shape=(8, 64), dtype=float64, numpy=\n","array([[0.        , 0.        , 0.01176471, 0.05882353, 0.05098039,\n","        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n","        0.03921569, 0.0627451 , 0.04705882, 0.05098039, 0.        ,\n","        0.        , 0.        , 0.        , 0.05098039, 0.05098039,\n","        0.03529412, 0.05490196, 0.        , 0.        , 0.        ,\n","        0.        , 0.02352941, 0.05882353, 0.05882353, 0.04313725,\n","        0.        , 0.        , 0.        , 0.        , 0.01568627,\n","        0.0627451 , 0.05490196, 0.00392157, 0.        , 0.        ,\n","        0.        , 0.        , 0.04313725, 0.05490196, 0.05882353,\n","        0.01960784, 0.        , 0.        , 0.        , 0.        ,\n","        0.03529412, 0.03921569, 0.05490196, 0.03529412, 0.        ,\n","        0.        , 0.        , 0.        , 0.01568627, 0.0627451 ,\n","        0.05882353, 0.00784314, 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.01568627, 0.05882353,\n","        0.02745098, 0.        , 0.        , 0.        , 0.        ,\n","        0.01176471, 0.05882353, 0.04705882, 0.        , 0.        ,\n","        0.        , 0.        , 0.00392157, 0.05490196, 0.04705882,\n","        0.        , 0.00784314, 0.04313725, 0.        , 0.        ,\n","        0.03921569, 0.05490196, 0.        , 0.        , 0.05098039,\n","        0.04705882, 0.        , 0.        , 0.04313725, 0.05882353,\n","        0.04705882, 0.05882353, 0.0627451 , 0.01960784, 0.        ,\n","        0.        , 0.01568627, 0.03921569, 0.03137255, 0.0627451 ,\n","        0.04313725, 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.00784314, 0.0627451 , 0.01568627, 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.02352941,\n","        0.05490196, 0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.01176471, 0.05882353, 0.00784314,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.04705882, 0.04705882, 0.00392157, 0.02745098, 0.        ,\n","        0.        , 0.        , 0.00784314, 0.0627451 , 0.01568627,\n","        0.03529412, 0.05098039, 0.        , 0.        , 0.        ,\n","        0.03137255, 0.04313725, 0.02352941, 0.0627451 , 0.00392157,\n","        0.00784314, 0.        , 0.        , 0.04705882, 0.03921569,\n","        0.04705882, 0.05490196, 0.04705882, 0.04313725, 0.        ,\n","        0.        , 0.04313725, 0.0627451 , 0.0627451 , 0.05490196,\n","        0.02745098, 0.00392157, 0.        , 0.        , 0.00392157,\n","        0.02745098, 0.0627451 , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.01960784, 0.0627451 ,\n","        0.00392157, 0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.01568627, 0.04313725, 0.05882353,\n","        0.00784314, 0.        , 0.        , 0.        , 0.00784314,\n","        0.0627451 , 0.03529412, 0.03137255, 0.03529412, 0.        ,\n","        0.        , 0.        , 0.01568627, 0.05882353, 0.        ,\n","        0.01960784, 0.0627451 , 0.01176471, 0.        , 0.        ,\n","        0.        , 0.04313725, 0.04313725, 0.0627451 , 0.03529412,\n","        0.        , 0.        , 0.        , 0.        , 0.01568627,\n","        0.0627451 , 0.05882353, 0.00392157, 0.        , 0.        ,\n","        0.        , 0.        , 0.05098039, 0.03529412, 0.02352941,\n","        0.04705882, 0.00392157, 0.        , 0.        , 0.        ,\n","        0.05882353, 0.01176471, 0.        , 0.03529412, 0.01960784,\n","        0.        , 0.        , 0.        , 0.01960784, 0.05098039,\n","        0.05098039, 0.04705882, 0.01960784, 0.        ],\n","       [0.        , 0.        , 0.00392157, 0.03921569, 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.01568627, 0.05882353, 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.03921569, 0.04313725,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.05098039, 0.03529412, 0.01176471, 0.00784314,\n","        0.        , 0.        , 0.        , 0.        , 0.05098039,\n","        0.0627451 , 0.0627451 , 0.05882353, 0.01568627, 0.        ,\n","        0.        , 0.        , 0.05098039, 0.05098039, 0.02352941,\n","        0.01568627, 0.04705882, 0.        , 0.        , 0.        ,\n","        0.03529412, 0.04313725, 0.01960784, 0.03529412, 0.05882353,\n","        0.00784314, 0.        , 0.        , 0.00784314, 0.04705882,\n","        0.0627451 , 0.04705882, 0.02352941, 0.        ],\n","       [0.        , 0.        , 0.        , 0.00784314, 0.05882353,\n","        0.01568627, 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.03137255, 0.05882353, 0.00392157, 0.        ,\n","        0.        , 0.        , 0.        , 0.00392157, 0.05490196,\n","        0.04705882, 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.02352941, 0.0627451 , 0.04705882, 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.05098039,\n","        0.0627451 , 0.05882353, 0.01568627, 0.00784314, 0.        ,\n","        0.        , 0.03529412, 0.0627451 , 0.0627451 , 0.0627451 ,\n","        0.0627451 , 0.04313725, 0.        , 0.        , 0.01176471,\n","        0.03137255, 0.03137255, 0.0627451 , 0.01176471, 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.01176471,\n","        0.05882353, 0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.00392157, 0.03529412, 0.05098039,\n","        0.04313725, 0.        , 0.        , 0.        , 0.        ,\n","        0.03921569, 0.04313725, 0.04705882, 0.0627451 , 0.00392157,\n","        0.        , 0.        , 0.        , 0.05882353, 0.01568627,\n","        0.04705882, 0.0627451 , 0.00392157, 0.        , 0.        ,\n","        0.        , 0.04705882, 0.0627451 , 0.04313725, 0.05882353,\n","        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.05490196, 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.01176471,\n","        0.05490196, 0.        , 0.        , 0.        , 0.01568627,\n","        0.04705882, 0.03137255, 0.03921569, 0.04313725, 0.        ,\n","        0.        , 0.        , 0.        , 0.00784314, 0.03529412,\n","        0.0627451 , 0.02352941, 0.        , 0.        ],\n","       [0.        , 0.        , 0.03921569, 0.02745098, 0.01176471,\n","        0.        , 0.        , 0.        , 0.        , 0.00392157,\n","        0.05882353, 0.04705882, 0.05490196, 0.02352941, 0.        ,\n","        0.        , 0.        , 0.01960784, 0.04705882, 0.        ,\n","        0.00784314, 0.05098039, 0.        , 0.        , 0.        ,\n","        0.01568627, 0.04705882, 0.        , 0.        , 0.01568627,\n","        0.02745098, 0.        , 0.        , 0.03137255, 0.01960784,\n","        0.        , 0.        , 0.01568627, 0.03137255, 0.        ,\n","        0.        , 0.01960784, 0.03137255, 0.        , 0.        ,\n","        0.01960784, 0.03921569, 0.        , 0.        , 0.        ,\n","        0.05490196, 0.01176471, 0.01568627, 0.05490196, 0.02352941,\n","        0.        , 0.        , 0.        , 0.02745098, 0.0627451 ,\n","        0.0627451 , 0.03921569, 0.        , 0.        ]])>, <tf.Tensor: shape=(8,), dtype=int64, numpy=array([8, 4, 4, 8, 6, 4, 9, 0])>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AIG8SZ_fbAM4"},"source":["We are now ready to start training deep learning models!"]},{"cell_type":"markdown","metadata":{"id":"fhAb3OHwbFHh"},"source":["## Technique 2: split using tensorflow\r\n","\r\n","This technique is not so recommended because tensorflow is not able to work with datasets in the same way that sklearn does, it is not as practical to split the data in a random way, but we will show you how it can be done, as sometimes you will strictly be working with tensorflow objects.\r\n","\r\n","* Create a tensor slice dataset object using `data`and `target`."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kdlzq88sa5tr","executionInfo":{"status":"ok","timestamp":1612901705374,"user_tz":-60,"elapsed":431,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"}},"outputId":"54afcd37-29a3-4bb7-f2ea-d49925e59de5"},"source":["full_ds = tf.data.Dataset.from_tensor_slices((data,target))\r\n","print(\"full_ds:\", full_ds)"],"execution_count":40,"outputs":[{"output_type":"stream","text":["full_ds: <TensorSliceDataset shapes: ((64,), ()), types: (tf.float64, tf.int64)>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iLDSGNPIbvMn"},"source":["* Using the commands take and skip, separate the tensor slice dataset into a train object containing 60% of the data, a val object (20%) and a test object (20%)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NvTEUACTbuSb","executionInfo":{"status":"ok","timestamp":1612902008107,"user_tz":-60,"elapsed":510,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"}},"outputId":"4bb1bc34-f42c-42e5-f999-4719479fba6b"},"source":["n_train = int(0.6*len(data))\r\n","n_val = int(0.2*len(data))\r\n","n_test = len(data) - n_train - n_val\r\n","\r\n","train = full_ds.take(n_train)\r\n","valtest = full_ds.skip(n_train)\r\n","val = valtest.take(n_val)\r\n","test = valtest.skip(n_val)\r\n","\r\n","print(\"train:\", train, len(train))\r\n","print(\"val:\", val, len(val))\r\n","print(\"test:\", test, len(test))"],"execution_count":45,"outputs":[{"output_type":"stream","text":["train: <TakeDataset shapes: ((64,), ()), types: (tf.float64, tf.int64)> 1078\n","val: <TakeDataset shapes: ((64,), ()), types: (tf.float64, tf.int64)> 359\n","test: <SkipDataset shapes: ((64,), ()), types: (tf.float64, tf.int64)> 360\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TTdWCH3ic7Dm"},"source":["* Use methods shuffle and batch in order to create batch datasets with batches of 8 observations for train, val, and test, and show one batch from each of these objects."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ghhNRALRdGLy","executionInfo":{"status":"ok","timestamp":1612902150674,"user_tz":-60,"elapsed":480,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"}},"outputId":"fa57bcc3-2a43-4390-8470-8ba650515568"},"source":["train_batch = train.shuffle(n_train).batch(8)\r\n","val_batch = val.shuffle(n_val).batch(8)\r\n","test_batch = test.shuffle(n_test).batch(8)\r\n","\r\n","print(\"train batch:\", next(iter(train_batch)))\r\n","print(\"val batch:\", next(iter(val_batch)))\r\n","print(\"test batch:\", next(iter(test_batch)))"],"execution_count":46,"outputs":[{"output_type":"stream","text":["train batch: (<tf.Tensor: shape=(8, 64), dtype=float64, numpy=\n","array([[0.        , 0.        , 0.00784314, 0.05490196, 0.01960784,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.03529412, 0.04705882, 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.00392157, 0.05882353, 0.00392157,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.01176471, 0.05882353, 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.02352941, 0.0627451 ,\n","        0.0627451 , 0.0627451 , 0.05098039, 0.00392157, 0.        ,\n","        0.        , 0.00784314, 0.0627451 , 0.03137255, 0.01568627,\n","        0.02745098, 0.04313725, 0.        , 0.        , 0.        ,\n","        0.04705882, 0.04313725, 0.00392157, 0.03137255, 0.04313725,\n","        0.        , 0.        , 0.        , 0.01176471, 0.04705882,\n","        0.0627451 , 0.05882353, 0.01568627, 0.        ],\n","       [0.        , 0.        , 0.00392157, 0.05098039, 0.04705882,\n","        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n","        0.03529412, 0.0627451 , 0.0627451 , 0.04705882, 0.        ,\n","        0.        , 0.        , 0.        , 0.05490196, 0.02352941,\n","        0.        , 0.05098039, 0.01176471, 0.        , 0.        ,\n","        0.02352941, 0.03921569, 0.        , 0.        , 0.03921569,\n","        0.02352941, 0.        , 0.        , 0.02745098, 0.05098039,\n","        0.        , 0.        , 0.03529412, 0.03137255, 0.        ,\n","        0.        , 0.01176471, 0.0627451 , 0.00392157, 0.01176471,\n","        0.05490196, 0.02745098, 0.        , 0.        , 0.        ,\n","        0.04313725, 0.0627451 , 0.0627451 , 0.0627451 , 0.00392157,\n","        0.        , 0.        , 0.        , 0.        , 0.04313725,\n","        0.0627451 , 0.02352941, 0.        , 0.        ],\n","       [0.        , 0.        , 0.00784314, 0.03921569, 0.0627451 ,\n","        0.03921569, 0.        , 0.        , 0.        , 0.        ,\n","        0.05490196, 0.03529412, 0.02352941, 0.0627451 , 0.0627451 ,\n","        0.        , 0.        , 0.        , 0.0627451 , 0.02352941,\n","        0.01960784, 0.05490196, 0.04313725, 0.        , 0.        ,\n","        0.        , 0.01960784, 0.05490196, 0.05490196, 0.0627451 ,\n","        0.02352941, 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.00392157, 0.0627451 , 0.01176471, 0.        ,\n","        0.        , 0.        , 0.01176471, 0.00392157, 0.01568627,\n","        0.0627451 , 0.01176471, 0.        , 0.        , 0.00784314,\n","        0.05882353, 0.05098039, 0.04313725, 0.05098039, 0.00392157,\n","        0.        , 0.        , 0.        , 0.01176471, 0.04705882,\n","        0.05098039, 0.01568627, 0.        , 0.        ],\n","       [0.        , 0.        , 0.01568627, 0.02352941, 0.04313725,\n","        0.01960784, 0.        , 0.        , 0.        , 0.00784314,\n","        0.05490196, 0.02745098, 0.00784314, 0.05882353, 0.        ,\n","        0.        , 0.        , 0.01568627, 0.03137255, 0.        ,\n","        0.        , 0.03921569, 0.00784314, 0.        , 0.        ,\n","        0.        , 0.05490196, 0.03137255, 0.03137255, 0.05098039,\n","        0.00392157, 0.        , 0.        , 0.        , 0.05882353,\n","        0.03921569, 0.0627451 , 0.02745098, 0.        , 0.        ,\n","        0.        , 0.00392157, 0.03921569, 0.        , 0.00392157,\n","        0.03921569, 0.01568627, 0.        , 0.        , 0.        ,\n","        0.04705882, 0.00784314, 0.        , 0.02352941, 0.03137255,\n","        0.        , 0.        , 0.        , 0.02352941, 0.03921569,\n","        0.04313725, 0.02745098, 0.00392157, 0.        ],\n","       [0.        , 0.        , 0.01176471, 0.04313725, 0.05098039,\n","        0.00392157, 0.        , 0.        , 0.        , 0.02352941,\n","        0.0627451 , 0.04313725, 0.05098039, 0.02352941, 0.        ,\n","        0.        , 0.00392157, 0.0627451 , 0.03137255, 0.        ,\n","        0.04313725, 0.01568627, 0.        , 0.        , 0.        ,\n","        0.01568627, 0.01568627, 0.        , 0.0627451 , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.01960784, 0.04313725, 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.03137255, 0.03529412,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.04705882, 0.03529412, 0.01568627, 0.01960784,\n","        0.        , 0.        , 0.        , 0.00392157, 0.05490196,\n","        0.05098039, 0.04705882, 0.05882353, 0.01960784],\n","       [0.        , 0.00392157, 0.04313725, 0.04705882, 0.00392157,\n","        0.        , 0.        , 0.        , 0.        , 0.03137255,\n","        0.0627451 , 0.04705882, 0.03529412, 0.        , 0.        ,\n","        0.        , 0.        , 0.02745098, 0.03137255, 0.02745098,\n","        0.04705882, 0.        , 0.        , 0.        , 0.        ,\n","        0.00392157, 0.00392157, 0.01568627, 0.05490196, 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.01960784, 0.04313725, 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.04313725, 0.03529412,\n","        0.        , 0.        , 0.        , 0.        , 0.00392157,\n","        0.05490196, 0.0627451 , 0.0627451 , 0.05882353, 0.03921569,\n","        0.        , 0.        , 0.        , 0.05098039, 0.04313725,\n","        0.03137255, 0.04705882, 0.03137255, 0.        ],\n","       [0.        , 0.        , 0.01960784, 0.05490196, 0.04313725,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.05882353, 0.0627451 , 0.05882353, 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.03921569, 0.03137255,\n","        0.0627451 , 0.00392157, 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.02352941, 0.05490196, 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.04705882, 0.03529412, 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.00392157, 0.0627451 , 0.01176471,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.03137255, 0.0627451 , 0.04705882, 0.04313725, 0.        ,\n","        0.        , 0.        , 0.        , 0.02745098, 0.0627451 ,\n","        0.04705882, 0.02745098, 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.01960784, 0.04313725,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.00392157, 0.05490196, 0.03529412, 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.01568627, 0.05490196,\n","        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.03921569, 0.03137255, 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.05098039,\n","        0.03137255, 0.01568627, 0.02352941, 0.00784314, 0.        ,\n","        0.        , 0.        , 0.04313725, 0.0627451 , 0.05098039,\n","        0.04705882, 0.05098039, 0.        , 0.        , 0.        ,\n","        0.04705882, 0.05490196, 0.01568627, 0.01960784, 0.0627451 ,\n","        0.00784314, 0.        , 0.        , 0.00392157, 0.03137255,\n","        0.0627451 , 0.05098039, 0.03529412, 0.00392157]])>, <tf.Tensor: shape=(8,), dtype=int64, numpy=array([6, 0, 9, 8, 2, 2, 2, 6])>)\n","val batch: (<tf.Tensor: shape=(8, 64), dtype=float64, numpy=\n","array([[0.        , 0.        , 0.04313725, 0.0627451 , 0.05882353,\n","        0.01176471, 0.        , 0.        , 0.        , 0.01960784,\n","        0.0627451 , 0.04705882, 0.04313725, 0.05098039, 0.        ,\n","        0.        , 0.        , 0.01176471, 0.05098039, 0.00392157,\n","        0.01960784, 0.05882353, 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.04705882, 0.04313725,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.00392157, 0.0627451 , 0.02745098, 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.03921569, 0.05882353,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.04705882, 0.0627451 , 0.0627451 , 0.04313725, 0.00392157,\n","        0.        , 0.        , 0.        , 0.05098039, 0.05098039,\n","        0.03137255, 0.05098039, 0.0627451 , 0.03137255],\n","       [0.        , 0.        , 0.03921569, 0.0627451 , 0.0627451 ,\n","        0.03137255, 0.        , 0.        , 0.        , 0.01960784,\n","        0.0627451 , 0.02352941, 0.02745098, 0.05490196, 0.        ,\n","        0.        , 0.        , 0.01176471, 0.0627451 , 0.01176471,\n","        0.05098039, 0.03529412, 0.        , 0.        , 0.        ,\n","        0.        , 0.05098039, 0.05882353, 0.03529412, 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.03921569,\n","        0.0627451 , 0.00392157, 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.0627451 , 0.05882353, 0.02352941,\n","        0.        , 0.        , 0.        , 0.        , 0.00392157,\n","        0.05882353, 0.04705882, 0.04313725, 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.01960784, 0.0627451 ,\n","        0.03921569, 0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.03137255, 0.0627451 , 0.03921569,\n","        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n","        0.04705882, 0.05098039, 0.05490196, 0.04313725, 0.        ,\n","        0.        , 0.        , 0.        , 0.03921569, 0.05098039,\n","        0.03137255, 0.0627451 , 0.00784314, 0.        , 0.        ,\n","        0.        , 0.01568627, 0.05882353, 0.05882353, 0.0627451 ,\n","        0.03137255, 0.        , 0.        , 0.        , 0.        ,\n","        0.01176471, 0.03137255, 0.04313725, 0.05098039, 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.01960784, 0.0627451 , 0.01568627, 0.        , 0.        ,\n","        0.00392157, 0.00784314, 0.00784314, 0.02745098, 0.0627451 ,\n","        0.01960784, 0.        , 0.        , 0.01176471, 0.05490196,\n","        0.0627451 , 0.0627451 , 0.04313725, 0.00392157],\n","       [0.        , 0.01176471, 0.0627451 , 0.03529412, 0.00784314,\n","        0.        , 0.        , 0.        , 0.        , 0.01176471,\n","        0.0627451 , 0.05098039, 0.04705882, 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.04705882, 0.04313725,\n","        0.05490196, 0.03921569, 0.02352941, 0.        , 0.        ,\n","        0.        , 0.00784314, 0.05882353, 0.0627451 , 0.03921569,\n","        0.00784314, 0.        , 0.        , 0.        , 0.02352941,\n","        0.05490196, 0.05882353, 0.00392157, 0.        , 0.        ,\n","        0.        , 0.01176471, 0.05882353, 0.01568627, 0.03529412,\n","        0.02745098, 0.        , 0.        , 0.        , 0.02352941,\n","        0.05098039, 0.00392157, 0.03921569, 0.03529412, 0.        ,\n","        0.        , 0.        , 0.00784314, 0.04313725, 0.04705882,\n","        0.05490196, 0.01568627, 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.00392157, 0.05882353,\n","        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.03921569, 0.05882353, 0.01176471, 0.        ,\n","        0.        , 0.        , 0.        , 0.03529412, 0.0627451 ,\n","        0.01960784, 0.01176471, 0.02352941, 0.        , 0.        ,\n","        0.01960784, 0.0627451 , 0.03137255, 0.        , 0.04705882,\n","        0.05098039, 0.        , 0.        , 0.04705882, 0.05490196,\n","        0.01568627, 0.03137255, 0.0627451 , 0.03529412, 0.        ,\n","        0.        , 0.04705882, 0.0627451 , 0.0627451 , 0.0627451 ,\n","        0.0627451 , 0.        , 0.        , 0.        , 0.        ,\n","        0.01568627, 0.00784314, 0.05490196, 0.04313725, 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.00392157,\n","        0.0627451 , 0.03529412, 0.        , 0.        ],\n","       [0.        , 0.        , 0.01960784, 0.05098039, 0.04313725,\n","        0.00392157, 0.        , 0.        , 0.        , 0.01176471,\n","        0.0627451 , 0.04313725, 0.03137255, 0.04705882, 0.        ,\n","        0.        , 0.        , 0.01960784, 0.0627451 , 0.        ,\n","        0.        , 0.05098039, 0.01176471, 0.        , 0.        ,\n","        0.01960784, 0.05098039, 0.        , 0.        , 0.02352941,\n","        0.02745098, 0.        , 0.        , 0.02745098, 0.03921569,\n","        0.        , 0.        , 0.03137255, 0.02745098, 0.        ,\n","        0.        , 0.01568627, 0.05098039, 0.        , 0.00392157,\n","        0.05490196, 0.01960784, 0.        , 0.        , 0.00392157,\n","        0.05882353, 0.01960784, 0.04705882, 0.03921569, 0.        ,\n","        0.        , 0.        , 0.        , 0.02745098, 0.0627451 ,\n","        0.03921569, 0.00392157, 0.        , 0.        ],\n","       [0.        , 0.00784314, 0.03921569, 0.05490196, 0.0627451 ,\n","        0.04705882, 0.        , 0.        , 0.        , 0.03921569,\n","        0.04705882, 0.02745098, 0.03921569, 0.04705882, 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.05098039, 0.03921569, 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.01176471, 0.0627451 , 0.01176471,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.05098039, 0.03921569, 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.01960784, 0.0627451 , 0.00392157,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.05490196, 0.05882353, 0.04705882, 0.0627451 , 0.03921569,\n","        0.        , 0.        , 0.00392157, 0.0627451 , 0.05098039,\n","        0.03529412, 0.01176471, 0.        , 0.        ],\n","       [0.        , 0.00392157, 0.03921569, 0.05882353, 0.0627451 ,\n","        0.04313725, 0.        , 0.        , 0.        , 0.03137255,\n","        0.04313725, 0.01568627, 0.02745098, 0.05490196, 0.        ,\n","        0.        , 0.        , 0.02745098, 0.00392157, 0.00784314,\n","        0.05098039, 0.02745098, 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.03921569, 0.0627451 , 0.02352941,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.00392157, 0.05490196, 0.01960784, 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.02745098, 0.03529412, 0.        , 0.        , 0.        ,\n","        0.00784314, 0.        , 0.01176471, 0.04313725, 0.02745098,\n","        0.        , 0.        , 0.        , 0.05882353, 0.0627451 ,\n","        0.0627451 , 0.02745098, 0.        , 0.        ]])>, <tf.Tensor: shape=(8,), dtype=int64, numpy=array([2, 8, 9, 8, 4, 0, 2, 3])>)\n","test batch: (<tf.Tensor: shape=(8, 64), dtype=float64, numpy=\n","array([[0.        , 0.        , 0.        , 0.03137255, 0.0627451 ,\n","        0.0627451 , 0.0627451 , 0.02352941, 0.        , 0.        ,\n","        0.02352941, 0.05490196, 0.01960784, 0.03137255, 0.0627451 ,\n","        0.00784314, 0.        , 0.        , 0.02745098, 0.01568627,\n","        0.        , 0.02352941, 0.04705882, 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.04705882,\n","        0.02352941, 0.        , 0.        , 0.        , 0.        ,\n","        0.04313725, 0.0627451 , 0.0627451 , 0.03921569, 0.        ,\n","        0.        , 0.        , 0.        , 0.04705882, 0.0627451 ,\n","        0.03137255, 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.02352941, 0.0627451 , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.04705882,\n","        0.03529412, 0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.00392157, 0.03921569, 0.05490196,\n","        0.05098039, 0.00392157, 0.        , 0.        , 0.        ,\n","        0.03137255, 0.04705882, 0.02352941, 0.01568627, 0.        ,\n","        0.        , 0.        , 0.        , 0.05490196, 0.01568627,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.01960784, 0.0627451 , 0.04705882, 0.05098039, 0.04705882,\n","        0.        , 0.        , 0.        , 0.00784314, 0.04313725,\n","        0.04313725, 0.03137255, 0.05490196, 0.01568627, 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.0627451 , 0.01568627, 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.02352941, 0.05882353, 0.00784314,\n","        0.        , 0.        , 0.        , 0.        , 0.04705882,\n","        0.05490196, 0.01568627, 0.        , 0.        ],\n","       [0.        , 0.        , 0.05098039, 0.0627451 , 0.0627451 ,\n","        0.01960784, 0.        , 0.        , 0.        , 0.01960784,\n","        0.05882353, 0.02352941, 0.04313725, 0.05098039, 0.        ,\n","        0.        , 0.        , 0.        , 0.00784314, 0.00784314,\n","        0.05098039, 0.03137255, 0.        , 0.        , 0.        ,\n","        0.        , 0.01568627, 0.0627451 , 0.05882353, 0.00784314,\n","        0.        , 0.        , 0.        , 0.        , 0.01176471,\n","        0.04313725, 0.05882353, 0.0627451 , 0.01960784, 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.00784314,\n","        0.05882353, 0.04313725, 0.        , 0.        , 0.        ,\n","        0.01176471, 0.01568627, 0.03529412, 0.0627451 , 0.02352941,\n","        0.        , 0.        , 0.        , 0.05882353, 0.0627451 ,\n","        0.0627451 , 0.03921569, 0.        , 0.        ],\n","       [0.        , 0.        , 0.00392157, 0.05490196, 0.0627451 ,\n","        0.0627451 , 0.05882353, 0.00392157, 0.        , 0.        ,\n","        0.04313725, 0.05490196, 0.03137255, 0.05098039, 0.04313725,\n","        0.        , 0.        , 0.        , 0.05882353, 0.02352941,\n","        0.        , 0.05490196, 0.01176471, 0.        , 0.        ,\n","        0.        , 0.01960784, 0.00392157, 0.01960784, 0.05098039,\n","        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n","        0.05098039, 0.0627451 , 0.0627451 , 0.03529412, 0.        ,\n","        0.        , 0.        , 0.00784314, 0.0627451 , 0.05882353,\n","        0.03529412, 0.00392157, 0.        , 0.        , 0.        ,\n","        0.        , 0.04313725, 0.03529412, 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.01176471, 0.0627451 ,\n","        0.00784314, 0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.00784314, 0.0627451 , 0.03137255,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.03137255, 0.05882353, 0.01960784, 0.        , 0.        ,\n","        0.        , 0.        , 0.00784314, 0.0627451 , 0.02745098,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.01176471, 0.0627451 , 0.02745098, 0.01960784, 0.00392157,\n","        0.        , 0.        , 0.        , 0.02745098, 0.0627451 ,\n","        0.0627451 , 0.0627451 , 0.05882353, 0.01176471, 0.        ,\n","        0.        , 0.01960784, 0.0627451 , 0.04705882, 0.01568627,\n","        0.03921569, 0.05490196, 0.        , 0.        , 0.        ,\n","        0.05490196, 0.05098039, 0.01960784, 0.03921569, 0.05882353,\n","        0.        , 0.        , 0.        , 0.01176471, 0.05098039,\n","        0.0627451 , 0.0627451 , 0.02745098, 0.        ],\n","       [0.        , 0.00392157, 0.04313725, 0.0627451 , 0.04313725,\n","        0.        , 0.        , 0.        , 0.        , 0.03921569,\n","        0.05490196, 0.04313725, 0.0627451 , 0.        , 0.        ,\n","        0.        , 0.        , 0.05490196, 0.01960784, 0.02352941,\n","        0.05882353, 0.        , 0.        , 0.        , 0.        ,\n","        0.01176471, 0.00392157, 0.04313725, 0.05490196, 0.01176471,\n","        0.00392157, 0.        , 0.        , 0.00784314, 0.05098039,\n","        0.0627451 , 0.0627451 , 0.0627451 , 0.03529412, 0.        ,\n","        0.        , 0.00784314, 0.05490196, 0.0627451 , 0.01960784,\n","        0.01568627, 0.00784314, 0.        , 0.        , 0.        ,\n","        0.04313725, 0.04313725, 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.0627451 , 0.01176471,\n","        0.        , 0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.00392157, 0.05098039, 0.03921569,\n","        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n","        0.04705882, 0.02352941, 0.02745098, 0.03921569, 0.        ,\n","        0.        , 0.        , 0.        , 0.03921569, 0.03921569,\n","        0.04313725, 0.05882353, 0.        , 0.        , 0.        ,\n","        0.        , 0.00392157, 0.05490196, 0.0627451 , 0.0627451 ,\n","        0.01960784, 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.03921569, 0.03921569, 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.01960784, 0.04313725, 0.        , 0.        , 0.        ,\n","        0.00784314, 0.01568627, 0.01568627, 0.05490196, 0.04313725,\n","        0.        , 0.        , 0.        , 0.00784314, 0.04313725,\n","        0.05882353, 0.0627451 , 0.01960784, 0.        ],\n","       [0.        , 0.        , 0.02745098, 0.05490196, 0.03137255,\n","        0.01568627, 0.        , 0.        , 0.        , 0.        ,\n","        0.0627451 , 0.03137255, 0.05882353, 0.05490196, 0.00392157,\n","        0.        , 0.        , 0.01568627, 0.0627451 , 0.01568627,\n","        0.        , 0.03137255, 0.01568627, 0.        , 0.        ,\n","        0.03137255, 0.05490196, 0.        , 0.        , 0.01568627,\n","        0.01568627, 0.        , 0.        , 0.03137255, 0.0627451 ,\n","        0.        , 0.        , 0.01568627, 0.01960784, 0.        ,\n","        0.        , 0.01176471, 0.0627451 , 0.00392157, 0.        ,\n","        0.04313725, 0.01568627, 0.        , 0.        , 0.        ,\n","        0.05882353, 0.0627451 , 0.0627451 , 0.04705882, 0.        ,\n","        0.        , 0.        , 0.        , 0.02352941, 0.05098039,\n","        0.02745098, 0.        , 0.        , 0.        ]])>, <tf.Tensor: shape=(8,), dtype=int64, numpy=array([7, 5, 3, 7, 6, 7, 9, 0])>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6fUS1ootddPP"},"source":["Congratulations, you know two different ways of forming datasets that are fit for training deep learning models with tensorflow! This skill will come in very handy as we will try to focus more on building models from now on, and put less focus on preprocessing.\r\n","Until then, happy learning!"]}]}