{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TF_Hub_generative_image_module.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxmDMK4yupqg"
      },
      "source": [
        "# Generate Artificial Faces with CelebA Progressive GAN Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy553YSVmYiK"
      },
      "source": [
        "This exercise will let you use pre-trained models from tensorflow hub in order to generate images, the goal of the exercise will be to generate an image that is the most resembling to your own face!\n",
        "\n",
        "The concepts here are a little challenging, this is on purpose, it's your last day of image processing with deep learning so we would like to show you some more complciated things, however most of the code here will be pre-written and you will just have to complete some cells to get it to work!\n",
        "\n",
        "Two examples are provided:\n",
        "* **Mapping** from latent space to images\n",
        "* Given a target image, **using gradient descent to find** a latent vector that generates an image similar to the target image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4XGxDrCkeip"
      },
      "source": [
        "## Optional prerequisites\n",
        "\n",
        "* Familiarity with [low level Tensorflow concepts](https://www.tensorflow.org/guide/eager).\n",
        "* [Generative Adversarial Network](https://en.wikipedia.org/wiki/Generative_adversarial_network) on Wikipedia.\n",
        "* Paper on Progressive GANs: [Progressive Growing of GANs for Improved Quality, Stability, and Variation](https://arxiv.org/abs/1710.10196)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK3Q2vIaVw56"
      },
      "source": [
        "### More models\n",
        "[Here](https://tfhub.dev/s?module-type=image-generator) you can find all models currently hosted on [tfhub.dev](tfhub.dev) that can generate images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4DN769E2O_R"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNM3kA0arrUu"
      },
      "source": [
        "# Install imageio for creating animations.  \n",
        "!pip -q install imageio\n",
        "!pip -q install scikit-image\n",
        "!pip install git+https://github.com/tensorflow/docs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohvje0oquB0Z"
      },
      "source": [
        "from absl import logging\n",
        "\n",
        "import imageio\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "#tf.random.set_seed(1)\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow_docs.vis import embed\n",
        "import time\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "\n",
        "from IPython import display\n",
        "from skimage import transform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJb9gFmRvynZ"
      },
      "source": [
        "## Random vectors\n",
        "\n",
        "We will use a TF-Hub module [progan-128](https://tfhub.dev/google/progan-128/1) that contains a pre-trained Progressive GAN. Progressive GANs are GANs that were trained to progressively output higher and higher resolution images, in addition to the paper we mentionned earlier you may read <a href=\"https://machinelearningmastery.com/introduction-to-progressive-growing-generative-adversarial-networks/#:~:text=Progressive%20Growing%20GAN%20is%20an,output%20large%20high%2Dquality%20images.&text=Progressive%20growing%20GAN%20models%20are,resolution%20that%20are%20remarkably%20realistic.\"> this blog post </a> that explains very simply how this process works!\n",
        "\n",
        "1. Use the documentation to load the model into an object called `progan`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8StEe9x9wGma"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggL1FULMyUGC"
      },
      "source": [
        "2. Use one of the attributes of the `progan` object to figure out what is the expected input shape for this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qWa2wf0wX85"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cpP2rYkzZro"
      },
      "source": [
        "3. Create a random input vector to compute a random image using `progan`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVqD-5nuzigs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0R5QAKG0fDm"
      },
      "source": [
        "4. Use the following function to display your random image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpEYunOF0jaD"
      },
      "source": [
        "# Simple way to display an image.\n",
        "def display_image(image):\n",
        "  image = tf.constant(image)\n",
        "  image = tf.image.convert_image_dtype(image, tf.uint8)\n",
        "  return PIL.Image.fromarray(image.numpy())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5EESfBvukYI"
      },
      "source": [
        "## Latent space interpolation\n",
        "\n",
        "An interesting technique that can challenge the performance of your generative model is interpolation. The idea is the following: You generate two random vectors from the latent space (input vectors for the progan model), and you sort of draw an line between the two latent vectors and draw vectors from this line (as if you were trying to draw a dotted line between the two). Then you use the model to generate the images corresponding to all those latent vectors.\n",
        "\n",
        "This will give us an idea of the richness of the output space of the progan model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72CrvZAg4EoL"
      },
      "source": [
        "In this series of questions we will create a function `interpolate_hypersphere` that will generate all the vectors on the \"dotted line\" in between two vectors of the latent space, let's go!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cDCTFiF41DH"
      },
      "source": [
        "1. We will use the `tf.norm` function, check out the documentation to see how this function works. It will be useful to normalize the vectors we are trying to interpolate. Compute the norm from the random vector we created before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUr4z8nf6D2Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2Xd4cLn6PIu"
      },
      "source": [
        "2. To implement the logic of interpolation, let's try it first on two 2-dimensional vectors. Create a numpy array with coordinates `(2,1)` and another with coordinates `(3,4)`, display them in a graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWsMo8ke7kmM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj8n6Qhw9C5b"
      },
      "source": [
        "3. Try and create a hundred interpolation vectors between the two you have just created, and include them in a graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVD-XqDc9BVk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3iHBNWV_mQ3"
      },
      "source": [
        "Congratulations you just did your first interpolation!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quE3f0tQ_jMf"
      },
      "source": [
        "4. Now let's use the same principle to interpolate two vectors from the latent space of the progan model!\n",
        "\n",
        "We'll use a specific type of interpolation here which is called hypersphere interpolation, the idea is that we'll have two vectors with different norms (the norm can be interpreted as the distance between a vector and the origin of the space i.e. the vector with all-zero coordinates) we normalize one of them so they have the same norm, then we interpolate the two vectors using only vectors with the same norm, which means all this vectors will be on the sphere centered on the origin and radius equals to the norm of the first vector! (Think of it as the trajectory of shortest distance between two cities on earth which is roughly a sphere!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cPY9Ou4sWs_",
        "cellView": "code"
      },
      "source": [
        "# Interpolates between two vectors that are non-zero and don't both lie on a\n",
        "# line going through origin. First normalizes v2 to have the same norm as v1. \n",
        "# Then interpolates between the two vectors on the hypersphere.\n",
        "def interpolate_hypersphere(v1, v2, num_steps):\n",
        "  # compute the norm for each vector\n",
        "  v1_norm = \n",
        "  v2_norm = \n",
        "  # normalize v2 so it has the same norm as v1\n",
        "  v2_normalized = \n",
        "\n",
        "  # We'll create an empty list where we will store all the interpolated vectors\n",
        "  vectors = []\n",
        "  # loop over the number of steps and create the collection of interpolated\n",
        "  # vectors between v1 and nromalized v2\n",
        "  for step in range(num_steps):\n",
        "    # create the interpolated vector \n",
        "    interpolated = \n",
        "    # calculate the interpolated vector's norm\n",
        "    interpolated_norm = \n",
        "    # normalize the interpolated vector so it has the same norm as v1\n",
        "    interpolated_normalized = \n",
        "    # add that vector to the list\n",
        "    vectors.append(interpolated_normalized)\n",
        "  # Return a stacked version of all these vectors\n",
        "  return tf.stack(vectors)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr5G9BkbDBqi"
      },
      "source": [
        "5. We introduce a utility function to render an animated gif showing the images produced from all the latent space vectors we use in the interpolation!\n",
        "\n",
        "We'll then create an `interpolate_between_vectors` function that can produce all the images from two interpolated vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBgsgHvK_6M-"
      },
      "source": [
        "# Given a set of images, show an animation.\n",
        "def animate(images):\n",
        "  images = np.array(images)\n",
        "  converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
        "  imageio.mimsave('./animation.gif', converted_images)\n",
        "  return embed.embed_file('./animation.gif')\n",
        "\n",
        "logging.set_verbosity(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ0O5_5Jhwio"
      },
      "source": [
        "def interpolate_between_vectors():\n",
        "  # create two random vectors from the latent space\n",
        "  v1 = \n",
        "  v2 = \n",
        "    \n",
        "  # Creates a tensor with 50 steps of interpolation between v1 and v2 using the \n",
        "  # interpolate_hypershpere function\n",
        "  vectors = \n",
        "\n",
        "  # Use progan to generate images from the latent space.\n",
        "  interpolated_images = \n",
        "\n",
        "  return interpolated_images\n",
        "\n",
        "interpolated_images = interpolate_between_vectors()\n",
        "animate(interpolated_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9-uXoTHuXQC"
      },
      "source": [
        "## Finding closest vector in latent space\n",
        "Fix a target image. As an example use an image generated from the module or upload your own.\n",
        "This next cell will let you pick the image you want to generate using the progan model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phT4W66pMmko"
      },
      "source": [
        "image_from_module_space = False  # @param { isTemplate:true, type:\"boolean\" }\n",
        "\n",
        "def get_module_space_image():\n",
        "  vector = tf.random.normal([1, latent_dim])\n",
        "  images = progan(vector)['default'][0]\n",
        "  return images\n",
        "\n",
        "def upload_image():\n",
        "  uploaded = files.upload()\n",
        "  image = imageio.imread(uploaded[list(uploaded.keys())[0]])\n",
        "  image = tf.cast(image/255, tf.float32)\n",
        "  return transform.resize(image, [128, 128])\n",
        "\n",
        "if image_from_module_space:\n",
        "  target_image = get_module_space_image()\n",
        "else:\n",
        "  target_image = upload_image()\n",
        "\n",
        "display_image(target_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBIt3Q4qvhuq"
      },
      "source": [
        "After defining a loss function between the target image and the image generated by a latent space variable, we can use gradient descent to find variable values that minimize the loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f5S7jsxIFdk"
      },
      "source": [
        "1. Create an initial vector and display the image that progan is generating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUGakLdbML2Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7MGzDE5MU20"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CgGgg2MIL5P"
      },
      "source": [
        "2. Let's define a function that will find an image that ressembles the uploaded image as closely as possible.\n",
        "\n",
        "For this we will use gradient descent (with custom training, you already knew this right?). The idea is to define a loss function that will measure how different the two images are from each other, and then use gradient descent to modify the latent vector so that the generated image approaches the target images as closely as possible. Let's do this!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_4Z7tnyg-ZY"
      },
      "source": [
        "def find_closest_latent_vector(initial_vector, num_optimization_steps,\n",
        "                               steps_per_image):\n",
        "  # create two empty lists for the losses and images\n",
        "  images = []\n",
        "  losses = []\n",
        "\n",
        "  # convert intital_vector into a variable tensor (because that's what we will\n",
        "  # update through gradient descent)\n",
        "  vector = \n",
        "  # set up an Adam optimizer\n",
        "  optimizer = \n",
        "  # set up a loss function, you may use MeanAbsoluteError for now\n",
        "  loss_fn = \n",
        "\n",
        "  # loop over num_optimization_steps\n",
        "  for step in range(num_optimization_steps):\n",
        "    #This will print a dot every 100 steps \n",
        "    if (step % 100)==0:\n",
        "      print()\n",
        "    print('.', end='')\n",
        "    # Use gradient tape\n",
        "    with \n",
        "      # Generate the image using the progan model\n",
        "      image = \n",
        "      # Add the image to the list we'll visualize later\n",
        "      if (step % steps_per_image) == 0:\n",
        "        images.append(image.numpy())\n",
        "      # compute the loss function between the generated and target image\n",
        "      target_image_difference = \n",
        "      # The latent vectors were sampled from a normal distribution. We can get\n",
        "      # more realistic images if we regularize the length of the latent vector to \n",
        "      # the average length of vector from this distribution.\n",
        "      regularizer = tf.abs(tf.norm(vector) - np.sqrt(latent_dim))\n",
        "      \n",
        "      # add the regularization to the loss\n",
        "      loss = \n",
        "      # append the loss to the losses list\n",
        "      losses.append(loss.numpy())\n",
        "    # compute the gradients thanks to the loss and according to the latent vector's\n",
        "    # coordinates\n",
        "    grads = \n",
        "    # use the optimizer to update the latent vector\n",
        "    \n",
        "    \n",
        "  return images, losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJdUczSEd0qr"
      },
      "source": [
        "3. Use the `find_closest_latent_vector` function with 200 steps and 5 steps per image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZCQs4uQd_3s"
      },
      "source": [
        "num_optimization_steps=200\n",
        "steps_per_image=5\n",
        "images, loss = find_closest_latent_vector(initial_vector, num_optimization_steps, steps_per_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2Lw2oZ_eOYp"
      },
      "source": [
        "4. Plot the evolution of the loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRbeF2oSAcOB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-hVP-nCeUtW"
      },
      "source": [
        "5. Use the `animate` function in order to display the evolution of the generated image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnZkDy2FEsTt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGKfuCdfPQKH"
      },
      "source": [
        "Compare the result to the target:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK1P5z3bNuIl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDt15dLsJwMy"
      },
      "source": [
        "### Playing with the above example\n",
        "If image is from the module space, the descent is quick and converges to a reasonable sample. Try out descending to an image that is **not from the module space**. The descent will only converge if the image is reasonably close to the space of training images.\n",
        "\n",
        "How to make it descend faster and to a more realistic image? One can try:\n",
        "* using different loss on the image difference, e.g. quadratic,\n",
        "* using different regularizer on the latent vector,\n",
        "* initializing from a random vector in multiple runs,\n",
        "* etc.\n"
      ]
    }
  ]
}