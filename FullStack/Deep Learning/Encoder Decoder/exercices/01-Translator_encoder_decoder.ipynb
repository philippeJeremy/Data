{"cells":[{"cell_type":"markdown","metadata":{"id":"5NFuUYKHABlD"},"source":["# Translations with ENcoder Decoder\n","\n","We'll see that with LSTMs and the Encoder Decoder framework, we can do some pretty powerful things like: *translators* ! Let's see how we can create a French > English translator with TensorFlow \n","\n","### Tips \n","\n","Don't take the whole dataset at the beginning for your experiments, just take 5000 or even 3000 sentences. This will allow you to iterate faster and avoid bugs simply related to your need for computing power.\n","\n","Let's get started!"]},{"cell_type":"markdown","metadata":{"id":"em7GqFRv4nRZ"},"source":["## Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":305,"status":"ok","timestamp":1633714477653,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"},"user_tz":-120},"id":"2qUhyNPnhBtk","outputId":"0d6746ce-cae0-41da-8a06-2ae991989e22"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.6.0'"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["# Import necessaries librairies\n","import pandas as pd\n","import numpy as np \n","import sklearn\n","import tensorflow_datasets as tfds\n","import tensorflow as tf \n","tf.__version__"]},{"cell_type":"markdown","metadata":{"id":"3UoJ_qncuYKk"},"source":["## Importing data \n","\n","1. Load the data using the following url https://go.aws/38ECHUB you can read this using `pd.read_csv` with the `\"\\t\"` delimiter and `header=None`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":1335,"status":"ok","timestamp":1633714479320,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"},"user_tz":-120},"id":"U2-Sd6lq_8ax","outputId":"984135a3-b0ea-40f1-b756-6ca385d3ad13"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Go.</td>\n","      <td>Va !</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Hi.</td>\n","      <td>Salut !</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Run!</td>\n","      <td>Cours !</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Run!</td>\n","      <td>Courez !</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Wow!</td>\n","      <td>Ça alors !</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      0           1\n","0   Go.        Va !\n","1   Hi.     Salut !\n","2  Run!     Cours !\n","3  Run!    Courez !\n","4  Wow!  Ça alors !"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"markdown","metadata":{"id":"sJZCMavOoX3E"},"source":["2. Create an object `doc` containing the first 5000 rows from the file."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YrcFSfBZMuQ7"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"eu-0BjwvoiGY"},"source":["3. In your opinion, are we going to need to lemmatize and remove stop words for a translation problem?"]},{"cell_type":"markdown","metadata":{"id":"ZUxnMkUOwIKb"},"source":[]},{"cell_type":"markdown","metadata":{"id":"_ha3hfzswnVd"},"source":["4. Add the word `<start>` to the beginning of each target sentence in order to create a new column named `padded_en`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":310},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1633714479325,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"},"user_tz":-120},"id":"5AReCt5Zw5TF","outputId":"3abd6792-de20-4114-8292-64987a2e56c0"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>padded_en</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Go.</td>\n","      <td>Va !</td>\n","      <td>&lt;start&gt; Go.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Hi.</td>\n","      <td>Salut !</td>\n","      <td>&lt;start&gt; Hi.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Run!</td>\n","      <td>Cours !</td>\n","      <td>&lt;start&gt; Run!</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Run!</td>\n","      <td>Courez !</td>\n","      <td>&lt;start&gt; Run!</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Wow!</td>\n","      <td>Ça alors !</td>\n","      <td>&lt;start&gt; Wow!</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      0           1     padded_en\n","0   Go.        Va !   <start> Go.\n","1   Hi.     Salut !   <start> Hi.\n","2  Run!     Cours !  <start> Run!\n","3  Run!    Courez !  <start> Run!\n","4  Wow!  Ça alors !  <start> Wow!"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"markdown","metadata":{"id":"0V_yusBAot6c"},"source":["5. Create two objects : `tokenizer_fr` and `tokenizer_en` that will be instances of the `tf.keras.preprocessing.text.Tokenizer` class. \n","\n","Be careful! Since we added a special token containing special characters, make sure you setup the tokenizers right so this token is well interpreted! (use the `filters` argument for example)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f5yAwku3eBro"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"oNRgvH_co7Va"},"source":["6. Fit the tokenizers on the french, and **padded** english sentences respectively."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OVxpAyw5eGAH"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"CUojFPPwpCpo"},"source":["7. Create three new columns in your Dataframe for the encoded french, english, and padded english sentences."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":518},"executionInfo":{"elapsed":508,"status":"ok","timestamp":1633714479816,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"},"user_tz":-120},"id":"X2ueH5W8eTBZ","outputId":"9265158b-f53f-49ec-a255-793ca2841a11"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>padded_en</th>\n","      <th>fr_indices</th>\n","      <th>en_indices</th>\n","      <th>padded_en_indices</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Go.</td>\n","      <td>Va !</td>\n","      <td>&lt;start&gt; Go.</td>\n","      <td>[36]</td>\n","      <td>[11]</td>\n","      <td>[1, 11]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Hi.</td>\n","      <td>Salut !</td>\n","      <td>&lt;start&gt; Hi.</td>\n","      <td>[404]</td>\n","      <td>[616]</td>\n","      <td>[1, 616]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Run!</td>\n","      <td>Cours !</td>\n","      <td>&lt;start&gt; Run!</td>\n","      <td>[1212]</td>\n","      <td>[111]</td>\n","      <td>[1, 111]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Run!</td>\n","      <td>Courez !</td>\n","      <td>&lt;start&gt; Run!</td>\n","      <td>[1213]</td>\n","      <td>[111]</td>\n","      <td>[1, 111]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Wow!</td>\n","      <td>Ça alors !</td>\n","      <td>&lt;start&gt; Wow!</td>\n","      <td>[22, 1214]</td>\n","      <td>[872]</td>\n","      <td>[1, 872]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      0           1     padded_en  fr_indices en_indices padded_en_indices\n","0   Go.        Va !   <start> Go.        [36]       [11]           [1, 11]\n","1   Hi.     Salut !   <start> Hi.       [404]      [616]          [1, 616]\n","2  Run!     Cours !  <start> Run!      [1212]      [111]          [1, 111]\n","3  Run!    Courez !  <start> Run!      [1213]      [111]          [1, 111]\n","4  Wow!  Ça alors !  <start> Wow!  [22, 1214]      [872]          [1, 872]"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"markdown","metadata":{"id":"qFVz8F99yr7P"},"source":["8. We learned from the tutorial that the padded target sequences need to have the same length as the target sequences, so we will remove the last element of each padded target sequence (this will help us enforce teacher forcing)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":310},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1633714479817,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"},"user_tz":-120},"id":"9oYtlrlqzVBi","outputId":"dde0298e-cccc-4bda-fbb7-2b00290579bd"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>padded_en</th>\n","      <th>fr_indices</th>\n","      <th>en_indices</th>\n","      <th>padded_en_indices</th>\n","      <th>padded_en_indices_clean</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Go.</td>\n","      <td>Va !</td>\n","      <td>&lt;start&gt; Go.</td>\n","      <td>[36]</td>\n","      <td>[11]</td>\n","      <td>[1, 11]</td>\n","      <td>[1]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Hi.</td>\n","      <td>Salut !</td>\n","      <td>&lt;start&gt; Hi.</td>\n","      <td>[404]</td>\n","      <td>[616]</td>\n","      <td>[1, 616]</td>\n","      <td>[1]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Run!</td>\n","      <td>Cours !</td>\n","      <td>&lt;start&gt; Run!</td>\n","      <td>[1212]</td>\n","      <td>[111]</td>\n","      <td>[1, 111]</td>\n","      <td>[1]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Run!</td>\n","      <td>Courez !</td>\n","      <td>&lt;start&gt; Run!</td>\n","      <td>[1213]</td>\n","      <td>[111]</td>\n","      <td>[1, 111]</td>\n","      <td>[1]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Wow!</td>\n","      <td>Ça alors !</td>\n","      <td>&lt;start&gt; Wow!</td>\n","      <td>[22, 1214]</td>\n","      <td>[872]</td>\n","      <td>[1, 872]</td>\n","      <td>[1]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      0           1  ... padded_en_indices padded_en_indices_clean\n","0   Go.        Va !  ...           [1, 11]                     [1]\n","1   Hi.     Salut !  ...          [1, 616]                     [1]\n","2  Run!     Cours !  ...          [1, 111]                     [1]\n","3  Run!    Courez !  ...          [1, 111]                     [1]\n","4  Wow!  Ça alors !  ...          [1, 872]                     [1]\n","\n","[5 rows x 7 columns]"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"markdown","metadata":{"id":"mSU_oz8WpShr"},"source":["9. It's rather difficult to work with sequences with variable length, use zero-padding to normalize the length of all the sequences in each category."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UpNwsqpjO0TM"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"BOje1lkApr4Q"},"source":["10. What are the shapes of the arrays you just created for the french, padded english, and english sentences?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1633714479821,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"},"user_tz":-120},"id":"38el3B3z3btO","outputId":"31d254a0-43a5-4b05-a822-ba2e5c786475"},"outputs":[{"data":{"text/plain":["(5000, 10)"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1633714479822,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"},"user_tz":-120},"id":"2qy5q9XSqQCB","outputId":"253c2a3b-8e80-4138-cc43-0bb7ab553de7"},"outputs":[{"data":{"text/plain":["(5000, 4)"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1633714479823,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"},"user_tz":-120},"id":"u9DUbG8D0AgG","outputId":"bfcdfc36-e6ea-4670-e5ec-15fb51859cb6"},"outputs":[{"data":{"text/plain":["(5000, 4)"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"markdown","metadata":{"id":"T0OTamAZ6gX4"},"source":["11. Use `sklearn` `train_test_split` function to divide your sample into train and validation sets."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5xTFcEtSLamK"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"2A63yoDAsZJ0"},"source":["## MODEL\n","\n","Now it's time to code the model, thankfully you can largely base yourself off the code provided during the demo!"]},{"cell_type":"markdown","metadata":{"id":"krxpB96-64Rx"},"source":["1. Create the following variables:\n","* `n_embed` the number of dimensions you want for the embeddings output spaces\n","* `n_lstm` the number of units you want for the lstm layers\n","* `fr_len` the length of a french sentence\n","* `en_len` the length of an english or teacher forcing sentence\n","* `vocab_size_fr` the number of tokens in the french vocabulary\n","* `vocab_size_en` the number of tokens in the english vocabulary (based of the padded sequences so the `<start>` is included!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LO6v2m4q1Z9V"},"outputs":[],"source":["# let's start by defining the number of units needed for the embedding and\n","# the lstm layers\n","\n","n_embed = \n","n_lstm = \n","fr_len = \n","en_len = \n","vocab_size_fr = \n","vocab_size_en = "]},{"cell_type":"markdown","metadata":{"id":"MJPChtoE71DK"},"source":["2. Set up the encoder\n","\n","This will work in the same way as the demo, just make sure the input dimension of the embedding is equal to the number of words in the french vocabulary +1 (for the zero-padding)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BPGvJYwx1bqB"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"dblxRs9G8PQC"},"source":["3. Try the encoder on the french train data (using the call method)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1633714479828,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"},"user_tz":-120},"id":"Tc4TGKC02BFB","outputId":"6dbf83ea-098d-4334-ee89-6eb2707115b6"},"outputs":[{"data":{"text/plain":["[<tf.Tensor: shape=(3500, 64), dtype=float32, numpy=\n"," array([[ 0.03516009,  0.03100508,  0.02265517, ..., -0.01395426,\n","         -0.02611356,  0.009006  ],\n","        [ 0.03598815,  0.03333484,  0.01612609, ..., -0.01795677,\n","         -0.02568691,  0.00788247],\n","        [ 0.0381716 ,  0.03174238,  0.01842551, ..., -0.01462295,\n","         -0.02422647,  0.00832345],\n","        ...,\n","        [ 0.03569918,  0.03146626,  0.02163094, ..., -0.01790284,\n","         -0.02431938,  0.00937005],\n","        [ 0.037827  ,  0.03526489,  0.01708072, ..., -0.01626929,\n","         -0.02635708,  0.01015202],\n","        [ 0.03321327,  0.02693242,  0.0135023 , ..., -0.01000259,\n","         -0.02379798,  0.01082663]], dtype=float32)>,\n"," <tf.Tensor: shape=(3500, 64), dtype=float32, numpy=\n"," array([[ 0.03516009,  0.03100508,  0.02265517, ..., -0.01395426,\n","         -0.02611356,  0.009006  ],\n","        [ 0.03598815,  0.03333484,  0.01612609, ..., -0.01795677,\n","         -0.02568691,  0.00788247],\n","        [ 0.0381716 ,  0.03174238,  0.01842551, ..., -0.01462295,\n","         -0.02422647,  0.00832345],\n","        ...,\n","        [ 0.03569918,  0.03146626,  0.02163094, ..., -0.01790284,\n","         -0.02431938,  0.00937005],\n","        [ 0.037827  ,  0.03526489,  0.01708072, ..., -0.01626929,\n","         -0.02635708,  0.01015202],\n","        [ 0.03321327,  0.02693242,  0.0135023 , ..., -0.01000259,\n","         -0.02379798,  0.01082663]], dtype=float32)>,\n"," <tf.Tensor: shape=(3500, 64), dtype=float32, numpy=\n"," array([[ 0.07132903,  0.06252082,  0.04594512, ..., -0.02778306,\n","         -0.05129484,  0.01805663],\n","        [ 0.07302698,  0.06718089,  0.03269703, ..., -0.03574736,\n","         -0.0505277 ,  0.01579245],\n","        [ 0.07750386,  0.06398077,  0.03737562, ..., -0.02909358,\n","         -0.04764846,  0.01668139],\n","        ...,\n","        [ 0.07240549,  0.0634395 ,  0.04386986, ..., -0.0356677 ,\n","         -0.04776749,  0.01878225],\n","        [ 0.07677907,  0.07117263,  0.03464082, ..., -0.03239217,\n","         -0.05181399,  0.02034902],\n","        [ 0.06741559,  0.05421781,  0.02736798, ..., -0.01989932,\n","         -0.04694292,  0.02171513]], dtype=float32)>]"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"markdown","metadata":{"id":"HZLS83o28Whq"},"source":["4. Set up the decoder\n","\n","This will work in the same way as the demo, just make sure the input dimension of the embedding is equal to the number of words in the french vocabulary +1 (for the zero-padding). The same goes for the last Dense layer!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zqgF-UNG2h5X"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"8d_9ixBl8miy"},"source":["5. Try the decoder on the french train data and the teacher forcing data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1633714480190,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"},"user_tz":-120},"id":"4HkqPbEk2qk6","outputId":"0ddd04c4-d839-4299-9884-b6c7dc725906"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3500, 4, 1258), dtype=float32, numpy=\n","array([[[0.00079917, 0.00078856, 0.00079867, ..., 0.00080011,\n","         0.00079256, 0.00079229],\n","        [0.00079764, 0.00079093, 0.00079901, ..., 0.00079932,\n","         0.00078957, 0.0007946 ],\n","        [0.00079621, 0.00079152, 0.00079583, ..., 0.00079952,\n","         0.00078921, 0.00079494],\n","        [0.00079622, 0.00079408, 0.00079392, ..., 0.00079977,\n","         0.00079026, 0.00079613]],\n","\n","       [[0.00079946, 0.00078939, 0.00079881, ..., 0.00080009,\n","         0.00079287, 0.00079212],\n","        [0.00079881, 0.00078832, 0.00079819, ..., 0.00079679,\n","         0.00079118, 0.00078969],\n","        [0.00079534, 0.00078864, 0.00079493, ..., 0.00079706,\n","         0.00079157, 0.00078996],\n","        [0.0007948 , 0.00079164, 0.00079286, ..., 0.00079765,\n","         0.00079189, 0.00079264]],\n","\n","       [[0.00079904, 0.00078939, 0.00079909, ..., 0.00079993,\n","         0.00079231, 0.00079234],\n","        [0.0007985 , 0.00078829, 0.00079849, ..., 0.00079665,\n","         0.00079078, 0.00078986],\n","        [0.00079875, 0.00079259, 0.00079924, ..., 0.00079699,\n","         0.0007923 , 0.00079135],\n","        [0.00079763, 0.00079447, 0.00079675, ..., 0.00079758,\n","         0.00079283, 0.00079343]],\n","\n","       ...,\n","\n","       [[0.00079916, 0.00078883, 0.00079918, ..., 0.00080005,\n","         0.0007927 , 0.00079221],\n","        [0.00080047, 0.00078975, 0.00079841, ..., 0.00079917,\n","         0.00079389, 0.00079321],\n","        [0.00079752, 0.00079132, 0.0007953 , ..., 0.00080062,\n","         0.00079228, 0.00079401],\n","        [0.00079789, 0.00079367, 0.00079417, ..., 0.00080055,\n","         0.00079242, 0.00079486]],\n","\n","       [[0.00079949, 0.00078923, 0.00079853, ..., 0.00080021,\n","         0.00079316, 0.00079215],\n","        [0.0007979 , 0.0007895 , 0.0008    , ..., 0.00079876,\n","         0.00079324, 0.0007897 ],\n","        [0.00079698, 0.00079185, 0.0007975 , ..., 0.00079911,\n","         0.00079332, 0.00079178],\n","        [0.0007964 , 0.00079385, 0.0007955 , ..., 0.0007994 ,\n","         0.00079335, 0.00079369]],\n","\n","       [[0.00079869, 0.00079052, 0.00079885, ..., 0.00079941,\n","         0.00079275, 0.00079233],\n","        [0.00079754, 0.00079024, 0.00079731, ..., 0.00079928,\n","         0.00079195, 0.00079294],\n","        [0.00079684, 0.00079258, 0.00079525, ..., 0.00079955,\n","         0.00079243, 0.00079415],\n","        [0.00079644, 0.00079446, 0.00079363, ..., 0.00079981,\n","         0.00079273, 0.00079544]]], dtype=float32)>"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"markdown","metadata":{"id":"cR06rACR8uD6"},"source":["6. Set up the inference decoder\n","\n","The code here will be identical to the one from the demo except if you changed some naming conventions!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hp9wT_7e3HWO"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"5MVJbjVE8_HU"},"source":["7. Compile the decoder (the training version) using the appropriate loss and metric functions."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aQwqIpRn3Xjg"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"CdKFFI3i9JaL"},"source":["8. Train the decoder for 50 epochs, this should take 10 minutes. Is there overfitting ?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":78015,"status":"ok","timestamp":1633714558697,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"},"user_tz":-120},"id":"26EGWOcz3vgG","outputId":"54803b9a-1287-4a98-e849-99dfc209c605"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","110/110 [==============================] - 6s 21ms/step - loss: 4.9265 - sparse_categorical_accuracy: 0.3499 - val_loss: 4.0519 - val_sparse_categorical_accuracy: 0.3503\n","Epoch 2/50\n","110/110 [==============================] - 1s 13ms/step - loss: 3.7258 - sparse_categorical_accuracy: 0.3727 - val_loss: 3.6789 - val_sparse_categorical_accuracy: 0.3935\n","Epoch 3/50\n","110/110 [==============================] - 1s 14ms/step - loss: 3.5260 - sparse_categorical_accuracy: 0.3989 - val_loss: 3.5757 - val_sparse_categorical_accuracy: 0.3983\n","Epoch 4/50\n","110/110 [==============================] - 1s 13ms/step - loss: 3.4243 - sparse_categorical_accuracy: 0.4013 - val_loss: 3.5028 - val_sparse_categorical_accuracy: 0.4040\n","Epoch 5/50\n","110/110 [==============================] - 1s 13ms/step - loss: 3.3338 - sparse_categorical_accuracy: 0.4061 - val_loss: 3.4290 - val_sparse_categorical_accuracy: 0.4087\n","Epoch 6/50\n","110/110 [==============================] - 1s 13ms/step - loss: 3.2429 - sparse_categorical_accuracy: 0.4225 - val_loss: 3.3594 - val_sparse_categorical_accuracy: 0.4250\n","Epoch 7/50\n","110/110 [==============================] - 1s 14ms/step - loss: 3.1464 - sparse_categorical_accuracy: 0.4366 - val_loss: 3.2610 - val_sparse_categorical_accuracy: 0.4357\n","Epoch 8/50\n","110/110 [==============================] - 2s 14ms/step - loss: 3.0236 - sparse_categorical_accuracy: 0.4503 - val_loss: 3.1686 - val_sparse_categorical_accuracy: 0.4470\n","Epoch 9/50\n","110/110 [==============================] - 1s 13ms/step - loss: 2.9135 - sparse_categorical_accuracy: 0.4626 - val_loss: 3.0985 - val_sparse_categorical_accuracy: 0.4635\n","Epoch 10/50\n","110/110 [==============================] - 1s 13ms/step - loss: 2.8141 - sparse_categorical_accuracy: 0.4769 - val_loss: 3.0317 - val_sparse_categorical_accuracy: 0.4642\n","Epoch 11/50\n","110/110 [==============================] - 1s 13ms/step - loss: 2.7264 - sparse_categorical_accuracy: 0.4850 - val_loss: 2.9831 - val_sparse_categorical_accuracy: 0.4712\n","Epoch 12/50\n","110/110 [==============================] - 1s 13ms/step - loss: 2.6447 - sparse_categorical_accuracy: 0.4944 - val_loss: 2.9388 - val_sparse_categorical_accuracy: 0.4787\n","Epoch 13/50\n","110/110 [==============================] - 1s 13ms/step - loss: 2.5647 - sparse_categorical_accuracy: 0.5021 - val_loss: 2.8910 - val_sparse_categorical_accuracy: 0.4833\n","Epoch 14/50\n","110/110 [==============================] - 1s 13ms/step - loss: 2.4882 - sparse_categorical_accuracy: 0.5084 - val_loss: 2.8436 - val_sparse_categorical_accuracy: 0.4903\n","Epoch 15/50\n","110/110 [==============================] - 1s 13ms/step - loss: 2.4082 - sparse_categorical_accuracy: 0.5176 - val_loss: 2.7993 - val_sparse_categorical_accuracy: 0.4960\n","Epoch 16/50\n","110/110 [==============================] - 1s 13ms/step - loss: 2.3329 - sparse_categorical_accuracy: 0.5279 - val_loss: 2.7527 - val_sparse_categorical_accuracy: 0.5070\n","Epoch 17/50\n","110/110 [==============================] - 1s 13ms/step - loss: 2.2448 - sparse_categorical_accuracy: 0.5499 - val_loss: 2.7075 - val_sparse_categorical_accuracy: 0.5200\n","Epoch 18/50\n","110/110 [==============================] - 1s 14ms/step - loss: 2.1615 - sparse_categorical_accuracy: 0.5719 - val_loss: 2.6611 - val_sparse_categorical_accuracy: 0.5340\n","Epoch 19/50\n","110/110 [==============================] - 1s 13ms/step - loss: 2.0780 - sparse_categorical_accuracy: 0.5891 - val_loss: 2.6210 - val_sparse_categorical_accuracy: 0.5448\n","Epoch 20/50\n","110/110 [==============================] - 1s 13ms/step - loss: 1.9999 - sparse_categorical_accuracy: 0.6040 - val_loss: 2.5806 - val_sparse_categorical_accuracy: 0.5532\n","Epoch 21/50\n","110/110 [==============================] - 1s 13ms/step - loss: 1.9241 - sparse_categorical_accuracy: 0.6137 - val_loss: 2.5430 - val_sparse_categorical_accuracy: 0.5548\n","Epoch 22/50\n","110/110 [==============================] - 1s 13ms/step - loss: 1.8551 - sparse_categorical_accuracy: 0.6222 - val_loss: 2.5165 - val_sparse_categorical_accuracy: 0.5583\n","Epoch 23/50\n","110/110 [==============================] - 1s 13ms/step - loss: 1.7886 - sparse_categorical_accuracy: 0.6302 - val_loss: 2.4912 - val_sparse_categorical_accuracy: 0.5642\n","Epoch 24/50\n","110/110 [==============================] - 1s 13ms/step - loss: 1.7270 - sparse_categorical_accuracy: 0.6411 - val_loss: 2.4654 - val_sparse_categorical_accuracy: 0.5702\n","Epoch 25/50\n","110/110 [==============================] - 1s 13ms/step - loss: 1.6685 - sparse_categorical_accuracy: 0.6494 - val_loss: 2.4680 - val_sparse_categorical_accuracy: 0.5562\n","Epoch 26/50\n","110/110 [==============================] - 1s 13ms/step - loss: 1.6156 - sparse_categorical_accuracy: 0.6594 - val_loss: 2.4349 - val_sparse_categorical_accuracy: 0.5765\n","Epoch 27/50\n","110/110 [==============================] - 1s 13ms/step - loss: 1.5614 - sparse_categorical_accuracy: 0.6674 - val_loss: 2.4074 - val_sparse_categorical_accuracy: 0.5820\n","Epoch 28/50\n","110/110 [==============================] - 1s 13ms/step - loss: 1.5141 - sparse_categorical_accuracy: 0.6741 - val_loss: 2.3879 - val_sparse_categorical_accuracy: 0.5843\n","Epoch 29/50\n","110/110 [==============================] - 1s 13ms/step - loss: 1.4614 - sparse_categorical_accuracy: 0.6831 - val_loss: 2.3882 - val_sparse_categorical_accuracy: 0.5875\n","Epoch 30/50\n","110/110 [==============================] - 1s 13ms/step - loss: 1.4147 - sparse_categorical_accuracy: 0.6932 - val_loss: 2.3746 - val_sparse_categorical_accuracy: 0.5902\n","Epoch 31/50\n","110/110 [==============================] - 1s 13ms/step - loss: 1.3700 - sparse_categorical_accuracy: 0.7011 - val_loss: 2.3630 - val_sparse_categorical_accuracy: 0.5923\n","Epoch 32/50\n","110/110 [==============================] - 1s 13ms/step - loss: 1.3312 - sparse_categorical_accuracy: 0.7091 - val_loss: 2.3701 - val_sparse_categorical_accuracy: 0.5928\n","Epoch 33/50\n","110/110 [==============================] - 1s 13ms/step - loss: 1.2882 - sparse_categorical_accuracy: 0.7158 - val_loss: 2.3514 - val_sparse_categorical_accuracy: 0.5958\n","Epoch 34/50\n","110/110 [==============================] - 1s 13ms/step - loss: 1.2472 - sparse_categorical_accuracy: 0.7247 - val_loss: 2.3315 - val_sparse_categorical_accuracy: 0.6027\n","Epoch 35/50\n","110/110 [==============================] - 1s 13ms/step - loss: 1.2127 - sparse_categorical_accuracy: 0.7299 - val_loss: 2.3306 - val_sparse_categorical_accuracy: 0.6058\n","Epoch 36/50\n","110/110 [==============================] - 1s 13ms/step - loss: 1.1728 - sparse_categorical_accuracy: 0.7364 - val_loss: 2.3203 - val_sparse_categorical_accuracy: 0.6037\n","Epoch 37/50\n","110/110 [==============================] - 1s 13ms/step - loss: 1.1332 - sparse_categorical_accuracy: 0.7440 - val_loss: 2.3203 - val_sparse_categorical_accuracy: 0.6108\n","Epoch 38/50\n","110/110 [==============================] - 1s 13ms/step - loss: 1.0969 - sparse_categorical_accuracy: 0.7526 - val_loss: 2.3176 - val_sparse_categorical_accuracy: 0.6152\n","Epoch 39/50\n","110/110 [==============================] - 1s 13ms/step - loss: 1.0629 - sparse_categorical_accuracy: 0.7601 - val_loss: 2.3172 - val_sparse_categorical_accuracy: 0.6137\n","Epoch 40/50\n","110/110 [==============================] - 1s 13ms/step - loss: 1.0321 - sparse_categorical_accuracy: 0.7669 - val_loss: 2.3214 - val_sparse_categorical_accuracy: 0.6143\n","Epoch 41/50\n","110/110 [==============================] - 1s 14ms/step - loss: 0.9964 - sparse_categorical_accuracy: 0.7710 - val_loss: 2.3125 - val_sparse_categorical_accuracy: 0.6187\n","Epoch 42/50\n","110/110 [==============================] - 1s 13ms/step - loss: 0.9650 - sparse_categorical_accuracy: 0.7800 - val_loss: 2.3168 - val_sparse_categorical_accuracy: 0.6200\n","Epoch 43/50\n","110/110 [==============================] - 1s 13ms/step - loss: 0.9375 - sparse_categorical_accuracy: 0.7879 - val_loss: 2.3013 - val_sparse_categorical_accuracy: 0.6262\n","Epoch 44/50\n","110/110 [==============================] - 1s 14ms/step - loss: 0.9090 - sparse_categorical_accuracy: 0.7916 - val_loss: 2.2956 - val_sparse_categorical_accuracy: 0.6210\n","Epoch 45/50\n","110/110 [==============================] - 1s 13ms/step - loss: 0.8789 - sparse_categorical_accuracy: 0.7989 - val_loss: 2.3065 - val_sparse_categorical_accuracy: 0.6203\n","Epoch 46/50\n","110/110 [==============================] - 1s 13ms/step - loss: 0.8550 - sparse_categorical_accuracy: 0.8046 - val_loss: 2.2972 - val_sparse_categorical_accuracy: 0.6278\n","Epoch 47/50\n","110/110 [==============================] - 1s 13ms/step - loss: 0.8275 - sparse_categorical_accuracy: 0.8104 - val_loss: 2.2988 - val_sparse_categorical_accuracy: 0.6307\n","Epoch 48/50\n","110/110 [==============================] - 1s 13ms/step - loss: 0.7998 - sparse_categorical_accuracy: 0.8193 - val_loss: 2.3126 - val_sparse_categorical_accuracy: 0.6285\n","Epoch 49/50\n","110/110 [==============================] - 1s 13ms/step - loss: 0.7734 - sparse_categorical_accuracy: 0.8229 - val_loss: 2.3042 - val_sparse_categorical_accuracy: 0.6310\n","Epoch 50/50\n","110/110 [==============================] - 1s 13ms/step - loss: 0.7523 - sparse_categorical_accuracy: 0.8277 - val_loss: 2.3125 - val_sparse_categorical_accuracy: 0.6293\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7fd0cf49ff90>"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"markdown","metadata":{"id":"-w3kOO6g9YO4"},"source":["9. Adapt the code from the demo to make some predictions on the validation data.\n","\n","Be careful, in the demo the starting index for the teacher forcing sequences was 0, what index is the starting point of the teacher forcing sequences now?\n","\n","Set up the first decoder input with the right dimension too!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1633714558698,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"},"user_tz":-120},"id":"mO87iO6a5dlc","outputId":"3433439e-c825-44d9-ecce-c3ce3cfaa4a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["pred: [ 2 18 54 54]\n","true: [26 29  5  0]\n","\n","\n","pred: [ 41 207 207  32]\n","true: [41 32  0  0]\n","\n","\n","pred: [8 6 8 7]\n","true: [ 28  78 192   0]\n","\n","\n","pred: [  2  25 238   5]\n","true: [  2 284   5   0]\n","\n","\n","pred: [  8   6 291 120]\n","true: [  8   6  34 574]\n","\n","\n","pred: [  3  46 106 101]\n","true: [  3  46 233   0]\n","\n","\n","pred: [ 15 130 136  39]\n","true: [13  5 89  0]\n","\n","\n","pred: [  3 128  77  32]\n","true: [  2 706   4   0]\n","\n","\n","pred: [ 25   5 117   7]\n","true: [ 25   5 516   0]\n","\n","\n","pred: [  2  33 193  77]\n","true: [  2  33 193   0]\n","\n","\n"]}],"source":[]},{"cell_type":"markdown","metadata":{"id":"e_Rno_pP97hp"},"source":["10. Use the tokenizer to convert the target and predicted sequences back to text, what do you think of the translations?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1633714558698,"user":{"displayName":"Charles Tanguy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11930294859591867631"},"user_tz":-120},"id":"tSxu203W3gDC","outputId":"8d9fcf88-f230-4d2a-a1fd-7f82e30a29f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["true: i'll get you\n","pred i was good good\n","\n","\n","true: tom's here\n","pred tom's mad mad here\n","\n","\n","true: he's so young\n","pred he is he a\n","\n","\n","true: i called you\n","pred i can read you\n","\n","\n","true: he is no fool\n","pred he is kind too\n","\n","\n","true: i'm not mean\n","pred i'm not sure done\n","\n","\n","true: are you ready\n","pred be careful well in\n","\n","\n","true: i oppose it\n","pred i'm sorry busy here\n","\n","\n","true: can you pitch\n","pred can you swim a\n","\n","\n","true: i got fined\n","pred i got fined busy\n","\n","\n"]}],"source":[]},{"cell_type":"markdown","metadata":{"id":"VviPc59W-pJI"},"source":["11. Now that you reached the end of the exercise, go back to the beginning and increase the number of sentences your model will train on, this should significantly improve the quality of the predictions!"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"01-Translator_encoder_decoder.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
