{"cells":[{"cell_type":"markdown","metadata":{"id":"Va9BZ1QuNMKQ"},"source":["# Code recurrent neural networks\n","\n","This demo will walk you through how to build recurrent neural networks to solve problems with text data (these methods may also be used for any sequential data like time series, sound etc...)\n","\n","## What will you learn in this course? üßêüßê\n","\n","This course will focus on the technical approach to building recurrent neural networks and details on how to code the three new layers we have studied!\n","Here is the outline:\n","\n","* Recurrent layers\n","  * SimpleRNN\n","  * GRU\n","  * LSTM\n","* Build a recurrent neural network"]},{"cell_type":"markdown","metadata":{"id":"nOyBw-XTN-yc"},"source":["## Recurrent layers\n","\n","In this section we will focus strictly on studying the code around the three new layers we just learned about: simpleRNN, GRU, and LSTM."]},{"cell_type":"markdown","metadata":{"id":"FJVeimLTOJCN"},"source":["### SimpleRNN\n","\n","The most simple recurrent layer corresponds to `tf.keras.layers.SimpleRNN`, you may find the documentation here [simpleRNN](https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNN)."]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":198,"status":"ok","timestamp":1622105569833,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"JieP1O9a6g0w"},"outputs":[],"source":["import tensorflow as tf\n","\n","from tensorflow.keras.layers import SimpleRNN\n","\n","srnn = SimpleRNN(units=16, return_sequences=False, return_state=False)\n","\n","# units indicates the number of neurons in this layer\n","# return_sequences indicates whether the layer should output the full sequence\n","#   of outputs computed while processing the input sequence or just the last\n","#   output \n","# return_state indicates whether to return the hidden state in a separate object"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":201,"status":"ok","timestamp":1622105336610,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"WxmGGc1_AMgb","outputId":"705b7ec2-5237-4e62-ef28-a316fbeabe13"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(1, 10, 4), dtype=float32, numpy=\n","array([[[-1.1635678 ,  0.16855568, -0.75133115, -0.87421376],\n","        [-0.79280365,  0.18734804,  1.9284809 , -0.6769638 ],\n","        [-0.3092225 , -0.5739422 ,  0.12904677,  0.71961206],\n","        [-1.0049052 ,  0.7402705 , -0.5423828 , -0.67694044],\n","        [-0.3986196 ,  0.9453884 ,  0.44661582, -0.4180978 ],\n","        [ 0.5253731 ,  1.0866215 , -1.3690103 , -0.40669233],\n","        [-0.6830413 , -0.19420567, -0.44058374, -0.05411001],\n","        [-1.7652224 ,  0.3612688 ,  2.461906  ,  2.5993505 ],\n","        [-1.3611202 ,  0.0565971 ,  1.7649431 ,  1.009644  ],\n","        [ 0.30490953,  0.48030594, -0.42446727, -0.7473773 ]]],\n","      dtype=float32)>"]},"execution_count":3,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["# Let's create an example input for this layer and see how it works\n","batch_size = 1\n","seq_len = 10\n","channels = 4\n","input = tf.random.normal(shape=(batch_size, seq_len, channels))\n","\n","input"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":243,"status":"ok","timestamp":1622105579217,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"zrbMMSccBjY4","outputId":"616bc295-0044-4fbf-95e8-f8b0d83c82bd"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n","array([[-0.69963205, -0.8901289 , -0.65305644,  0.89033777, -0.5493674 ,\n","        -0.30030796, -0.87140274, -0.17787921, -0.710449  , -0.48489323,\n","         0.82255244,  0.10862522, -0.8405781 , -0.29141235, -0.58941853,\n","        -0.23059027]], dtype=float32)>"]},"execution_count":5,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["# now let's apply the simpleRNN layer and see what comes out\n","srnn(input)\n","\n","# the ouput is a batch of one observation with 16 representation channels which\n","# corresponds to the number of units in the layer"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":203,"status":"ok","timestamp":1622105724929,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"kXJGfMGsB8kn","outputId":"bd310559-1758-4bc4-ef48-f6dd1602f981"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(1, 10, 16), dtype=float32, numpy=\n","array([[[ 0.27807614,  0.24998415, -0.206076  , -0.18585703,\n","         -0.13200063, -0.30927563,  0.30215526, -0.6047987 ,\n","          0.06832609,  0.09680297, -0.48995888,  0.74964297,\n","          0.12882937,  0.5754363 ,  0.26132122,  0.19606563],\n","        [ 0.4108236 , -0.4610422 , -0.06890181, -0.94440496,\n","          0.3286013 , -0.9087894 ,  0.90982765,  0.62182766,\n","          0.71168864,  0.2125421 ,  0.5943476 ,  0.11756188,\n","          0.33666435,  0.15585865, -0.67677826,  0.18991011],\n","        [ 0.7265542 , -0.32163596, -0.6203475 ,  0.14377876,\n","          0.5476527 , -0.23619634,  0.14602633, -0.62572193,\n","         -0.01003208,  0.30781385,  0.94770104,  0.52899766,\n","         -0.15797052,  0.06652664,  0.02946644,  0.21035738],\n","        [ 0.51004964,  0.6138037 ,  0.02415972, -0.29176757,\n","         -0.8195665 , -0.20461814,  0.752831  , -0.7716506 ,\n","         -0.23259985,  0.19450921, -0.19646755,  0.6881266 ,\n","         -0.45885983,  0.55662596,  0.5956314 , -0.37468666],\n","        [-0.6219748 , -0.5224188 ,  0.6221914 , -0.8986498 ,\n","         -0.07694807, -0.5211432 ,  0.7896241 ,  0.05194427,\n","          0.13779418, -0.2557532 , -0.05011434,  0.5237327 ,\n","         -0.46354145,  0.53967893,  0.11539973,  0.0872018 ],\n","        [-0.878509  ,  0.6153189 ,  0.32867664,  0.22790705,\n","          0.2523694 ,  0.6793663 , -0.03658522, -0.9293797 ,\n","         -0.2603043 , -0.10618925, -0.821134  ,  0.9571963 ,\n","         -0.85730517, -0.01158288,  0.48097673, -0.65087724],\n","        [-0.76293236,  0.51661414,  0.5477567 , -0.5105723 ,\n","         -0.37408763, -0.50672233, -0.596836  , -0.06055098,\n","          0.48890087, -0.5873008 , -0.56600416,  0.16006279,\n","         -0.08670354,  0.7805347 , -0.63342416, -0.05082037],\n","        [ 0.36409828, -0.6636757 , -0.28530994, -0.9763623 ,\n","          0.9694834 , -0.9453477 , -0.7098414 ,  0.32262313,\n","          0.976139  ,  0.24264036,  0.97876245, -0.8733473 ,\n","          0.95713127, -0.42002538, -0.47593945,  0.805689  ],\n","        [ 0.98826456, -0.4827019 , -0.7263188 , -0.5622041 ,\n","          0.7447973 , -0.9378748 ,  0.29087043,  0.11221948,\n","          0.6056863 ,  0.82882947,  0.9777489 , -0.4867482 ,\n","          0.8658655 , -0.8658465 , -0.19193996, -0.24165802],\n","        [ 0.58060116, -0.44059232, -0.21358967,  0.7562222 ,\n","         -0.7093822 , -0.06867652,  0.7117529 , -0.66154945,\n","         -0.73821795,  0.6327903 ,  0.64419246,  0.42421624,\n","         -0.4439558 , -0.48937362,  0.39101693, -0.8166257 ]]],\n","      dtype=float32)>"]},"execution_count":7,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["# let's change things up by returning the whole output sequence\n","srnn = SimpleRNN(units=16, return_sequences=True, return_state=False)\n","\n","srnn(input)\n","# now the layer preserves the sequential structure of the input, instead of\n","# returning a 2D tensor, now outputs a 3D tensor of shape (batch_size, seq_len, units)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":212,"status":"ok","timestamp":1622107008335,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"08XCE51rG-AD","outputId":"9ab12edc-1684-4b86-80d1-74ee3822b97f"},"outputs":[{"data":{"text/plain":["[<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n"," array([[-0.1098024 , -0.60982233, -0.32496956,  0.15012479, -0.85631555,\n","          0.10025096, -0.80801576, -0.7833567 ,  0.57048374,  0.366127  ,\n","         -0.06957667,  0.11576582,  0.27912173,  0.30287528, -0.6361747 ,\n","          0.21078372]], dtype=float32)>,\n"," <tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n"," array([[-0.1098024 , -0.60982233, -0.32496956,  0.15012479, -0.85631555,\n","          0.10025096, -0.80801576, -0.7833567 ,  0.57048374,  0.366127  ,\n","         -0.06957667,  0.11576582,  0.27912173,  0.30287528, -0.6361747 ,\n","          0.21078372]], dtype=float32)>]"]},"execution_count":8,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["# what happens if we return the state as well?\n","\n","srnn = SimpleRNN(units=16, return_sequences=False, return_state=True)\n","\n","srnn(input)\n","# now the layer returns two objects, the output and the hidden state, well in\n","# simpleRNN they carry the same values as you can see"]},{"cell_type":"markdown","metadata":{"id":"R1Dxj6TXOKsK"},"source":["### GRU\n","\n","Now let's see how we can code GRU layers, you can read the documentation here: [GRU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU)."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":227,"status":"ok","timestamp":1622107255234,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"JQ4gAQLQHxYW","outputId":"e2810dc5-41b1-4ee5-ebd8-355154817ed1"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n","array([[-1.0808587e-02,  1.6081883e-02,  2.5624454e-01, -1.7327070e-04,\n","        -3.6342442e-04, -1.3345486e-01, -1.9287676e-02,  1.6523668e-01,\n","         1.5990761e-01, -1.6242927e-01,  9.7698882e-02,  7.2466955e-04,\n","         1.1103213e-02, -2.1072997e-01, -1.5388536e-01,  9.7298890e-02]],\n","      dtype=float32)>"]},"execution_count":10,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["from tensorflow.keras.layers import GRU\n","\n","gru = GRU(units=16, return_sequences=False, return_state=False)\n","\n","gru(input)\n","\n","# it works mainly in the same way as the SimpleRNN layer"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":206,"status":"ok","timestamp":1622107384945,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"oEdJ_-ZlIibX","outputId":"c73a4933-b653-4c5e-cd28-65513c2207b1"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(1, 10, 16), dtype=float32, numpy=\n","array([[[-0.06934597,  0.0994537 ,  0.19374685,  0.06849788,\n","         -0.24599184,  0.20088878, -0.03349971,  0.04861541,\n","         -0.05434639,  0.07263847, -0.20479624, -0.00352959,\n","          0.1506898 , -0.30446586,  0.01592659, -0.21474351],\n","        [-0.23376793, -0.21181841,  0.49358296,  0.00247522,\n","          0.09905542, -0.07676595, -0.11009975,  0.03201354,\n","         -0.24974006,  0.31153888, -0.13860452,  0.18306912,\n","         -0.01656908, -0.07648543, -0.00100983, -0.03535505],\n","        [-0.14887926, -0.01346983,  0.16340686,  0.04806547,\n","          0.03504476, -0.02840108,  0.10916819, -0.06649324,\n","         -0.11411075,  0.00463158, -0.05082737,  0.10810807,\n","          0.0317376 , -0.11074291,  0.14496876,  0.00664135],\n","        [-0.20463498, -0.03600414,  0.30112484,  0.18771484,\n","         -0.13481319, -0.00141429,  0.01309087, -0.0438042 ,\n","         -0.16769245,  0.15123951, -0.11137815, -0.01092391,\n","          0.14892133, -0.25927463,  0.04785539, -0.17356761],\n","        [-0.28321332, -0.22264864,  0.3650298 ,  0.18505219,\n","          0.07519662, -0.1938022 , -0.08089121, -0.08034434,\n","         -0.25270262,  0.28232032, -0.01124487,  0.00087256,\n","          0.06237639, -0.02803541, -0.06668163, -0.09468069],\n","        [-0.06344774, -0.17036559,  0.20287877,  0.14013158,\n","          0.00466806, -0.06158723, -0.14944056, -0.11406663,\n","         -0.08928463,  0.19123702,  0.04653457, -0.36120734,\n","          0.1658746 ,  0.00966057, -0.16601937, -0.23657295],\n","        [-0.08376159,  0.04234851,  0.14773364,  0.1174287 ,\n","         -0.13208768,  0.09725036, -0.04306489, -0.07084123,\n","         -0.04680695,  0.04347267, -0.08513265, -0.19018075,\n","          0.17956048, -0.19172226, -0.02615151, -0.2544432 ],\n","        [-0.567358  , -0.13451786,  0.47183576,  0.57062775,\n","          0.07819316, -0.05938038,  0.24291715, -0.28205284,\n","         -0.19983444,  0.04778895,  0.29102477, -0.01329198,\n","          0.04481336,  0.04944929,  0.17150998, -0.0422439 ],\n","        [-0.550462  , -0.197265  ,  0.54457617,  0.5377399 ,\n","          0.1900335 , -0.24503432,  0.2858354 , -0.28330746,\n","         -0.34278068,  0.12462194,  0.19813538,  0.12374156,\n","         -0.03107614, -0.00789023,  0.25068867,  0.06467366],\n","        [-0.17175822, -0.14218509,  0.39513832,  0.18399768,\n","          0.13489988, -0.14783086, -0.08498415, -0.11294794,\n","         -0.17406864,  0.18044735,  0.04537484,  0.02568164,\n","          0.02883067, -0.08177166,  0.07072511,  0.00516928]]],\n","      dtype=float32)>"]},"execution_count":11,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["gru = GRU(units=16, return_sequences=True, return_state=False)\n","\n","gru(input)\n","\n","# you can still use return_sequences in order to preserve the sequential\n","# nature of the data"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":308,"status":"ok","timestamp":1622107700150,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"fyY8OkghI5Qb","outputId":"3e2568cc-4c73-4910-e0f9-21016ab52a98"},"outputs":[{"data":{"text/plain":["[<tf.Tensor: shape=(1, 10, 16), dtype=float32, numpy=\n"," array([[[ 1.68479919e-01,  8.23669434e-02,  3.23924780e-01,\n","          -8.42784345e-02, -9.56254266e-03, -1.59966320e-01,\n","           2.76096463e-01, -1.02438785e-01,  2.03701615e-01,\n","          -1.92683958e-03,  1.70403346e-01,  1.54588059e-01,\n","          -8.10326338e-02, -5.28476685e-02,  1.08160235e-01,\n","          -2.27760404e-01],\n","         [-1.32329106e-01, -1.27311483e-01,  2.83936799e-01,\n","           1.67768389e-01, -3.10528845e-01, -3.13403666e-01,\n","           1.92587525e-02, -2.44162321e-01,  3.72009426e-01,\n","           9.21765193e-02,  5.12781441e-01,  9.05069336e-02,\n","           8.67996067e-02, -1.11345544e-01,  2.73031592e-02,\n","          -2.54611522e-02],\n","         [-6.42747879e-02, -1.70516461e-01,  1.37872756e-01,\n","           9.04626772e-02, -2.21704453e-01,  3.52517068e-02,\n","          -1.12043321e-01, -2.15143144e-01,  1.13908403e-01,\n","           2.45724559e-01,  2.97635645e-01, -1.03899032e-01,\n","          -9.39854234e-03, -4.96274941e-02, -1.15752399e-01,\n","           2.10224628e-01],\n","         [ 6.36660606e-02, -9.35586393e-02,  1.97934330e-01,\n","           4.47791219e-02, -1.06083900e-01, -1.81099623e-01,\n","           1.49454594e-01, -1.87458441e-01,  3.19767296e-01,\n","           4.03449275e-02,  2.79123724e-01,  6.19127899e-02,\n","          -2.82848328e-02, -8.19952041e-02,  8.23464990e-02,\n","          -7.53275231e-02],\n","         [-6.02391586e-02, -1.25336275e-01,  6.34330511e-02,\n","           1.52550340e-01, -1.18345127e-01, -3.08042288e-01,\n","           7.75570795e-02, -9.38239843e-02,  3.87534112e-01,\n","          -8.89832154e-02,  2.44721860e-01,  3.06382980e-02,\n","           5.31976819e-02, -1.01244494e-01,  1.59392387e-01,\n","          -4.98802811e-02],\n","         [ 1.03154808e-01,  1.45321444e-01, -9.14944559e-02,\n","          -1.00011528e-02,  1.41031578e-01, -2.72675723e-01,\n","           2.41087437e-01,  1.11696377e-01,  1.12669006e-01,\n","          -3.75009120e-01, -9.52121615e-03,  1.09410711e-01,\n","           1.93804502e-04, -5.82007617e-02,  4.00904417e-01,\n","          -3.19302917e-01],\n","         [ 1.77826226e-01,  1.35633111e-01,  1.34790361e-01,\n","          -6.73252791e-02,  1.02326520e-01, -1.27370924e-01,\n","           1.72943175e-01,  4.60279733e-03,  3.86723354e-02,\n","          -8.69642571e-02,  6.72001243e-02,  4.81895097e-02,\n","          -7.01079071e-02, -6.10630140e-02,  2.01253459e-01,\n","          -2.20897585e-01],\n","         [ 1.75214112e-02, -4.74716693e-01, -1.16083547e-01,\n","           6.29535437e-01, -1.14333563e-01,  1.60147995e-01,\n","          -1.00423738e-01, -2.83711940e-01,  4.01710063e-01,\n","           3.64062935e-01,  3.53825808e-01, -2.47040749e-01,\n","           5.68108678e-01, -1.59507245e-01,  4.44597825e-02,\n","           1.34337842e-02],\n","         [-2.08422411e-02, -5.88330626e-01, -8.39133263e-02,\n","           6.15159690e-01, -3.19468707e-01,  1.50956899e-01,\n","          -2.51629323e-01, -4.00686502e-01,  4.98579741e-01,\n","           5.54567695e-01,  4.22925770e-01, -3.40914011e-01,\n","           4.59543616e-01, -1.75167874e-01, -3.25161703e-02,\n","           2.52637357e-01],\n","         [ 1.94092058e-02, -1.56572297e-01, -4.35202904e-02,\n","           3.33140880e-01, -1.81836709e-01,  1.25139132e-02,\n","          -1.90196633e-02, -1.84322506e-01,  3.37724775e-01,\n","           1.05246797e-01,  2.05337226e-01, -1.09679401e-02,\n","           2.28344172e-01, -6.98427558e-02,  2.04015151e-01,\n","          -1.25531197e-01]]], dtype=float32)>,\n"," <tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n"," array([[ 0.01940921, -0.1565723 , -0.04352029,  0.33314088, -0.18183671,\n","          0.01251391, -0.01901966, -0.1843225 ,  0.33772478,  0.1052468 ,\n","          0.20533723, -0.01096794,  0.22834417, -0.06984276,  0.20401515,\n","         -0.1255312 ]], dtype=float32)>]"]},"execution_count":15,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["gru = GRU(units=16, return_sequences=True, return_state=True)\n","\n","gru(input)\n","\n","# the state is always equal to the values returned after processing the whole\n","# sequence"]},{"cell_type":"markdown","metadata":{"id":"GYf2DkyJOL2j"},"source":["### LSTM\n","\n","Last but not least let's see how to code an LSTM neuron, check the documentation: \n","[LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM)."]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":200,"status":"ok","timestamp":1622108542503,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"iigMjAFhMwqn","outputId":"85e48a2e-32c0-4837-91e4-9c8b2e56ccfb"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n","array([[ 0.07914715,  0.07655661, -0.02766241, -0.12622504,  0.02012474,\n","        -0.28260395, -0.07853369,  0.1230915 , -0.15065426,  0.01768514,\n","         0.07268874, -0.12879959,  0.08355555, -0.01858526, -0.13285434,\n","        -0.05467749]], dtype=float32)>"]},"execution_count":17,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["from tensorflow.keras.layers import LSTM\n","\n","lstm = LSTM(units=16, return_sequences=False, return_state=False)\n","\n","lstm(input)\n","\n","# it works mainly like GRU"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":200,"status":"ok","timestamp":1622108607115,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"vk9oezEKNLrL","outputId":"88696b59-2643-4db7-e6a5-4589a021000f"},"outputs":[{"data":{"text/plain":["[<tf.Tensor: shape=(1, 10, 16), dtype=float32, numpy=\n"," array([[[-7.14064986e-02, -4.10236940e-02,  3.96738835e-02,\n","           2.14840518e-03,  2.57249698e-02, -3.26019898e-02,\n","           5.92622161e-02,  5.29569872e-02, -7.35800155e-03,\n","           1.77562386e-01, -1.37414224e-02, -1.07611351e-01,\n","           1.18049234e-01,  2.45713983e-02,  9.78207067e-02,\n","           1.91633254e-02],\n","         [ 2.09015124e-02, -1.21876560e-01,  8.26791860e-03,\n","          -1.52107090e-01,  1.10287145e-02,  1.33250102e-01,\n","           5.73449582e-02,  9.98590067e-02, -3.48599367e-02,\n","           1.83004320e-01,  5.15443534e-02,  3.12008243e-02,\n","           4.25682738e-02,  2.20248178e-01,  1.50843382e-01,\n","          -1.47773579e-01],\n","         [ 3.81631702e-02, -4.77095842e-02,  8.64316244e-03,\n","          -3.09723355e-02, -7.94051439e-02,  4.97619249e-02,\n","           6.55366480e-02,  1.13652036e-01, -6.12777434e-02,\n","           7.59801492e-02,  7.06352741e-02,  1.14705414e-01,\n","          -2.13253293e-02,  1.70152515e-01,  1.01738378e-01,\n","          -1.94013834e-01],\n","         [-6.13381341e-02, -1.01823770e-01, -2.08233017e-03,\n","          -2.32990477e-02, -9.36266501e-03,  3.11774405e-04,\n","           1.14079721e-01,  1.33922443e-01, -8.82083401e-02,\n","           1.72270238e-01,  7.27900714e-02, -2.32908372e-02,\n","           9.65481773e-02,  1.17388926e-01,  1.30923092e-01,\n","          -7.91445822e-02],\n","         [-9.50806662e-02, -1.39323816e-01, -5.11329398e-02,\n","          -7.16703236e-02,  4.53328267e-02,  4.55965996e-02,\n","           8.87396559e-02,  1.01160362e-01, -1.22061923e-01,\n","           1.07841559e-01,  8.30539763e-02, -3.60619761e-02,\n","           9.98848155e-02,  1.62001148e-01,  1.02093890e-01,\n","          -6.08672351e-02],\n","         [-1.38788879e-01, -3.55827399e-02, -8.90881792e-02,\n","          -1.41783999e-02,  1.44787803e-01, -6.22881949e-03,\n","           3.16290893e-02, -2.57977527e-02, -1.44536138e-01,\n","           3.79468501e-02, -2.33657844e-02, -1.30793139e-01,\n","           1.34126976e-01,  3.79667543e-02, -3.39181657e-04,\n","           7.65430480e-02],\n","         [-1.38476044e-01, -3.12400088e-02, -2.17020176e-02,\n","          -2.48408434e-03,  7.62182325e-02, -4.83036116e-02,\n","           4.77449633e-02,  7.18661165e-03, -1.10984251e-01,\n","           1.18157052e-01,  1.01965731e-02, -1.29477993e-01,\n","           1.84544936e-01,  5.01082055e-02,  6.93641081e-02,\n","           5.30562811e-02],\n","         [-4.87851538e-02, -3.19743782e-01, -1.48257539e-01,\n","          -1.28152803e-01, -1.27836689e-01, -1.95055027e-02,\n","           2.60062981e-02,  1.30003333e-01, -1.71007499e-01,\n","          -1.33864641e-01,  1.25247240e-01,  6.70154318e-02,\n","          -1.03887118e-01,  3.15651655e-01,  6.86798617e-02,\n","          -1.31678864e-01],\n","         [-1.91177242e-03, -3.86038661e-01, -1.23536654e-01,\n","          -1.37869805e-01, -1.73698038e-01,  3.17719206e-02,\n","           5.26393466e-02,  2.01236248e-01, -1.97160006e-01,\n","          -1.85083821e-01,  1.82301015e-01,  1.77063406e-01,\n","          -1.98778421e-01,  3.35282177e-01,  9.16492715e-02,\n","          -2.67787635e-01],\n","         [-3.66799980e-02, -2.02182487e-01, -9.55837220e-02,\n","          -3.90168726e-02, -8.33867937e-02,  1.81651283e-02,\n","           1.75037086e-02,  1.25581264e-01, -1.87798813e-01,\n","          -1.00057386e-01,  9.59850848e-02,  9.18723866e-02,\n","          -5.66306971e-02,  1.70333967e-01,  1.18778106e-02,\n","          -5.65147027e-03]]], dtype=float32)>,\n"," <tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n"," array([[-0.03668   , -0.20218249, -0.09558372, -0.03901687, -0.08338679,\n","          0.01816513,  0.01750371,  0.12558126, -0.18779881, -0.10005739,\n","          0.09598508,  0.09187239, -0.0566307 ,  0.17033397,  0.01187781,\n","         -0.00565147]], dtype=float32)>,\n"," <tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n"," array([[-0.0735779 , -0.4016881 , -0.21662068, -0.10075758, -0.1791047 ,\n","          0.03789696,  0.03002457,  0.2709057 , -0.40343902, -0.21586826,\n","          0.18260738,  0.18391338, -0.13618271,  0.3827544 ,  0.0248985 ,\n","         -0.01242504]], dtype=float32)>]"]},"execution_count":18,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["lstm = LSTM(units=16, return_sequences=True, return_state=True)\n","\n","lstm(input)\n","\n","# When using return_state, the layer returns \n","# 1 the output (sequence or not depending on return_sequences)\n","# 2 the hidden state which is equal to the final output\n","# 3 the cell state"]},{"cell_type":"markdown","metadata":{"id":"2U2HpYlROSc2"},"source":["Now that you know how to code the three different recurrent layers, let's look to build a recurrent neural network on text data."]},{"cell_type":"markdown","metadata":{"id":"UwzRBiroONUH"},"source":["## Build a recurrent network"]},{"cell_type":"markdown","metadata":{"id":"e6nwJV3xPkAx"},"source":["Let's show you an example on some toy dataset"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":363,"status":"ok","timestamp":1622117843336,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"YqtF4ChPM23g"},"outputs":[],"source":["import io\n","import os\n","import re\n","import shutil\n","import string\n","import tensorflow as tf\n","\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n","from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"]},{"cell_type":"markdown","metadata":{"id":"ykIM87xnwg17"},"source":["We'll use the same dataset we used for the embedding and word2vec demos which is the movie critique dataset."]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":27768,"status":"ok","timestamp":1622118017009,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"J1O1JVh4VqdW"},"outputs":[],"source":["url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n","\n","dataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", url,\n","                                  untar=True, cache_dir='.',\n","                                  cache_subdir='')\n","\n","# after dowloading the data we remove the unlabeled examples stored in the \n","# unsup folder\n","remove_dir = os.path.join(\"/content/aclImdb/train\", 'unsup')\n","shutil.rmtree(remove_dir)"]},{"cell_type":"markdown","metadata":{"id":"4Ebv4o1gx2pF"},"source":["Now let's proceed to load the data into a batch generator"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":350,"status":"ok","timestamp":1622120446469,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"IB95a31VV0G4","outputId":"07a73407-94b4-4eb9-9ef7-04a28411a7e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 25000 files belonging to 2 classes.\n","Using 20000 files for training.\n","Found 25000 files belonging to 2 classes.\n","Using 5000 files for validation.\n"]}],"source":["batch_size = 128\n","seed = 123 # seed is mandatory here to prevent overlap between train and validation\n","train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n","    'aclImdb/train', # path to the folder containing the text files\n","    batch_size=batch_size, # the size of a batch of data\n","    validation_split=0.2, # The proportion of data in the validation set\n","    subset='training', # Forms the train set\n","    seed=seed) # similar to random_state\n","val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n","    'aclImdb/train', \n","    batch_size=batch_size, \n","    validation_split=0.2,\n","    subset='validation', # forms the validation set\n","    seed=seed)  "]},{"cell_type":"markdown","metadata":{"id":"g21cpyyEx9Qz"},"source":["Let's take a look at a batch of data"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1622121954926,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"_iNWrNx3V3bo","outputId":"d2f8e905-afe9-48ec-f3e8-454c8e7a8e4f"},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(0, shape=(), dtype=int32) tf.Tensor(b'I thought it was a New-York located movie: wrong! It\\'s a little British countryside setting.<br /><br />I thought it was a comedy: wrong! It\\'s a drama.... Well, up to the last third, because after the story becomes totally \"abracadabrantesque\", the symbolic word for a French presidential mandate. It means, close to nonsense even it the motives would like to bring a sincere feeling.<br /><br />What Do I have left? Maybe, a good duo of actress: Yes, I know, they are 3 friends, but the redhead policewoman is a bit invisible for me. The tall doctoress surprises by her punch, and McDowell delivers a fine acting as usual, all in delicate, soft and almost mute attitude. This gentleness puzzles me, because as other fine artists or directors, the same pattern is repeating over and over. In her case, it\\'s like, whatever the movie, it\\'s always the same character defined by her feelings, her values, who lives infinite different stories. I still don\\'t know how to set the limit (or the fusion) between the artists and the works.<br /><br />Another positive side of this movie is its feminine touch & the interesting different points of view. The women have each their own way of living, even if they are all single. It brings a lot of tolerance and learning to witness how a same and unique reality can be perceived in as many ways as people.<br /><br />Finally, the movie is quite viewable, but the great final cuts the desire of a next vision.', shape=(), dtype=string)\n","tf.Tensor(1, shape=(), dtype=int32) tf.Tensor(b\"'Presque Rien' ('Come Undone') is an earlier work by the inordinately gifted writer/ director S\\xc3\\xa9bastien Lifshitz (with the collaboration of writer St\\xc3\\xa9phane Bouquet - the team that gave us the later 'Wild Side'). As we come to understand Lifshitz's manner of storytelling each of his works becomes more treasureable. By allowing his tender and sensitive love stories to unfold in the same random fashion found in the minds of confused and insecure youths - time now, time passed, time reflective, time imagined, time alone - Lifshitz makes his tales more personal, involving the viewer with every aspect of the characters' responses. It takes a bit of work to key into his method, but going with his technique draws us deeply into the film.<br /><br />Mathieu (handsome and gifted J\\xc3\\xa9r\\xc3\\xa9mie Elka\\xc3\\xafm) is visiting the seaside for a holiday, a time to allow his mother (Dominique Reymond) to struggle with her undefined illness, cared for by the worldly and wise Annick (Marie Matheron) and accompanied by his sister Sarah (Laetitia Legrix): their distant father has remained at home for business reasons. Weaving in and out of the first moments of the film are images of Mathieu alone, looking depressed, riding trains, speaking to someone in a little recorder. We are left to wonder whether the unfolding action is all memory or contemporary action.<br /><br />While sunning at the beach Mathieu notices a handsome youth his age starring at him, and we can feel Mathieu's emotions quivering with confusion. The youth C\\xc3\\xa9dric (St\\xc3\\xa9phane Rideau) follows Mathieu and his sister home, continuing the mystery of attraction. Soon C\\xc3\\xa9dric approaches Mathieu and a gentle introduction leads to a kiss that begins a passionate love obsession. Mathieu is terrified of the direction he is taking, rebuffs C\\xc3\\xa9dric's public approaches, but continues to seek him out for consignations. The two young men are fully in the throes of being in love and the enactment of the physical aspect of this relationship, so very necessary to understanding this story, is shared with the audience in some very erotic and sensual scenes. Yet as the summer wears on Mathieu, a committed student, realizes that C\\xc3\\xa9dric is a drifter working in a condiment stand at a carnival. It becomes apparent that C\\xc3\\xa9dric is the Dionysian partner while Mathieu is the Apollonian one: in a telling time in architectural ruin Mathieu is excited by the beauty of the history and space while C\\xc3\\xa9dric is only interested in the place as a new hideaway for lovemaking.<br /><br />Mathieu is a complex person, coping with his familial ties strained by critical illness and a non-present father, a fear of his burgeoning sexuality, and his nascent passion for C\\xc3\\xa9dric. Their moments of joy are disrupted by C\\xc3\\xa9dric's admission of infidelity and Mathieu's inability to cope with that issue and eventually they part ways. Time passes, family changes are made, and Mathieu drifts into depression including a suicide attempt. The manner in which Mathieu copes with all of these challenges and finds solace, strangely enough, in one of C\\xc3\\xa9dric's past lovers Pierre (Nils Ohlund) brings the film to an ambiguous yet wholly successful climax.<br /><br />After viewing the film the feeling of identification with these characters is so strong that the desire to start the film from the beginning now with the knowledge of the complete story is powerful. Lifshitz has given us a film of meditation with passion, conflicts with passion's powers found in love, and a quiet film of silences and reveries that are incomparably beautiful. The entire cast is superb and the direction is gentle and provocative. Lifshitz is most assuredly one of the bright lights of film-making. In French with English subtitles. Highly Recommended. Grady Harp\", shape=(), dtype=string)\n","tf.Tensor(1, shape=(), dtype=int32) tf.Tensor(b\"I chose to watch this film at Tribeca based on Judd Hirsch and Scott Cohen and found it to be one of the best movies in the festival. Both leading actors deliver a well rounded sensitive performance that seems to match the characters on a personal level. The director did a great job bringing the characters and story to life with skill that is usually not seen in a first-time production.<br /><br />One interesting aspect of this film is the love of woodwork and New York City (Brooklyn in specific). The movie revolves around the family furniture making business and weaves delicate cinematography of both carpentry and ordinary Brooklyn life \\xc2\\x96 again kudos to the director on this fine choice.<br /><br />This is gem and I would whole heartedly recommend it (I'm sure it will make it to the screen).\", shape=(), dtype=string)\n","tf.Tensor(0, shape=(), dtype=int32) tf.Tensor(b'The premise for Circle of Two is an intriguing one. A forbidden love between a sixty year old painter Ashleigh (Richard Burton) and a fifteen year old girl Sarah Norton (Tatum O\\'Neill); and the question of whether such a relationship is acceptable given society\\'s standards. The problem with Circle of Two, however, is that it fails to live up to its promise. Director Jules Dassin and Hedley should have put more thought into the screenplay. When I watched this film, I expected to learn something new about love and sexuality. Instead, I got boring dialogue, a pointless lecture on art, outings where Sarah seemed to have more fun away from Ashleigh, and a closing scene so artificial that its emotional impact was lost. This script makes good actors look bad. So one can imagine how the film\\'s problems were compounded even further with the largely amateurish cast that Jules Dassin assembled. Tatum O\\'Neill was not in her element. I did not believe for a second that her character Sarah was in love with Ashleigh. Her performance seemed superficial, like a contestant at a beauty pageant. It was as though she forced herself to be happy, when the script required her to be happy, and to be sad, when the script asked her to be sad. The only scene I liked with her in was at the very end when she said nothing at all. That was probably the closest Tatum\\'s Sarah Norton ever came to being real. But Tatum was not the only one at fault. Richard Burton\\'s Ashleigh lacked the charm, the charisma and the complexity to attract even women of his own age, let alone a fifteen year old. The rest of the cast was also dismal. Even their arguing was unconvincing, because they waited to take turns. Who does that? Michael Wincott as the jealous ex-boyfriend Paul was probably the best thing in this film, but his role was small. To be fair to the actors, Dassin\\'s direction let everyone down; but it is also true that a great movie goes beyond the script. Kubrick\\'s Lolita did that with James Mason and Sue Lyon; Konchalovsky\\'s Runaway Train went beyond the script with Jon Voight and Eric Roberts playing convicts. The directors of these films also knew how to use music to dramatize their films and reveal something about the characters in them. In spite of its own score (a combination of Antonio Vivaldi, Carl Off and Bernard Hoffer), Circle of Two never succeeds in doing that.<br /><br />In conclusion, the idea of a forbidden love story between an elder painter and a teenage girl is a good one, but its execution in Circle of Two is terrible. In many ways, it is a shame that a controversial, Lolita-type story \\xc2\\x96 which most film directors for understandable reasons would prefer to avoid \\xc2\\x96 did not have receive more intelligent treatment; that a script which actors would have gladly rehearsed was not written; that actors, who were committed to their part or had the talent to make their characters real, could not be found; and that the director Jules Dassin (who did so much better with films like Rififi and Topkapi) did not have to will to put his foot down and say, \"Before we do any filming, we must rethink the love story and revamp the script.\" The only silver lining is that one day an intelligent film about an elder painter and a teenager girl falling in love may one day be made. If such a film ever appears, this it will be surely spark controversy, debate and questions for many years to come.', shape=(), dtype=string)\n","tf.Tensor(0, shape=(), dtype=int32) tf.Tensor(b\"This film failed to explore the humanity of the animals which left me with an empty feeling inside. [Spoiler ahead] I was not convinced that Dr. D really had a compelling reason to forego the big buyout deal to help his furry friends. Whereas Babe (the original) bucked the trend of big-budget hits by focusing on the human virtues of the animals vs. their humans counterparts, all the animals in this film were nothing more than comical caricatures which one would gladly stuff in the meat-grinder (even more so if one could understand their pointless babble). Without Eddie Murphy's zany behavior, this film would be a flop.\", shape=(), dtype=string)\n"]}],"source":["for text_batch, label_batch in train_ds.take(1):\n","  for i in range(5):\n","    print(label_batch[i].numpy(), text_batch.numpy()[i])"]},{"cell_type":"markdown","metadata":{"id":"QsJIenKRyAXt"},"source":["There's some preprocessing to be done, it's possible to do it with spacy by loading all the texts in memory and removing stop words and lemmatize tokens, but the more memory friendly way to do this is to create a preprocessing layer."]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":6031,"status":"ok","timestamp":1622120457457,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"GzKT7y43V8sC"},"outputs":[],"source":["# Create a custom standardization function to strip HTML break tags '<br />'.\n","def custom_standardization(input_data):\n","  # transform all characters to lowercase\n","  lowercase = tf.strings.lower(input_data)\n","  # remove all <br and /> strings\n","  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n","  # replace punctuation with empty string\n","  # [%s] % re.escape(string.punctuation) is a formatting syntax borrowed to see\n","  # [] creates a group, and the %s gets replaced by the content of \n","  # re.escape(string.punctuation) (the escaped punctuation characters)\n","  return tf.strings.regex_replace(stripped_html,\n","                                  '[%s]' % re.escape(string.punctuation), '')\n","\n","\n","# Vocabulary size and number of words in a sequence.\n","vocab_size = 10000\n","sequence_length = 100\n","\n","# Use the text vectorization layer to normalize, split, and map strings to\n","# integers. Note that the layer uses the custom standardization defined above.\n","# Set maximum_sequence length as all samples are not of the same length.\n","vectorize_layer = TextVectorization(\n","    standardize=custom_standardization, # string tensor input -> string tensor output\n","    max_tokens=vocab_size, # int, keep only the vocab_size most common tokens\n","    output_mode='int', # sets the type of encoding\n","    output_sequence_length=sequence_length) # truncates or pads sequences to a\n","    # certain length\n","\n","# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n","text_ds = train_ds.map(lambda x, y: x) # this is building a text only tf dataset\n","vectorize_layer.adapt(text_ds) # lists the vocab and the most common words"]},{"cell_type":"markdown","metadata":{"id":"MQPVhsPk28GI"},"source":["Now let's define a model including some recurrent neurons. Note that if you wish to stack recurrent layers you have to preserve the sequential nature of the data with `return_sequence=True`, the last recurrent may use `return_sequence=False` this will flatten the data so you can use dense layers afterwards."]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":494,"status":"ok","timestamp":1622122003469,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"RHbDdC7UWAW2"},"outputs":[],"source":["embedding_dim=32 # the dimensionality of the representation space\n","\n","model = Sequential([\n","  vectorize_layer, # This layers encodes the string as sequences of int\n","  Embedding(vocab_size, embedding_dim, name=\"embedding\"), # the embedding layer\n","  # the input dim needs to be equal to the size of the vocabulary + 1 (because of\n","  # the zero padding)\n","  SimpleRNN(units=64, return_sequences=True), # maintains the sequential nature\n","  SimpleRNN(units=32, return_sequences=False), # returns the last output\n","  Dense(16, activation='relu'), # a dense layer\n","  Dense(1, activation=\"sigmoid\") # the prediction layer\n","])"]},{"cell_type":"markdown","metadata":{"id":"TFZx3-gg4qpI"},"source":["We need to compile the model so it can train on the data"]},{"cell_type":"code","execution_count":52,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1622122004845,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"RDhWp7qg3LVX"},"outputs":[],"source":["model.compile(optimizer='adam',\n","              loss=tf.keras.losses.BinaryCrossentropy(),\n","              metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"LpQT2l3E4wEu"},"source":["We can now train the model"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":189239,"status":"ok","timestamp":1622122194889,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"lLyvaid93Nto","outputId":"d6b7878b-a00b-492c-d9a1-2aef03173fd2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","157/157 [==============================] - 19s 108ms/step - loss: 0.6944 - accuracy: 0.4991 - val_loss: 0.6931 - val_accuracy: 0.4972\n","Epoch 2/10\n","157/157 [==============================] - 17s 107ms/step - loss: 0.6876 - accuracy: 0.5397 - val_loss: 0.6970 - val_accuracy: 0.4914\n","Epoch 3/10\n","157/157 [==============================] - 17s 107ms/step - loss: 0.5728 - accuracy: 0.6909 - val_loss: 0.7943 - val_accuracy: 0.5088\n","Epoch 4/10\n","157/157 [==============================] - 17s 106ms/step - loss: 0.3189 - accuracy: 0.8526 - val_loss: 1.0888 - val_accuracy: 0.5142\n","Epoch 5/10\n","157/157 [==============================] - 17s 107ms/step - loss: 0.1621 - accuracy: 0.9288 - val_loss: 1.4667 - val_accuracy: 0.5012\n","Epoch 6/10\n","157/157 [==============================] - 17s 107ms/step - loss: 0.1043 - accuracy: 0.9505 - val_loss: 1.9333 - val_accuracy: 0.5066\n","Epoch 7/10\n","157/157 [==============================] - 17s 107ms/step - loss: 0.0769 - accuracy: 0.9633 - val_loss: 2.1390 - val_accuracy: 0.5056\n","Epoch 8/10\n","157/157 [==============================] - 17s 107ms/step - loss: 0.0647 - accuracy: 0.9699 - val_loss: 2.3150 - val_accuracy: 0.4996\n","Epoch 9/10\n","157/157 [==============================] - 17s 107ms/step - loss: 0.0499 - accuracy: 0.9761 - val_loss: 2.4491 - val_accuracy: 0.5026\n","Epoch 10/10\n","157/157 [==============================] - 17s 107ms/step - loss: 0.0449 - accuracy: 0.9814 - val_loss: 2.5385 - val_accuracy: 0.4968\n"]},{"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f5a14718f10>"]},"execution_count":53,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["model.fit(\n","    train_ds,\n","    validation_data=val_ds,\n","    epochs=10)"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1622122194892,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"UPPIHNO0AZWh","outputId":"54c84f5f-d923-45c6-ffe7-2cf3a9550c16"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","text_vectorization_1 (TextVe (None, 100)               0         \n","_________________________________________________________________\n","embedding (Embedding)        (None, 100, 32)           320000    \n","_________________________________________________________________\n","simple_rnn_12 (SimpleRNN)    (None, 100, 64)           6208      \n","_________________________________________________________________\n","simple_rnn_13 (SimpleRNN)    (None, 32)                3104      \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 16)                528       \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 1)                 17        \n","=================================================================\n","Total params: 329,857\n","Trainable params: 329,857\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"Q6IOQDso7z3a"},"source":["There is a lot of overfitting! Let's try with the other two types of layers"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":211,"status":"ok","timestamp":1622120984143,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"uVi3mCCT7_nq"},"outputs":[],"source":["embedding_dim=32 # the dimensionality of the representation space\n","\n","model = Sequential([\n","  vectorize_layer, # This layers encodes the string as sequences of int\n","  Embedding(vocab_size, embedding_dim, name=\"embedding\"), # the embedding layer\n","  # the input dim needs to be equal to the size of the vocabulary + 1 (because of\n","  # the zero padding)\n","  GRU(units=64, return_sequences=True), # maintains the sequential nature\n","  GRU(units=32, return_sequences=False), # returns the last output\n","  Dense(16, activation='relu'), # a dense layer\n","  Dense(1, activation=\"sigmoid\") # the prediction layer\n","])"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1622120985986,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"QsmCSFG76coy"},"outputs":[],"source":["model.compile(optimizer='adam',\n","              loss=tf.keras.losses.BinaryCrossentropy(),\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":370312,"status":"ok","timestamp":1622121356669,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"qtvnEGVP8d9G","outputId":"0777127d-3699-4cad-a95f-61fe0aa7a737"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","157/157 [==============================] - 35s 197ms/step - loss: 0.6316 - accuracy: 0.6119 - val_loss: 0.4675 - val_accuracy: 0.7976\n","Epoch 2/10\n","157/157 [==============================] - 30s 193ms/step - loss: 0.3666 - accuracy: 0.8421 - val_loss: 0.4762 - val_accuracy: 0.8262\n","Epoch 3/10\n","157/157 [==============================] - 30s 193ms/step - loss: 0.2699 - accuracy: 0.8957 - val_loss: 0.4648 - val_accuracy: 0.8182\n","Epoch 4/10\n","157/157 [==============================] - 30s 192ms/step - loss: 0.2187 - accuracy: 0.9202 - val_loss: 0.5123 - val_accuracy: 0.8172\n","Epoch 5/10\n","157/157 [==============================] - 30s 191ms/step - loss: 0.1797 - accuracy: 0.9389 - val_loss: 0.6383 - val_accuracy: 0.7954\n","Epoch 6/10\n","157/157 [==============================] - 30s 192ms/step - loss: 0.1577 - accuracy: 0.9458 - val_loss: 0.6428 - val_accuracy: 0.8062\n","Epoch 7/10\n","157/157 [==============================] - 30s 191ms/step - loss: 0.1237 - accuracy: 0.9601 - val_loss: 0.7436 - val_accuracy: 0.7988\n","Epoch 8/10\n","157/157 [==============================] - 30s 191ms/step - loss: 0.0977 - accuracy: 0.9693 - val_loss: 0.7688 - val_accuracy: 0.7962\n","Epoch 9/10\n","157/157 [==============================] - 30s 191ms/step - loss: 0.0766 - accuracy: 0.9784 - val_loss: 0.8300 - val_accuracy: 0.8014\n","Epoch 10/10\n","157/157 [==============================] - 30s 191ms/step - loss: 0.0628 - accuracy: 0.9822 - val_loss: 0.9239 - val_accuracy: 0.8006\n"]},{"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f5a148f7710>"]},"execution_count":43,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["model.fit(\n","    train_ds,\n","    validation_data=val_ds,\n","    epochs=10)"]},{"cell_type":"markdown","metadata":{"id":"8GW3s4AO9LXv"},"source":["Seems like using GRU instead of simpleRNN is helping the model a lot with the overfitting problem. Now let's compare this with LSTM."]},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":610,"status":"ok","timestamp":1622121396741,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"QYKGhY_v8fSE"},"outputs":[],"source":["embedding_dim=32 # the dimensionality of the representation space\n","\n","model = Sequential([\n","  vectorize_layer, # This layers encodes the string as sequences of int\n","  Embedding(vocab_size, embedding_dim, name=\"embedding\"), # the embedding layer\n","  # the input dim needs to be equal to the size of the vocabulary + 1 (because of\n","  # the zero padding)\n","  LSTM(units=64, return_sequences=True), # maintains the sequential nature\n","  LSTM(units=32, return_sequences=False), # returns the last output\n","  Dense(16, activation='relu'), # a dense layer\n","  Dense(1, activation=\"sigmoid\") # the prediction layer\n","])"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":904,"status":"ok","timestamp":1622121401746,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"xnqAIATE9lHw"},"outputs":[],"source":["model.compile(optimizer='adam',\n","              loss=tf.keras.losses.BinaryCrossentropy(),\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":383579,"status":"ok","timestamp":1622121786270,"user":{"displayName":"Charles Tanguy","photoUrl":"","userId":"11930294859591867631"},"user_tz":-120},"id":"E70_hHes9nD5","outputId":"26dcbb3a-f89e-4119-cec0-f6fdcea457d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","157/157 [==============================] - 38s 217ms/step - loss: 0.5523 - accuracy: 0.6898 - val_loss: 0.3948 - val_accuracy: 0.8190\n","Epoch 2/10\n","157/157 [==============================] - 33s 211ms/step - loss: 0.3280 - accuracy: 0.8661 - val_loss: 0.4381 - val_accuracy: 0.8080\n","Epoch 3/10\n","157/157 [==============================] - 33s 212ms/step - loss: 0.2523 - accuracy: 0.9047 - val_loss: 0.4361 - val_accuracy: 0.8208\n","Epoch 4/10\n","157/157 [==============================] - 34s 212ms/step - loss: 0.2055 - accuracy: 0.9269 - val_loss: 0.5393 - val_accuracy: 0.8136\n","Epoch 5/10\n","157/157 [==============================] - 33s 212ms/step - loss: 0.1744 - accuracy: 0.9417 - val_loss: 0.5330 - val_accuracy: 0.8048\n","Epoch 6/10\n","157/157 [==============================] - 34s 213ms/step - loss: 0.1492 - accuracy: 0.9514 - val_loss: 0.6694 - val_accuracy: 0.7924\n","Epoch 7/10\n","157/157 [==============================] - 34s 213ms/step - loss: 0.1330 - accuracy: 0.9570 - val_loss: 0.6537 - val_accuracy: 0.8064\n","Epoch 8/10\n","157/157 [==============================] - 34s 213ms/step - loss: 0.1111 - accuracy: 0.9650 - val_loss: 0.6913 - val_accuracy: 0.7970\n","Epoch 9/10\n","157/157 [==============================] - 33s 212ms/step - loss: 0.0959 - accuracy: 0.9707 - val_loss: 0.6894 - val_accuracy: 0.8002\n","Epoch 10/10\n","157/157 [==============================] - 34s 213ms/step - loss: 0.0806 - accuracy: 0.9764 - val_loss: 0.7540 - val_accuracy: 0.8042\n"]},{"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f5a11c0d110>"]},"execution_count":46,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["model.fit(\n","    train_ds,\n","    validation_data=val_ds,\n","    epochs=10)"]},{"cell_type":"markdown","metadata":{"id":"yPBVeavM_1aM"},"source":["It looks like the results we obtain for GRU and LSTM are quite comparable, they are both able to solve the overfitting problem which is probably due to the fact that the input data consists in long sequences."]},{"cell_type":"markdown","metadata":{"id":"gAnpwz8mAczx"},"source":["## Conclusion\n","We conclude here that GRU and LSTM layers seem way better for supervised learning tasks than the simple RNN. If you are looking for other best practices for building recurrent neural network, this [blog post](https://danijar.com/tips-for-training-recurrent-neural-networks/) contains lots of great ideas for improving your results and getting better understanding overall of these types of models."]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPb1QwCibhNieo0j2KUBj7u","name":"02-Code_recurrent_neural_networks.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
