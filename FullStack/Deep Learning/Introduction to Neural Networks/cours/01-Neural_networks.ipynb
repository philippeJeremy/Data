{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKZs1d59pyZG"
   },
   "source": [
    "# Neural Networks üß†üß†\n",
    "\n",
    "Before digging into the details of what neural networks are and how they work, let's contemplate a quote from visionnary physicist Stephen Hawking :\n",
    "\n",
    "_\"I think the brain is essentially a computer and consciousness is like a computer program. It will cease to run when the computer is turned off. Theoretically, it could be re-created on a neural network, but that would be very difficult, as it would require all one's memories.\"_\n",
    "\n",
    "He makes an analogy between the way the human brain works and computer programs, and stresses the need for memories, aka, data! We will elaborate more on this quote and the analogy at the end of lecture.\n",
    "\n",
    "<img src=\"https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/M08-DeepLearning/artificial-intelligence.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_0YyxL8tYkP"
   },
   "source": [
    "## What you will learn in this course ? üßêüßê\n",
    "\n",
    "Neural Networks are a class of models vaguely inspired by the biological neural networks in the humain brain, here's an outline of what will be covered in this lecture :\n",
    "\n",
    "* History\n",
    "* Formal neuron (weights, bias, activation function)\n",
    "* Forward pass\n",
    "* Chain rule (for derivating composed functions)\n",
    "* Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjVCmIXgxTTQ"
   },
   "source": [
    "## History üìúüìú\n",
    "\n",
    "Artificial neural networks first appeared in the 1950s in the work of neurologists Warren McCulloch and Walter Pitts, who were the first to define a model mimicking the functioning of a neuron in a nervous system. They called this model a \"formal neuron\": it is a mathematical model with a \"transfer function\" that transforms the data it receives as input into a result according to precise rules defined when the model was specified.\n",
    "\n",
    "Since this first introduction, and largely thanks to advances in Cloud Computing, distributed computing and the improvement of computer computing speed, models built from neural networks have led to phenomenal advances in various fields such as signal processing, natural language processing, image analysis, artificial intelligence, and many others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSUu8GVUzPZk"
   },
   "source": [
    "# Formal Neuron üíªüíª\n",
    "\n",
    "Neural networks are made up of layers composed of neurons. Formal neurons are just functions that turn inputs into outputs according to a certain number of rules and specifications. We will now present the most simple kind of components of artificial neural networks : the densely (or fully-connected) neuron :\n",
    "\n",
    "<img src=\"https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/M08-DeepLearning/Formal_neuron.png\" />\n",
    "\n",
    "The above figure represents a formal neuron as it would work when included in a network structure, let's explain the different elements represented here :\n",
    "\n",
    "* At the input of the neuron, we have a number of input values $i_1, \\dots, i_p$. These inputs are float values that are either coming from the variables in the data or from other neurons in the network. (we will elaborate on that in what follows)\n",
    "* The inputs go into the neuron defined by the blue zone. Each input is multiplied by a weight $w_1j, ..., w_pj$ determined specifically for that neuron of index $j$. The weights are parameters of the neuron and they will be trained through gradient descent.\n",
    "* The weighted inputs go through a combination function noted $\\sum$ because most often the combination function is a simple sum.\n",
    "* We then add a bias to the linear combination of input noted $\\theta_j$ it is a parameter associated with neuron $j$ and it will also be trained through gradient descent.\n",
    "* The result $w_{1j} \\times i_1 + \\dots + w_{pj} \\times i_p + \\theta_j$ is passed to an activation function $\\Phi$. The activation function will most of the time be non-linear in order to give a non-linear behavior to the neural network. More detail will be given on activation functions later on.\n",
    "* The output of the formal neuron is $\\Phi(w_{1j} \\times i_1 + \\dots + w_{pj} \\times i_p + \\theta_j)$\n",
    "\n",
    "The most important things to remember about formal neurons are the following : A fully-connected formal neuron has $p+1$ parameters, where $p$ represents the dimension of the input, and what gives it a non-linear behavior is the activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpXJ_B9d3L_l"
   },
   "source": [
    "## Activation function üí°üí°\n",
    "\n",
    "Activation functions are essential to neural network models because they are bringing non-linearity to the way a formal neuron neuron transforms its input into an output.\n",
    "\n",
    "We will talk about several activation functions in what follows and go into much detail about them, let's mention some of these functions here and give some of their advantages and shortcomings :\n",
    "\n",
    "### ReLu\n",
    "\n",
    "The rectified linear unit function (noted ReLu):\n",
    "\n",
    "$$\n",
    "ReLu(x)=x^{+}=max(0,x)\n",
    "$$\n",
    "\n",
    "\n",
    "is one of the simplest non-linear functions that can be included in a neural network.\n",
    "\n",
    "* Advantages\n",
    "  * Computationally efficient‚Äîallows the network to converge very quickly\n",
    "  * Non-linear‚Äîalthough it looks like a linear function, ReLU has a derivative function and allows for backpropagation\n",
    "* Disadvantages\n",
    "  * The Dying ReLU problem‚Äîwhen inputs approach zero, or are negative, the gradient of the function becomes zero, the network cannot perform backpropagation and cannot learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "JJHkj_766Qfx",
    "outputId": "2482057e-526e-437c-9650-a6fe8e0b6945"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"700\" height=\"450\" style=\"\" viewBox=\"0 0 700 450\"><rect x=\"0\" y=\"0\" width=\"700\" height=\"450\" style=\"fill: rgb(255, 255, 255); fill-opacity: 1;\"/><defs id=\"defs-1e673c\"><g class=\"clips\"><clipPath id=\"clip1e673cxyplot\" class=\"plotclip\"><rect width=\"540\" height=\"270\"/></clipPath><clipPath class=\"axesclip\" id=\"clip1e673cx\"><rect x=\"80\" y=\"0\" width=\"540\" height=\"450\"/></clipPath><clipPath class=\"axesclip\" id=\"clip1e673cy\"><rect x=\"0\" y=\"100\" width=\"700\" height=\"270\"/></clipPath><clipPath class=\"axesclip\" id=\"clip1e673cxy\"><rect x=\"80\" y=\"100\" width=\"540\" height=\"270\"/></clipPath></g><g class=\"gradients\"/></defs><g class=\"bglayer\"><rect class=\"bg\" x=\"80\" y=\"100\" width=\"540\" height=\"270\" style=\"fill: rgb(229, 236, 246); fill-opacity: 1; stroke-width: 0;\"/></g><g class=\"layer-below\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"cartesianlayer\"><g class=\"subplot xy\"><g class=\"layer-subplot\"><g class=\"shapelayer\"/><g class=\"imagelayer\"/></g><g class=\"gridlayer\"><g class=\"x\"><path class=\"xgrid crisp\" transform=\"translate(134,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(242,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(458,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(566,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/></g><g class=\"y\"><path class=\"ygrid crisp\" transform=\"translate(0,307.9)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,259.3)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,210.7)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,162.1)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,113.5)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/></g></g><g class=\"zerolinelayer\"><path class=\"xzl zl crisp\" transform=\"translate(350,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 2px;\"/><path class=\"yzl zl crisp\" transform=\"translate(0,356.5)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 2px;\"/></g><path class=\"xlines-below\"/><path class=\"ylines-below\"/><g class=\"overlines-below\"/><g class=\"xaxislayer-below\"/><g class=\"yaxislayer-below\"/><g class=\"overaxes-below\"/><g class=\"plot\" transform=\"translate(80,100)\" clip-path=\"url('#clip1e673cxyplot')\"><g class=\"scatterlayer mlayer\"><g class=\"trace scatter trace1fe314\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M0,256.5L270.81,255.77L271.35,255.28L361.62,174.04L362.16,173.55L452.43,92.31L452.97,91.82L540,13.5\" style=\"vector-effect: non-scaling-stroke; fill: none; stroke: rgb(75, 154, 199); stroke-opacity: 1; stroke-width: 2px; opacity: 1;\"/></g><g class=\"points\"/><g class=\"text\"/></g></g></g><g class=\"overplot\"/><path class=\"xlines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><path class=\"ylines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><g class=\"overlines-above\"/><g class=\"xaxislayer-above\"><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(134,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">‚àí4</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(242,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">‚àí2</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(350,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">0</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(458,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">2</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(566,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">4</text></g></g><g class=\"yaxislayer-above\"><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,356.5)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">0</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,307.9)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">1</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,259.3)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">2</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,210.7)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">3</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,162.1)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">4</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,113.5)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">5</text></g></g><g class=\"overaxes-above\"/></g></g><g class=\"polarlayer\"/><g class=\"ternarylayer\"/><g class=\"geolayer\"/><g class=\"funnelarealayer\"/><g class=\"pielayer\"/><g class=\"treemaplayer\"/><g class=\"sunburstlayer\"/><g class=\"glimages\"/><defs id=\"topdefs-1e673c\"><g class=\"clips\"/></defs><g class=\"layer-above\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"infolayer\"><g class=\"g-gtitle\"><text class=\"gtitle\" x=\"35\" y=\"50\" text-anchor=\"start\" dy=\"0em\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 17px; fill: rgb(42, 63, 95); opacity: 1; font-weight: normal; white-space: pre;\">ReLu</text></g><g class=\"g-xtitle\"/><g class=\"g-ytitle\"/></g></svg>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "color_chart = [\"#4B9AC7\", \"#4BE8E0\", \"#9DD4F3\", \"#97FBF6\", \"#2A7FAF\", \"#23B1AB\", \"#0E3449\", \"#015955\"]\n",
    "x = np.linspace(-5, 5, num=1000)\n",
    "y = (np.abs(x) + x)/2\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=y,\n",
    "                         mode = \"lines\",\n",
    "                         marker=dict(\n",
    "        color=color_chart[0])))\n",
    "fig.update_layout(title=\"ReLu\")\n",
    "fig.show(\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wVPF2eENVGZ"
   },
   "source": [
    "### Leaky ReLU\n",
    "* Advantages\n",
    "  * Prevents dying ReLU problem‚Äîthis variation of ReLU has a small positive slope in the negative area, so it does enable backpropagation, even for negative input values\n",
    "  * Otherwise like ReLU, although a little slower to compute\n",
    "* Disadvantages\n",
    "  * Results not consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "Ohv0SHSxRNed",
    "outputId": "057589b0-156f-4bc8-b2b5-73990d5f91ad"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"700\" height=\"450\" style=\"\" viewBox=\"0 0 700 450\"><rect x=\"0\" y=\"0\" width=\"700\" height=\"450\" style=\"fill: rgb(255, 255, 255); fill-opacity: 1;\"/><defs id=\"defs-fee584\"><g class=\"clips\"><clipPath id=\"clipfee584xyplot\" class=\"plotclip\"><rect width=\"540\" height=\"270\"/></clipPath><clipPath class=\"axesclip\" id=\"clipfee584x\"><rect x=\"80\" y=\"0\" width=\"540\" height=\"450\"/></clipPath><clipPath class=\"axesclip\" id=\"clipfee584y\"><rect x=\"0\" y=\"100\" width=\"700\" height=\"270\"/></clipPath><clipPath class=\"axesclip\" id=\"clipfee584xy\"><rect x=\"80\" y=\"100\" width=\"540\" height=\"270\"/></clipPath></g><g class=\"gradients\"/></defs><g class=\"bglayer\"><rect class=\"bg\" x=\"80\" y=\"100\" width=\"540\" height=\"270\" style=\"fill: rgb(229, 236, 246); fill-opacity: 1; stroke-width: 0;\"/></g><g class=\"layer-below\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"cartesianlayer\"><g class=\"subplot xy\"><g class=\"layer-subplot\"><g class=\"shapelayer\"/><g class=\"imagelayer\"/></g><g class=\"gridlayer\"><g class=\"x\"><path class=\"xgrid crisp\" transform=\"translate(134,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(242,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(458,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(566,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/></g><g class=\"y\"><path class=\"ygrid crisp\" transform=\"translate(0,356.5)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,275.5)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,235)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,194.5)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,154)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,113.5)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/></g></g><g class=\"zerolinelayer\"><path class=\"xzl zl crisp\" transform=\"translate(350,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 2px;\"/><path class=\"yzl zl crisp\" transform=\"translate(0,316)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 2px;\"/></g><path class=\"xlines-below\"/><path class=\"ylines-below\"/><g class=\"overlines-below\"/><g class=\"xaxislayer-below\"/><g class=\"yaxislayer-below\"/><g class=\"overaxes-below\"/><g class=\"plot\" transform=\"translate(80,100)\" clip-path=\"url('#clipfee584xyplot')\"><g class=\"scatterlayer mlayer\"><g class=\"trace scatter tracec16089\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M0,256.5L270.27,215.8L270.81,215.39L371.35,139.99L371.89,139.58L472.43,64.18L472.97,63.77L540,13.5\" style=\"vector-effect: non-scaling-stroke; fill: none; stroke: rgb(75, 232, 224); stroke-opacity: 1; stroke-width: 2px; opacity: 1;\"/></g><g class=\"points\"/><g class=\"text\"/></g></g></g><g class=\"overplot\"/><path class=\"xlines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><path class=\"ylines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><g class=\"overlines-above\"/><g class=\"xaxislayer-above\"><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(134,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">‚àí4</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(242,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">‚àí2</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(350,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">0</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(458,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">2</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(566,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">4</text></g></g><g class=\"yaxislayer-above\"><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,356.5)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">‚àí1</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,316)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">0</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,275.5)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">1</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,235)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">2</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,194.5)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">3</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,154)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">4</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,113.5)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">5</text></g></g><g class=\"overaxes-above\"/></g></g><g class=\"polarlayer\"/><g class=\"ternarylayer\"/><g class=\"geolayer\"/><g class=\"funnelarealayer\"/><g class=\"pielayer\"/><g class=\"treemaplayer\"/><g class=\"sunburstlayer\"/><g class=\"glimages\"/><defs id=\"topdefs-fee584\"><g class=\"clips\"/></defs><g class=\"layer-above\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"infolayer\"><g class=\"g-gtitle\"><text class=\"gtitle\" x=\"35\" y=\"50\" text-anchor=\"start\" dy=\"0em\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 17px; fill: rgb(42, 63, 95); opacity: 1; font-weight: normal; white-space: pre;\">LeakyReLu</text></g><g class=\"g-xtitle\"/><g class=\"g-ytitle\"/></g></svg>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-5, 5, num=1000)\n",
    "y = (np.abs(x) + x)/2 - (np.abs(x) - x)/10\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=y,\n",
    "                         mode = \"lines\",\n",
    "                         marker=dict(\n",
    "        color=color_chart[1])))\n",
    "fig.update_layout(title=\"LeakyReLu\")\n",
    "fig.show(\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnFwQezbViGJ"
   },
   "source": [
    "### Sigmo√Ød\n",
    "* Advantages\n",
    "  * Smooth gradient, preventing ‚Äújumps‚Äù in output values.\n",
    "Output values bound between 0 and 1, normalizing the output of each neuron.\n",
    "Clear predictions‚ÄîFor X above 2 or below -2, tends to bring the Y value (the prediction) to the edge of the curve, very close to 1 or 0. This enables clear predictions.\n",
    "* Disadvantages\n",
    "  * Vanishing gradient‚Äîfor very high or very low values of input, there is almost no change to the prediction, causing a vanishing gradient problem. This can result in the network refusing to learn further, or being too slow to reach an accurate prediction.\n",
    "  * Outputs not zero centered.\n",
    "  * Computationally expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "WyEYhl7ZNUNV",
    "outputId": "99e04c89-163e-472b-85f9-dc5285c961a9"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"700\" height=\"450\" style=\"\" viewBox=\"0 0 700 450\"><rect x=\"0\" y=\"0\" width=\"700\" height=\"450\" style=\"fill: rgb(255, 255, 255); fill-opacity: 1;\"/><defs id=\"defs-967b59\"><g class=\"clips\"><clipPath id=\"clip967b59xyplot\" class=\"plotclip\"><rect width=\"540\" height=\"270\"/></clipPath><clipPath class=\"axesclip\" id=\"clip967b59x\"><rect x=\"80\" y=\"0\" width=\"540\" height=\"450\"/></clipPath><clipPath class=\"axesclip\" id=\"clip967b59y\"><rect x=\"0\" y=\"100\" width=\"700\" height=\"270\"/></clipPath><clipPath class=\"axesclip\" id=\"clip967b59xy\"><rect x=\"80\" y=\"100\" width=\"540\" height=\"270\"/></clipPath></g><g class=\"gradients\"/></defs><g class=\"bglayer\"><rect class=\"bg\" x=\"80\" y=\"100\" width=\"540\" height=\"270\" style=\"fill: rgb(229, 236, 246); fill-opacity: 1; stroke-width: 0;\"/></g><g class=\"layer-below\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"cartesianlayer\"><g class=\"subplot xy\"><g class=\"layer-subplot\"><g class=\"shapelayer\"/><g class=\"imagelayer\"/></g><g class=\"gridlayer\"><g class=\"x\"><path class=\"xgrid crisp\" transform=\"translate(134,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(242,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(458,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(566,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/></g><g class=\"y\"><path class=\"ygrid crisp\" transform=\"translate(0,308.89)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,259.63)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,210.37)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,161.11)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,111.85)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/></g></g><g class=\"zerolinelayer\"><path class=\"xzl zl crisp\" transform=\"translate(350,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 2px;\"/><path class=\"yzl zl crisp\" transform=\"translate(0,358.15)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 2px;\"/></g><path class=\"xlines-below\"/><path class=\"ylines-below\"/><g class=\"overlines-below\"/><g class=\"xaxislayer-below\"/><g class=\"yaxislayer-below\"/><g class=\"overaxes-below\"/><g class=\"plot\" transform=\"translate(80,100)\" clip-path=\"url('#clip967b59xyplot')\"><g class=\"scatterlayer mlayer\"><g class=\"trace scatter trace51aa72\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M0,256.5L51.89,253.89L52.43,253.84L80,251.06L80.54,250.99L104.86,247.1L105.41,246.99L127.03,241.86L127.57,241.71L147.57,235.03L148.11,234.82L163.24,228.19L163.78,227.92L177.84,220.32L178.38,220L195.14,208.89L195.68,208.5L211.35,195.99L211.89,195.53L228.65,179.97L229.19,179.44L249.73,157.85L250.27,157.25L309.19,92.18L309.73,91.64L326.49,75.89L327.03,75.41L342.7,62.7L343.24,62.3L358.38,51.98L358.92,51.64L374.59,42.88L375.14,42.61L390.81,35.61L391.35,35.39L409.19,29.24L409.73,29.08L428.65,24.24L429.19,24.13L448.65,20.54L449.19,20.46L477.3,17.04L477.84,16.99L511.35,14.64L511.89,14.61L540,13.5\" style=\"vector-effect: non-scaling-stroke; fill: none; stroke: rgb(157, 212, 243); stroke-opacity: 1; stroke-width: 2px; opacity: 1;\"/></g><g class=\"points\"/><g class=\"text\"/></g></g></g><g class=\"overplot\"/><path class=\"xlines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><path class=\"ylines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><g class=\"overlines-above\"/><g class=\"xaxislayer-above\"><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(134,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">‚àí4</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(242,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">‚àí2</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(350,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">0</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(458,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">2</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(566,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">4</text></g></g><g class=\"yaxislayer-above\"><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,358.15)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">0</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,308.89)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">0.2</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,259.63)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">0.4</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,210.37)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">0.6</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,161.11)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">0.8</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,111.85)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">1</text></g></g><g class=\"overaxes-above\"/></g></g><g class=\"polarlayer\"/><g class=\"ternarylayer\"/><g class=\"geolayer\"/><g class=\"funnelarealayer\"/><g class=\"pielayer\"/><g class=\"treemaplayer\"/><g class=\"sunburstlayer\"/><g class=\"glimages\"/><defs id=\"topdefs-967b59\"><g class=\"clips\"/></defs><g class=\"layer-above\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"infolayer\"><g class=\"g-gtitle\"><text class=\"gtitle\" x=\"35\" y=\"50\" text-anchor=\"start\" dy=\"0em\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 17px; fill: rgb(42, 63, 95); opacity: 1; font-weight: normal; white-space: pre;\">Sigmo√Ød</text></g><g class=\"g-xtitle\"/><g class=\"g-ytitle\"/></g></svg>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-5, 5, num=1000)\n",
    "y = 1/(1+np.exp(-x))\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=y,\n",
    "                         mode = \"lines\",\n",
    "                         marker=dict(\n",
    "        color=color_chart[2])))\n",
    "fig.update_layout(title=\"Sigmo√Ød\")\n",
    "fig.show(\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWBOKIJTWNB2"
   },
   "source": [
    "### TanH / Hyperbolic Tangent\n",
    "* Advantages\n",
    "  * Zero centered‚Äîmaking it easier to model inputs that have strongly negative, neutral, and strongly positive values.\n",
    "  * Otherwise like the Sigmoid function.\n",
    "* Disadvantages\n",
    "  * Like the Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "fDfzInZe4huQ",
    "outputId": "af7f1f63-dadd-49f5-d7fc-9fd97227bec4"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"700\" height=\"450\" style=\"\" viewBox=\"0 0 700 450\"><rect x=\"0\" y=\"0\" width=\"700\" height=\"450\" style=\"fill: rgb(255, 255, 255); fill-opacity: 1;\"/><defs id=\"defs-f71044\"><g class=\"clips\"><clipPath id=\"clipf71044xyplot\" class=\"plotclip\"><rect width=\"540\" height=\"270\"/></clipPath><clipPath class=\"axesclip\" id=\"clipf71044x\"><rect x=\"80\" y=\"0\" width=\"540\" height=\"450\"/></clipPath><clipPath class=\"axesclip\" id=\"clipf71044y\"><rect x=\"0\" y=\"100\" width=\"700\" height=\"270\"/></clipPath><clipPath class=\"axesclip\" id=\"clipf71044xy\"><rect x=\"80\" y=\"100\" width=\"540\" height=\"270\"/></clipPath></g><g class=\"gradients\"/></defs><g class=\"bglayer\"><rect class=\"bg\" x=\"80\" y=\"100\" width=\"540\" height=\"270\" style=\"fill: rgb(229, 236, 246); fill-opacity: 1; stroke-width: 0;\"/></g><g class=\"layer-below\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"cartesianlayer\"><g class=\"subplot xy\"><g class=\"layer-subplot\"><g class=\"shapelayer\"/><g class=\"imagelayer\"/></g><g class=\"gridlayer\"><g class=\"x\"><path class=\"xgrid crisp\" transform=\"translate(134,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(242,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(458,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(566,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/></g><g class=\"y\"><path class=\"ygrid crisp\" transform=\"translate(0,356.51)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,295.76)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,174.24)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,113.49)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/></g></g><g class=\"zerolinelayer\"><path class=\"xzl zl crisp\" transform=\"translate(350,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 2px;\"/><path class=\"yzl zl crisp\" transform=\"translate(0,235)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 2px;\"/></g><path class=\"xlines-below\"/><path class=\"ylines-below\"/><g class=\"overlines-below\"/><g class=\"xaxislayer-below\"/><g class=\"yaxislayer-below\"/><g class=\"overaxes-below\"/><g class=\"plot\" transform=\"translate(80,100)\" clip-path=\"url('#clipf71044xyplot')\"><g class=\"scatterlayer mlayer\"><g class=\"trace scatter trace839f0a\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M0,256.5L114.05,255.76L114.59,255.74L140.54,254.52L141.08,254.48L161.08,252.28L161.62,252.2L177.84,248.76L178.38,248.61L189.73,244.69L190.27,244.46L200,239.59L200.54,239.27L209.73,232.96L210.27,232.53L218.38,225.22L218.92,224.67L227.57,214.71L228.11,214.02L237.3,200.74L237.84,199.88L248.11,181.73L248.65,180.69L261.08,154.89L261.62,153.7L291.89,88.27L292.43,87.24L302.7,69.26L303.24,68.4L312.97,54.6L313.51,53.92L322.7,43.71L323.24,43.18L331.89,35.79L332.43,35.39L341.62,29.49L342.16,29.19L352.43,24.45L352.97,24.24L363.78,20.8L364.32,20.66L377.84,17.89L378.38,17.8L398.38,15.56L398.92,15.52L425.95,14.24L426.49,14.23L461.08,13.69L461.62,13.69L540,13.5\" style=\"vector-effect: non-scaling-stroke; fill: none; stroke: rgb(42, 127, 175); stroke-opacity: 1; stroke-width: 2px; opacity: 1;\"/></g><g class=\"points\"/><g class=\"text\"/></g></g></g><g class=\"overplot\"/><path class=\"xlines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><path class=\"ylines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><g class=\"overlines-above\"/><g class=\"xaxislayer-above\"><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(134,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">‚àí4</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(242,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">‚àí2</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(350,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">0</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(458,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">2</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(566,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">4</text></g></g><g class=\"yaxislayer-above\"><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,356.51)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">‚àí1</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,295.76)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">‚àí0.5</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,235)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">0</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,174.24)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">0.5</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,113.49)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">1</text></g></g><g class=\"overaxes-above\"/></g></g><g class=\"polarlayer\"/><g class=\"ternarylayer\"/><g class=\"geolayer\"/><g class=\"funnelarealayer\"/><g class=\"pielayer\"/><g class=\"treemaplayer\"/><g class=\"sunburstlayer\"/><g class=\"glimages\"/><defs id=\"topdefs-f71044\"><g class=\"clips\"/></defs><g class=\"layer-above\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"infolayer\"><g class=\"g-gtitle\"><text class=\"gtitle\" x=\"35\" y=\"50\" text-anchor=\"start\" dy=\"0em\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 17px; fill: rgb(42, 63, 95); opacity: 1; font-weight: normal; white-space: pre;\">TanH</text></g><g class=\"g-xtitle\"/><g class=\"g-ytitle\"/></g></svg>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-5, 5, num=1000)\n",
    "y = np.tanh(x)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=y,\n",
    "                         mode = \"lines\",\n",
    "                         marker=dict(\n",
    "        color=color_chart[4])))\n",
    "fig.update_layout(title=\"TanH\")\n",
    "fig.show(\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilgFCVv7ZMkZ"
   },
   "source": [
    "### Swish\n",
    "Swish is a new, self-gated activation function discovered by researchers at Google. According to their paper, it performs better than ReLU with a similar level of computational efficiency. In experiments on ImageNet with identical models running ReLU and Swish, the new function achieved top -1 classification accuracy 0.6-0.9% higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "1lXW0TV4ZTiu",
    "outputId": "9b7a7f20-1d2f-47de-e52c-341ae016e3f6"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"700\" height=\"450\" style=\"\" viewBox=\"0 0 700 450\"><rect x=\"0\" y=\"0\" width=\"700\" height=\"450\" style=\"fill: rgb(255, 255, 255); fill-opacity: 1;\"/><defs id=\"defs-eaf8a7\"><g class=\"clips\"><clipPath id=\"clipeaf8a7xyplot\" class=\"plotclip\"><rect width=\"540\" height=\"270\"/></clipPath><clipPath class=\"axesclip\" id=\"clipeaf8a7x\"><rect x=\"80\" y=\"0\" width=\"540\" height=\"450\"/></clipPath><clipPath class=\"axesclip\" id=\"clipeaf8a7y\"><rect x=\"0\" y=\"100\" width=\"700\" height=\"270\"/></clipPath><clipPath class=\"axesclip\" id=\"clipeaf8a7xy\"><rect x=\"80\" y=\"100\" width=\"540\" height=\"270\"/></clipPath></g><g class=\"gradients\"/></defs><g class=\"bglayer\"><rect class=\"bg\" x=\"80\" y=\"100\" width=\"540\" height=\"270\" style=\"fill: rgb(229, 236, 246); fill-opacity: 1; stroke-width: 0;\"/></g><g class=\"layer-below\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"cartesianlayer\"><g class=\"subplot xy\"><g class=\"layer-subplot\"><g class=\"shapelayer\"/><g class=\"imagelayer\"/></g><g class=\"gridlayer\"><g class=\"x\"><path class=\"xgrid crisp\" transform=\"translate(134,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(242,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(458,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(566,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/></g><g class=\"y\"><path class=\"ygrid crisp\" transform=\"translate(0,297.27)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,250.94)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,204.61)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,158.28)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,111.95)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/></g></g><g class=\"zerolinelayer\"><path class=\"xzl zl crisp\" transform=\"translate(350,0)\" d=\"M0,100v270\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 2px;\"/><path class=\"yzl zl crisp\" transform=\"translate(0,343.6)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 2px;\"/></g><path class=\"xlines-below\"/><path class=\"ylines-below\"/><g class=\"overlines-below\"/><g class=\"xaxislayer-below\"/><g class=\"yaxislayer-below\"/><g class=\"overaxes-below\"/><g class=\"plot\" transform=\"translate(80,100)\" clip-path=\"url('#clipeaf8a7xyplot')\"><g class=\"scatterlayer mlayer\"><g class=\"trace scatter trace750dc3\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M0,245.15L52.43,246.86L52.97,246.89L92.97,249.12L93.51,249.15L196.22,256.46L196.76,256.47L215.68,256.08L216.22,256.05L234.59,253.98L235.14,253.89L249.19,250.83L249.73,250.68L264.86,245.7L265.41,245.49L281.08,238.36L281.62,238.08L296.22,229.68L296.76,229.33L312.43,218.59L312.97,218.19L332.43,202.86L332.97,202.4L356.76,181.6L357.3,181.11L397.84,143.32L398.38,142.81L471.89,74.41L472.43,73.92L511.89,38.39L512.43,37.91L540,13.5\" style=\"vector-effect: non-scaling-stroke; fill: none; stroke: rgb(42, 127, 175); stroke-opacity: 1; stroke-width: 2px; opacity: 1;\"/></g><g class=\"points\"/><g class=\"text\"/></g></g></g><g class=\"overplot\"/><path class=\"xlines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><path class=\"ylines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><g class=\"overlines-above\"/><g class=\"xaxislayer-above\"><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(134,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">‚àí4</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(242,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">‚àí2</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(350,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">0</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(458,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">2</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"383\" transform=\"translate(566,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">4</text></g></g><g class=\"yaxislayer-above\"><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,343.6)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">0</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,297.27)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">1</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,250.94)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">2</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,204.61)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">3</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,158.28)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">4</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,111.95)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">5</text></g></g><g class=\"overaxes-above\"/></g></g><g class=\"polarlayer\"/><g class=\"ternarylayer\"/><g class=\"geolayer\"/><g class=\"funnelarealayer\"/><g class=\"pielayer\"/><g class=\"treemaplayer\"/><g class=\"sunburstlayer\"/><g class=\"glimages\"/><defs id=\"topdefs-eaf8a7\"><g class=\"clips\"/></defs><g class=\"layer-above\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"infolayer\"><g class=\"g-gtitle\"><text class=\"gtitle\" x=\"35\" y=\"50\" text-anchor=\"start\" dy=\"0em\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 17px; fill: rgb(42, 63, 95); opacity: 1; font-weight: normal; white-space: pre;\">Swish</text></g><g class=\"g-xtitle\"/><g class=\"g-ytitle\"/></g></svg>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-5, 5, num=1000)\n",
    "y = x / (1+np.exp(-x))\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=y,\n",
    "                         mode = \"lines\",\n",
    "                         marker=dict(\n",
    "        color=color_chart[4])))\n",
    "fig.update_layout(title=\"Swish\")\n",
    "fig.show(\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFGTF9yXEjPm"
   },
   "source": [
    "## Neural Networks üß†üß†\n",
    "\n",
    "A neural network is a collection of formal neurons, organized in layers. The way these layers are connected with each other may take several forms and we will have the opportunity to study a lot of them in the future. But for now we will focus on a specific type of organisation of the network (commonly called architecture) which is the sequential architecture.\n",
    "\n",
    "A sequential architecture, as its name suggests, is organized in the following way:\n",
    "\n",
    "* The first layer (also called input layer or bottom layer) takes the data variables as input\n",
    "* The following layers (also called hidden layers) use the outputs of the previous layer as input\n",
    "* The last layer (also called output layer or top layer) produces the output from which we make the prediction\n",
    "\n",
    "The figure below represents an exemple of what a sequential model architecture made of densely connected layers may look like:\n",
    "\n",
    "<img src=\"https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/M08-DeepLearning/neural_network_diagram.png\" />\n",
    "\n",
    "This may look intimidating, but remember, a model is never more than a function $h$, an hypothetesis that data scientists form around what the actual function $f$ linking the input variables $X$ to the target variable $Y$ looks like.\n",
    "\n",
    "Neural networks are only a visual way of representing functions that we use for tackling difficult problems. Neural networks are chained compositions of functions that make it possible to form complex and highly non-linear functions.\n",
    "\n",
    "The number of layers in the network, the number of neurons on each layer and their respective activation functions are all hyperparameters of the model which have to be chosen by the data scientist prior to training the model.\n",
    "\n",
    "By now you may wonder how do we choose how many layers to include in our neural network? Or how many neurons should be on each layer? These are all really great questions, neural networks are a very empirical branch of machine learning, and a lot of what we know about neural networks comes from trial and error and comparing models on comparable challenges. This introductory lesson's goal is also to give you some practical intuition on neural networks in addition to the theoretical background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhhQd23_qrpw"
   },
   "source": [
    "## Forward pass ‚ñ∂Ô∏è‚ñ∂Ô∏è\n",
    "\n",
    "The forward pass mentioned in the figure indicates the way that the neural network transforms the inputs into outputs.If we were to write the forward pass it would look like this:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "output = \\; & \\Phi_{output}(w_{o,(2,1)} \\times n_{2,1} + w_{o,(2,2)} \\times n_{2,2} + w_{o,(2,3)} \\times n_{2,3} + \\theta_{output}) \\\\\n",
    "n_{2,1} = \\; & \\Phi_{2,1}(w_{(2,1),(1,1)} \\times n_{1,1} + w_{(2,1),(1,2)} \\times n_{1,2} + w_{(2,1),(1,3)} \\times n_{1,3} + w_{(2,1),(1,4)} \\times n_{1,4} + w_{(2,1),(1,5)} \\times n_{1,5} + \\theta_{(2,1)}) \\\\\n",
    "n_{2,2} = \\; & \\Phi_{2,2}(w_{(2,2),(1,1)} \\times n_{1,1} + w_{(2,2),(1,2)} \\times n_{1,2} + w_{(2,2),(1,3)} \\times n_{1,3} + w_{(2,2),(1,4)} \\times n_{1,4} + w_{(2,2),(1,5)} \\times n_{1,5} + \\theta_{(2,2)}) \\\\\n",
    "n_{2,3} = \\; & \\Phi_{2,3}(w_{(2,3),(1,1)} \\times n_{1,1} + w_{(2,3),(1,2)} \\times n_{1,2} + w_{(2,3),(1,3)} \\times n_{1,3} + w_{(2,3),(1,4)} \\times n_{1,4} + w_{(2,3),(1,5)} \\times n_{1,5} + \\theta_{(2,3)}) \\\\\n",
    "n_{1,1} = \\; & \\Phi_{1,1}(w_{(1,1), 1} \\times x_1 + \\dots + w_{(1,1),p} \\times x_p + \\theta_{(1,1)}) \\\\\n",
    "n_{1,2} = \\; & \\Phi_{1,2}(w_{(1,2), 1} \\times x_1 + \\dots + w_{(1,2),p} \\times x_p + \\theta_{(1,2)}) \\\\\n",
    "n_{1,3} = \\; & \\Phi_{1,3}(w_{(1,3), 1} \\times x_1 + \\dots + w_{(1,3),p} \\times x_p + \\theta_{(1,3)}) \\\\\n",
    "n_{1,4} = \\; & \\Phi_{1,4}(w_{(1,4), 1} \\times x_1 + \\dots + w_{(1,4),p} \\times x_p + \\theta_{(1,4)}) \\\\\n",
    "n_{1,5} = \\; & \\Phi_{1,5}(w_{(1,5), 1} \\times x_1 + \\dots + w_{(1,5),p} \\times x_p + \\theta_{(1,5)}) \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Not so easy read this kind of formula, and believe it or not, the presented model is rather small! Which is why we will mostly use other ways of representing neural network models grahically. \n",
    "\n",
    "Like we said, the forward pass is the way the model will transform the inputs into outputs, therefore when defining the architecture of the model, the data scientist has to keep two main things in mind:\n",
    "* The input dimension : the number of weights on each neuron of the input layer will depend on the dimension of the output, we will how that translates in practice.\n",
    "* The dimension of the target variable (the type of problem) : The number and the characteristics of the neurons on the output layer depends on the target variable we are trying to predict, we will see how to do this in practice as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIdnMrCZaBDO"
   },
   "source": [
    "## Back Propagation ‚óÄÔ∏è‚óÄÔ∏è\n",
    "\n",
    "Back Propagation is the term used for the way a deep neural network model will optimize its parameters in order to find the loss function's minimum, the good news is that it is in fact nothing more than a batch gradient descent algorithm that will be computed step by step from the top layer backward all the way to the bottom layer, the bad news is... well there is not really a bad news, except from the fact that it may seem a little intimidating at first.\n",
    "\n",
    "### Chain rule\n",
    "\n",
    "As we mentionned earlier, nack propagation is done layer by layer starting from the top layer and moving backward all theway to the bottom layer. To achieve this decomposition, we are going to use a property of derivation operations called the chain rule.\n",
    "\n",
    "The chain rule is used to calculate the derivative of composed functions. Let $f$ and $g$ be two differentiable functions and $w$ a parameter of $g$, the derivative of $f \\circ g(w)$ is (all notations are equivalent):\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "(f \\circ g )'(w) & = f'\\circ g(w) \\times g'(w) \\\\\n",
    "\\frac{\\partial (f \\circ g)}{\\partial w}(w) & = \\frac{\\partial f}{\\partial g(w)}(g(w)) \\times \\frac{\\partial g}{\\partial w}(w) \\\\\n",
    "\\frac{\\partial (f(g(w)))}{\\partial w} & = \\frac{\\partial f}{\\partial g} \\times \\frac{\\partial g}{\\partial w}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "It may seem a little unclear at this point, but this makes it possible to differentiate composed functions one step at a time in order to get the final value of the derivative without having to compute the whole analytical expression of the derivative.\n",
    "\n",
    "### Backpropagation example\n",
    "\n",
    "Let's take the example of a very simple neural network model with two layers, thetop layer has one neuron on it with ReLu activation and the bottom layer has two neurons with Relu activation and we have two input variables $x_1$ and $x_2$.\n",
    "\n",
    "<img src=\"https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/M08-DeepLearning/backprop1.png\" />\n",
    "\n",
    "The output of the final neuron is compared to the target variable thanks to a loss function $C$, which can be computed for a single observation in the data. We said earlier that we use batch gradient descent to train deep learning models, meaning we have to compute the gradient of the loss function for a batch of observations in order to update each parameter in the model.\n",
    "\n",
    "A direct strategy to do this would be to calculate the full gradient of the loss function:\n",
    "\n",
    "$$\n",
    "\\nabla_{w_{11},w_{12},\\theta_{1,1}, w_{21},w_{22}, \\theta_{1,2},w_{1},w_{2}, \\theta_{2,1}} C(y_{pred},y) = (\\frac{\\partial C(y_{pred},y)}{\\partial w_{11}}, \\frac{\\partial C(y_{pred},y)}{\\partial w_{12}}, \\frac{\\partial C(y_{pred},y)}{\\partial \\theta_{1,1}}, \\frac{\\partial C(y_{pred},y)}{\\partial w_{21}}, \\frac{\\partial C(y_{pred},y)}{\\partial w_{22}}, \\frac{\\partial C(y_{pred},y)}{\\partial \\theta_{1,2}}, \\frac{\\partial C(y_{pred},y)}{\\partial w_{1}}, \\frac{\\partial C(y_{pred},y)}{\\partial w_{2}}, \\frac{\\partial C(y_{pred},y)}{\\partial \\theta_{2,1}})\n",
    "$$\n",
    "\n",
    "That would be acceptable in this case since we have only 9 parameters to udpate after each batch, but for more complex architectures it would just become a nightmare but also way too long to compute directly. Which is where the chain rule comes in :\n",
    "\n",
    "Let's only calculate the portion of the gradient for $\\theta_{2,1}$, $w_{1}$ and $w_2$:\n",
    "\n",
    "<img src=\"https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/M08-DeepLearning/backprop2.png\" />\n",
    "\n",
    "We have:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial C(y_{pred},y)}{\\partial w_{1}} & = \\frac{\\partial C}{\\partial y_{pred}} \\times \\frac{\\partial y_{pred}}{\\partial w_1} \\\\\n",
    "\\frac{\\partial C(y_{pred},y)}{\\partial w_{2}} & = \\frac{\\partial C}{\\partial y_{pred}} \\times \\frac{\\partial y_{pred}}{\\partial w_2} \\\\\n",
    "\\frac{\\partial C(y_{pred},y)}{\\partial \\theta_{2,1}} & = \\frac{\\partial C}{\\partial y_{pred}} \\times \\frac{\\partial y_{pred}}{\\theta_{2,1}} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "That is the first step of the back propagation. We can now cache (meaning save in memory) the results of these computations and move on to the next layer :\n",
    "\n",
    "<img src=\"https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/M08-DeepLearning/backprop3_2.png\" />\n",
    "\n",
    "The gradient portion regarding $n_{1,1}$ can be easily obtained from the cached value of the gradient for $w_1$, similarly the gradient portion regarding $n_{1,2}$  can be easily computed from the cached value of the gradient for $w_2$, as follows:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial C(y_{pred},y)}{\\partial w_{11}} & = \\frac{w_1}{n_{1,1}} \\underbrace{\\frac{\\partial C(y_{pred},y)}{\\partial w_{1}}}_\n",
    "    {\\text{already cached}} \\times \\frac{\\partial n_{1,1}}{\\partial w_{11}} \\\\\n",
    "\\frac{\\partial C(y_{pred},y)}{\\partial w_{12}} & = \\frac{w_1}{n_{1,1}} \\underbrace{\\frac{\\partial C(y_{pred},y)}{\\partial w_{1}}}_\n",
    "    {\\text{already cached}} \\times \\frac{\\partial n_{1,1}}{\\partial w_{12}} \\\\\n",
    "\\frac{\\partial C(y_{pred},y)}{\\partial \\theta_{1,1}} & = \\frac{w_1}{n_{1,1}}\\underbrace{\\frac{\\partial C(y_{pred},y)}{\\partial w_{1}}}_\n",
    "    {\\text{already cached}} \\times \\frac{\\partial n_{1,1}}{\\partial \\theta_{1,1}} \\\\\n",
    "\\frac{\\partial C(y_{pred},y)}{\\partial w_{21}} & = \\frac{w_2}{n_{1,2}} \\underbrace{\\frac{\\partial C(y_{pred},y)}{\\partial w_{2}}}_\n",
    "    {\\text{already cached}} \\times \\frac{\\partial n_{1,2}}{\\partial w_{21}} \\\\\n",
    "\\frac{\\partial C(y_{pred},y)}{\\partial w_{22}} & = \\frac{w_2}{n_{1,2}}\\underbrace{\\frac{\\partial C(y_{pred},y)}{\\partial w_{2}}}_\n",
    "    {\\text{already cached}} \\times \\frac{\\partial n_{1,2}}{\\partial w_{22}} \\\\\n",
    "\\frac{\\partial C(y_{pred},y)}{\\partial \\theta_{1,2}}& = \\frac{w_2}{n_{1,2}}\\underbrace{\\frac{\\partial C(y_{pred},y)}{\\partial w_{2}}}_\n",
    "    {\\text{already cached}} \\times \\frac{\\partial n_{1,2}}{\\partial \\theta_{1,2}} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The full computation leading to the expressions above is out of the scope of this lecture. However, if you're a fond of maths and an expert in partial derivatives, you can have a glance at the annex at the end of this notebook ü§ì\n",
    "\n",
    "This trick makes it possible to compute only one derivation operation for each parameter which saves a lot of time, it also sheds light on many of the remarks previously made on the activation functions. Indeed the gradient's components for the parameters of one layer depend on the product of all the gradient's components of the neurons connected to it further up in the network, therefore if one of these gradient's component is equal to $0$ then no contribution is made from this part of the network (this can happen for ReLu activation function, this phenomenon is known as dying ReLu). This can also lead to decreasing values of the gradient's components as you move down deeper in the network (this can happen with sigmo√Ød and tanH activation functions and is called vanishing gradient)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdSMXER51h2w"
   },
   "source": [
    "## Training a neural network üèÉüèÉ\n",
    "\n",
    "Training a neural network by batch gradient descent should no longer seem so nebulous to you at this point, we have just explained how the parameters in the network can be updated thanks to one batch of data, all that is left to do is loop over all batches in the dataset in order to complete an **epoch**, and then start next **epoch** by shuffling the dataset and creating a new set of batch and repeat !\n",
    "\n",
    "Let's review all the steps one last time so that we are all on the same page !\n",
    "* **Model building** : choose the number of layers, the number of neurons on each layer, the activation function on each neuron (usually it is the same one in the whole network to the exception of the final layer, we will see why) and all other hyper-parameters of the model\n",
    "* **Initialize the parameters** : this step sets a starting value for each parameter in the network (it can be random or set manually, if you chose activation functions that can saturate, make sure the initial parameters are not too high and that your data is normalized)\n",
    "* **Start the training**:\n",
    "  * Choose a learning rate (we will learn more about this later)\n",
    "  * The training set is shuffled and split into several batches of a given size\n",
    "  * A first batch of data goes through the network (this is called the forward pass) and an output is formed for each of the observations in the batch.\n",
    "  * The value of the loss function is computed by comparing every output with the target value\n",
    "  <img src=\"https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/M08-DeepLearning/forward_pass_batch.png\" />\n",
    "  * By using the chain rule, the components of the gradient of the loss function are computed for each parameter in the network and the parameters get an update based on the learning rate and the gradient. This is the back propagation step (for clarity purposes we have not represented all the red arrows represented the computations of the gradient's components).\n",
    "  <img src=\"https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/M08-DeepLearning/back_prop_batch.png\" />\n",
    "  * When this is done, a new batch of data is passed to the network and new outputs are computed based on the updated parameters. Backpropagation happens again, and these two steps are repeated until the end of the epoch, when all batches have gone through the network.\n",
    "  * The training stops when the desired number of epochs is achieved.\n",
    "* By the end of all this your neural network is trained and ready to make predictions !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annex - Backpropagation example ü§ìü§ì\n",
    "\n",
    "We would like to find an expression of the different partial derivatives of the loss function $C(y_{pred},y)$ with respect to each parameter of the neural network. What's more, we would like to find a smart way of performing the computations, by being able to re-use the derivatives that were already computed for the top layer, to deduce the derivatives of the hidden layer (this is the principle of backpropagation).\n",
    "\n",
    "From the neural network architecture shown as an example in this lecture, we have :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_{pred} = n_{2,1} = \\; & \\Phi_{2,1}(w_{1} \\times n_{1,1} + w_{2} \\times n_{1,2} + \\theta_{2,1}) = \\Phi_{2,1}(z_{2,1}) \\\\\n",
    "n_{1,1} = \\; & \\Phi_{1,1}(w_{1,1} \\times x_1 + w_{1,2} \\times x_2 + \\theta_{1,1}) = \\Phi_{1,1}(z_{1,1}) \\\\\n",
    "n_{1,2} = \\; & \\Phi_{1,2}(w_{2,1} \\times x_1 + w_{2,2} \\times x_2 + \\theta_{1,2}) = \\Phi_{1,2}(z_{1,2})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Let's compute the derivatives of $C(y_{pred},y)$ with respect to the top layer parameters :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial C}{\\partial w_1} &= \\frac{\\partial C}{\\partial n_{2,1}} \\frac{\\partial n_{2,1}}{\\partial z_{2,1}} \\frac{\\partial z_{2,1}}{\\partial w_1} \\\\\n",
    "&= n_{1,1}\\frac{\\partial C}{\\partial n_{2,1}} \\frac{\\partial n_{2,1}}{\\partial z_{2,1}}\\\\\n",
    "\\frac{\\partial C}{\\partial w_2} &= \\frac{\\partial C}{\\partial n_{2,1}} \\frac{\\partial n_{2,1}}{\\partial z_{2,1}} \\frac{\\partial z_{2,1}}{\\partial w_2} \\\\\n",
    "&= n_{1,2}\\frac{\\partial C}{\\partial n_{2,1}} \\frac{\\partial n_{2,1}}{\\partial z_{2,1}}\\\\\n",
    "\\frac{\\partial C}{\\partial \\theta_{2,1}} &= \\frac{\\partial C}{\\partial n_{2,1}} \\frac{\\partial n_{2,1}}{\\partial z_{2,1}}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Let's do the same for the derivatives with respect to the hidden layer parameters. Let's detail the whole process for $w_{1,1}$ :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial C}{\\partial w_{1,1}} &= \\frac{\\partial C}{\\partial n_{2,1}} \\frac{\\partial n_{2,1}}{\\partial z_{2,1}} \\frac{\\partial z_{2,1}}{\\partial n_{1,1}}\\frac{\\partial n_{1,1}}{\\partial z_{1,1}}\\frac{\\partial z_{1,1}}{\\partial w_{1,1}} \\\\\n",
    "&= w_1 x_1 \\frac{\\partial C}{\\partial n_{2,1}} \\frac{\\partial n_{2,1}}{\\partial z_{2,1}}\\frac{\\partial n_{1,1}}{\\partial z_{1,1}} \\\\\n",
    "&= \\frac{w_1 x_1}{n_{1,1}} \\frac{\\partial C}{\\partial w_1} \\frac{\\partial n_{1,1}}{\\partial z_{1,1}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Now, to make appear in this expression something that depends on the derivatives from the top layer, let's find use the following trick :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial n_{1,1}}{\\partial w_{1,1}} &= \\frac{\\partial n_{1,1}}{\\partial z_{1,1}}\\frac{\\partial z_{1,1}}{\\partial w_{1,1}} \\\\\n",
    "&= x_1 \\frac{\\partial n_{1,1}}{\\partial z_{1,1}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Now by substitution, we end up with the expression : \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial C}{\\partial w_{1,1}} = \\frac{w_1 x_1}{n_{1,1}} \\frac{\\partial C}{\\partial w_1} \\frac{1}{x_1}\\frac{\\partial n_{1,1}}{\\partial w_{1,1}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "And finally :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial C}{\\partial w_{1,1}} = \\frac{w_1}{n_{1,1}} \\underbrace{\\frac{\\partial C}{\\partial w_1}}_\n",
    "    {\\text{already cached}}\\frac{\\partial n_{1,1}}{\\partial w_{1,1}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Summing up and considering all the hidden layer parameters, we get :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial C(y_{pred},y)}{\\partial w_{11}} & = \\frac{w_1}{n_{1,1}} \\underbrace{\\frac{\\partial C(y_{pred},y)}{\\partial w_{1}}}_\n",
    "    {\\text{already cached}} \\times \\frac{\\partial n_{1,1}}{\\partial w_{11}} \\\\\n",
    "\\frac{\\partial C(y_{pred},y)}{\\partial w_{12}} & = \\frac{w_1}{n_{1,1}} \\underbrace{\\frac{\\partial C(y_{pred},y)}{\\partial w_{1}}}_\n",
    "    {\\text{already cached}} \\times \\frac{\\partial n_{1,1}}{\\partial w_{12}} \\\\\n",
    "\\frac{\\partial C(y_{pred},y)}{\\partial \\theta_{1,1}} & = \\frac{w_1}{n_{1,1}}\\underbrace{\\frac{\\partial C(y_{pred},y)}{\\partial w_{1}}}_\n",
    "    {\\text{already cached}} \\times \\frac{\\partial n_{1,1}}{\\partial \\theta_{1,1}} \\\\\n",
    "\\frac{\\partial C(y_{pred},y)}{\\partial w_{21}} & = \\frac{w_2}{n_{1,2}} \\underbrace{\\frac{\\partial C(y_{pred},y)}{\\partial w_{2}}}_\n",
    "    {\\text{already cached}} \\times \\frac{\\partial n_{1,2}}{\\partial w_{21}} \\\\\n",
    "\\frac{\\partial C(y_{pred},y)}{\\partial w_{22}} & = \\frac{w_2}{n_{1,2}}\\underbrace{\\frac{\\partial C(y_{pred},y)}{\\partial w_{2}}}_\n",
    "    {\\text{already cached}} \\times \\frac{\\partial n_{1,2}}{\\partial w_{22}} \\\\\n",
    "\\frac{\\partial C(y_{pred},y)}{\\partial \\theta_{1,2}}& = \\frac{w_2}{n_{1,2}}\\underbrace{\\frac{\\partial C(y_{pred},y)}{\\partial w_{2}}}_\n",
    "    {\\text{already cached}} \\times \\frac{\\partial n_{1,2}}{\\partial \\theta_{1,2}} \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKU0CSD6rQwP"
   },
   "source": [
    "## Ressources üìöüìö\n",
    "\n",
    "* <a href=\"https://www.youtube.com/watch?v=Ilg3gGewQ5U\">A video explaining backpropagation in a visual way </a>\n",
    "\n",
    "* <a href=\"https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/\"> A very good blog article on how to code a neural network model from scratch </a>\n",
    "\n",
    "* <a href=\"https://news.mit.edu/2017/explained-neural-networks-deep-learning-0414\"> An article on the history of neural networks</a>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "01-Neural_networks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
